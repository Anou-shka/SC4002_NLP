{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio\n",
    "# !pip install transformers\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow --user\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install scikit-learn\n",
    "# !pip install seaborn\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = \"/Users/anoushkanahata/Desktop/SC4002/SC4002_NLP/glove.6B.100d.txt\" # change to your path\n",
    "GLOVE_PATH = \"./glove.6B.100d.txt\"\n",
    "EMBED_DIM = 100 # No need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "# sys.path.append('/Users/anoushkanahata/Desktop/SC4002/SC4002_NLP')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, f1_score, f1_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import seaborn as sns\n",
    "from Embeddings import GloveEmbedding, GloveTokenizerNoSub\n",
    "import itertools\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Any\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer\n",
    "tokenizer_no_sub = GloveTokenizerNoSub(glove_file_path=GLOVE_PATH)\n",
    "embedding = GloveEmbedding(\n",
    "    glove_file_path = GLOVE_PATH, \n",
    "    trainable = False # False for part 2 to disable the Embedding training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, embedding, hidden_size, embed_size, bidirectional, num_rnn_layer, dropout_rate, layer_norm):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.embedding = embedding  # pass pretrained embedding in\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True, num_layers = num_rnn_layer, bidirectional=bidirectional, dropout = dropout_rate if num_rnn_layer > 1 else 0)\n",
    "        \n",
    "        # if bidirectional, the output hidden size is double\n",
    "        self.hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        \n",
    "        # MLP\n",
    "        if not layer_norm:\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(self.hidden_size, self.hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(self.hidden_size, 1),  # output dimension is 1 (sigmoid is in BCELossWithLogits, so no sigmoid here. This will get better result)\n",
    "            )\n",
    "        else:\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.LayerNorm(self.hidden_size),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(self.hidden_size, self.hidden_size),\n",
    "                nn.LayerNorm(self.hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(self.hidden_size, 1), \n",
    "            )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        '''\n",
    "        This method is designed for biLSTM/GRU/RNN. For LSTM/GRU/RNN for only one direction, just take hidden as the rnn output.\n",
    "        RNN - hidden -> MLP --> outcome\n",
    "        '''\n",
    "        # embed the input\n",
    "        embedded = self.embedding(input_ids)  # [batch_size, seq_length, embedding_dim]\n",
    "        \n",
    "        # feed forward\n",
    "        output, hidden = self.rnn(embedded) # we don't need encoder so we only keep the output\n",
    "\n",
    "        # make attention mask from [batch_size, seq_length] to [batch_size, seq_length, 1] as the same dimension as rnn\n",
    "        attention_mask = attention_mask.unsqueeze(-1)  # [batch_size, seq_length, 1]\n",
    "\n",
    "        # use attention mask to mask the output, ignore the padding embedding vector, only add the valid embedding vector \n",
    "        masked_output = output * attention_mask\n",
    "\n",
    "        # sum up all the valid output\n",
    "        summed_output = masked_output.sum(dim=1)  # [batch_size, hidden_size]\n",
    "\n",
    "        logits = self.output_layer(summed_output)\n",
    "        \n",
    "        return logits  # The output is [batch_size, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "\n",
    "train_df = pd.read_csv(\"./preprocessed_dataset/train.csv\").iloc[:,1:]\n",
    "validation_df = pd.read_csv(\"./preprocessed_dataset/validation.csv\").iloc[:,1:]\n",
    "test_df = pd.read_csv(\"./preprocessed_dataset/test.csv\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[13077,    87,     0],\n",
       "         [  199,    34,    83]]),\n",
       " 'attention_mask': tensor([[1, 1, 0],\n",
       "         [1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to use tokenizer api\n",
    "tokenizer_no_sub.encode([\"hello world\", \"how are you\"], return_tensors = \"pt\") # insist to return pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper paramaters\n",
    "dropout_rate = 0.1\n",
    "num_rnn_layer = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "val_steps = 100 # compute validation error every n step\n",
    "\n",
    "num_train_epochs = 3\n",
    "\n",
    "batch_size = 32\n",
    "lr = 8e-5\n",
    "weight_decay = 1e-5\n",
    "\n",
    "\n",
    "warmup_ratio=0.1\n",
    "max_grad_norm = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset and data loader\n",
    "class CustomizeDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            df : pd.DataFrame\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(\n",
    "            self, \n",
    "            index : int\n",
    "        ) -> dict:\n",
    "        \n",
    "        inputs = self.df.iloc[index,0] # 0 is text\n",
    "        label = self.df.iloc[index, 1] # 1 is label\n",
    "        \n",
    "        return {\n",
    "            \"input_str\" : inputs, # output a string\n",
    "            \"label\" : label # output a label\n",
    "        }\n",
    "        \n",
    "# collater function (used for dynamic padding to save memory)\n",
    "class Collater:\n",
    "    def __init__(\n",
    "            self,\n",
    "            tokenizer_no_sub : GloveTokenizerNoSub\n",
    "        ) -> None:\n",
    "        self.tokenizer_no_sub = tokenizer_no_sub \n",
    "    \n",
    "    def __call__(\n",
    "            self,\n",
    "            instances : list # a list of string\n",
    "        ) -> Any:\n",
    "        # __call__ is for function-like object\n",
    "        input_str_list = [instance[\"input_str\"] for instance in instances]\n",
    "        input_dict = tokenizer_no_sub.encode(input_str_list, return_tensors = \"pt\") # return pytorch tensor\n",
    "        input_ids = input_dict[\"input_ids\"]\n",
    "        attention_mask = input_dict[\"attention_mask\"]\n",
    "        label = [torch.tensor(instance[\"label\"], dtype = torch.int64) for instance in instances]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"label\": torch.tensor(label),\n",
    "            \"attention_mask\": attention_mask # mask the pad position\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and data loader\n",
    "collate_fn = Collater(tokenizer_no_sub)\n",
    "\n",
    "\n",
    "\n",
    "train_ds = CustomizeDataset(\n",
    "    df = train_df\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_ds,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_ds = CustomizeDataset(\n",
    "    df = validation_df\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_ds,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "test_ds = CustomizeDataset(\n",
    "    df = test_df\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_ds,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:801, warm up: 80\n"
     ]
    }
   ],
   "source": [
    "# compute warmup status\n",
    "num_training_steps = num_train_epochs * len(train_loader)\n",
    "num_warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "print(f\"train:{num_training_steps}, warm up: {num_warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer, loss_fn and so on\n",
    "\n",
    "cls_model = SentimentRNN(\n",
    "    embedding = embedding, \n",
    "    hidden_size = hidden_dim, \n",
    "    embed_size = EMBED_DIM, \n",
    "    bidirectional = False, #  False for part 2\n",
    "    num_rnn_layer = num_rnn_layer,\n",
    "    dropout_rate = dropout_rate,\n",
    "    layer_norm = True # set if you need layer norm\n",
    ")\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = AdamW(\n",
    "    params = cls_model.parameters(),\n",
    "    lr = lr,\n",
    "    weight_decay = weight_decay\n",
    ")\n",
    "\n",
    "scheduler  = get_cosine_schedule_with_warmup(\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = num_warmup_steps,\n",
    "    num_training_steps = num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy for wach data loader\n",
    "\n",
    "def compute_accuracy(data_loader: DataLoader) -> float:\n",
    "    \n",
    "    cls_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            labels = data[\"label\"].view(-1, 1).float().to(device)\n",
    "            \n",
    "            logits = cls_model(input_ids, attention_mask=attention_mask)\n",
    "     \n",
    "            predictions = (logits > 0).long()\n",
    "            \n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def compute_loss(data_loader: DataLoader) -> float:\n",
    "    total_loss = 0\n",
    "    cls_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            labels = data[\"label\"].view(-1, 1).float().to(device)\n",
    "            \n",
    "            logits = cls_model.forward(input_ids, attention_mask)\n",
    "            loss = loss_fn.forward(\n",
    "                input = logits,\n",
    "                target = labels\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            \n",
    "        total_loss /= len(val_loader)\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance, counter):\n",
    "    positive_diff = abs(validation_loss - train_loss)\n",
    "\n",
    "    # Increment counter if no significant improvement\n",
    "    if positive_diff >= min_delta:\n",
    "        counter += 1\n",
    "        if counter >= tolerance:\n",
    "            return True, counter\n",
    "    # Ensure the function always returns both values\n",
    "    return False, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/801] train loss: [0.7338] (epoch [1/3])\n",
      "[1/801] validation loss: [0.7005] validation accuracy: [0.4981]\n",
      "[2/801] train loss: [0.7387] (epoch [1/3])\n",
      "[3/801] train loss: [0.7350] (epoch [1/3])\n",
      "[4/801] train loss: [0.7270] (epoch [1/3])\n",
      "[5/801] train loss: [0.7024] (epoch [1/3])\n",
      "[6/801] train loss: [0.7457] (epoch [1/3])\n",
      "[7/801] train loss: [0.6884] (epoch [1/3])\n",
      "[8/801] train loss: [0.7260] (epoch [1/3])\n",
      "[9/801] train loss: [0.6645] (epoch [1/3])\n",
      "[10/801] train loss: [0.7335] (epoch [1/3])\n",
      "[11/801] train loss: [0.6870] (epoch [1/3])\n",
      "[12/801] train loss: [0.6733] (epoch [1/3])\n",
      "[13/801] train loss: [0.7197] (epoch [1/3])\n",
      "[14/801] train loss: [0.7066] (epoch [1/3])\n",
      "[15/801] train loss: [0.6882] (epoch [1/3])\n",
      "[16/801] train loss: [0.6948] (epoch [1/3])\n",
      "[17/801] train loss: [0.7176] (epoch [1/3])\n",
      "[18/801] train loss: [0.6886] (epoch [1/3])\n",
      "[19/801] train loss: [0.6960] (epoch [1/3])\n",
      "[20/801] train loss: [0.6967] (epoch [1/3])\n",
      "[21/801] train loss: [0.6739] (epoch [1/3])\n",
      "[22/801] train loss: [0.6910] (epoch [1/3])\n",
      "[23/801] train loss: [0.6749] (epoch [1/3])\n",
      "[24/801] train loss: [0.7019] (epoch [1/3])\n",
      "[25/801] train loss: [0.6839] (epoch [1/3])\n",
      "[26/801] train loss: [0.6598] (epoch [1/3])\n",
      "[27/801] train loss: [0.6844] (epoch [1/3])\n",
      "[28/801] train loss: [0.6990] (epoch [1/3])\n",
      "[29/801] train loss: [0.6894] (epoch [1/3])\n",
      "[30/801] train loss: [0.7048] (epoch [1/3])\n",
      "[31/801] train loss: [0.6828] (epoch [1/3])\n",
      "[32/801] train loss: [0.7115] (epoch [1/3])\n",
      "[33/801] train loss: [0.6737] (epoch [1/3])\n",
      "[34/801] train loss: [0.7281] (epoch [1/3])\n",
      "[35/801] train loss: [0.6978] (epoch [1/3])\n",
      "[36/801] train loss: [0.6975] (epoch [1/3])\n",
      "[37/801] train loss: [0.7007] (epoch [1/3])\n",
      "[38/801] train loss: [0.6765] (epoch [1/3])\n",
      "[39/801] train loss: [0.7030] (epoch [1/3])\n",
      "[40/801] train loss: [0.6831] (epoch [1/3])\n",
      "[41/801] train loss: [0.6980] (epoch [1/3])\n",
      "[42/801] train loss: [0.6997] (epoch [1/3])\n",
      "[43/801] train loss: [0.6819] (epoch [1/3])\n",
      "[44/801] train loss: [0.6817] (epoch [1/3])\n",
      "[45/801] train loss: [0.6935] (epoch [1/3])\n",
      "[46/801] train loss: [0.6820] (epoch [1/3])\n",
      "[47/801] train loss: [0.6793] (epoch [1/3])\n",
      "[48/801] train loss: [0.6909] (epoch [1/3])\n",
      "[49/801] train loss: [0.6772] (epoch [1/3])\n",
      "[50/801] train loss: [0.6699] (epoch [1/3])\n",
      "[51/801] train loss: [0.6958] (epoch [1/3])\n",
      "[52/801] train loss: [0.6783] (epoch [1/3])\n",
      "[53/801] train loss: [0.6733] (epoch [1/3])\n",
      "[54/801] train loss: [0.6801] (epoch [1/3])\n",
      "[55/801] train loss: [0.6648] (epoch [1/3])\n",
      "[56/801] train loss: [0.6390] (epoch [1/3])\n",
      "[57/801] train loss: [0.6863] (epoch [1/3])\n",
      "[58/801] train loss: [0.6791] (epoch [1/3])\n",
      "[59/801] train loss: [0.6563] (epoch [1/3])\n",
      "[60/801] train loss: [0.7171] (epoch [1/3])\n",
      "[61/801] train loss: [0.6958] (epoch [1/3])\n",
      "[62/801] train loss: [0.6571] (epoch [1/3])\n",
      "[63/801] train loss: [0.6276] (epoch [1/3])\n",
      "[64/801] train loss: [0.6826] (epoch [1/3])\n",
      "[65/801] train loss: [0.6822] (epoch [1/3])\n",
      "[66/801] train loss: [0.6744] (epoch [1/3])\n",
      "[67/801] train loss: [0.7091] (epoch [1/3])\n",
      "[68/801] train loss: [0.6650] (epoch [1/3])\n",
      "[69/801] train loss: [0.7008] (epoch [1/3])\n",
      "[70/801] train loss: [0.6962] (epoch [1/3])\n",
      "[71/801] train loss: [0.6698] (epoch [1/3])\n",
      "[72/801] train loss: [0.6467] (epoch [1/3])\n",
      "[73/801] train loss: [0.6353] (epoch [1/3])\n",
      "[74/801] train loss: [0.6338] (epoch [1/3])\n",
      "[75/801] train loss: [0.6694] (epoch [1/3])\n",
      "[76/801] train loss: [0.6997] (epoch [1/3])\n",
      "[77/801] train loss: [0.6777] (epoch [1/3])\n",
      "[78/801] train loss: [0.6556] (epoch [1/3])\n",
      "[79/801] train loss: [0.5700] (epoch [1/3])\n",
      "[80/801] train loss: [0.6347] (epoch [1/3])\n",
      "[81/801] train loss: [0.7155] (epoch [1/3])\n",
      "[82/801] train loss: [0.6760] (epoch [1/3])\n",
      "[83/801] train loss: [0.7713] (epoch [1/3])\n",
      "[84/801] train loss: [0.6468] (epoch [1/3])\n",
      "[85/801] train loss: [0.6342] (epoch [1/3])\n",
      "[86/801] train loss: [0.6221] (epoch [1/3])\n",
      "[87/801] train loss: [0.6420] (epoch [1/3])\n",
      "[88/801] train loss: [0.6906] (epoch [1/3])\n",
      "[89/801] train loss: [0.6093] (epoch [1/3])\n",
      "[90/801] train loss: [0.6608] (epoch [1/3])\n",
      "[91/801] train loss: [0.7264] (epoch [1/3])\n",
      "[92/801] train loss: [0.6245] (epoch [1/3])\n",
      "[93/801] train loss: [0.5922] (epoch [1/3])\n",
      "[94/801] train loss: [0.6508] (epoch [1/3])\n",
      "[95/801] train loss: [0.6466] (epoch [1/3])\n",
      "[96/801] train loss: [0.6063] (epoch [1/3])\n",
      "[97/801] train loss: [0.7133] (epoch [1/3])\n",
      "[98/801] train loss: [0.6753] (epoch [1/3])\n",
      "[99/801] train loss: [0.6441] (epoch [1/3])\n",
      "[100/801] train loss: [0.7015] (epoch [1/3])\n",
      "[100/801] validation loss: [0.6298] validation accuracy: [0.6735]\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "cls_model.to(device)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "step = 0\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "val_accs = []\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    \n",
    "    # train loop\n",
    "    for data in train_loader:\n",
    "        cls_model.train()\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attention_mask = data[\"attention_mask\"].to(device)\n",
    "        label = data[\"label\"].view(-1, 1).float().to(device)\n",
    "        \n",
    "        logits = cls_model.forward(input_ids, attention_mask)\n",
    "        \n",
    "        \n",
    "        loss = loss_fn.forward(\n",
    "            input = logits,\n",
    "            target = label\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clip (important for RNN, not necessary for LSTM/GRU/conv1d)\n",
    "        torch.nn.utils.clip_grad_norm_(cls_model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        optimizer.step() # update paramater\n",
    "        scheduler.step() \n",
    "        optimizer.zero_grad() # clear gradient\n",
    "        \n",
    "        vis_loss = loss.detach().cpu()\n",
    "        \n",
    "        print(f\"[{step + 1}/{num_training_steps}] train loss: [{vis_loss:.4f}] (epoch [{epoch + 1}/{num_train_epochs}])\")\n",
    "        \n",
    "        \n",
    "        train_losses.append(vis_loss)\n",
    "        i =0 \n",
    "\n",
    "        if (step + 1) % val_steps == 0 or step == 0:\n",
    "            # compute validation every \"val_steps\"\n",
    "           \n",
    "            cls_model.eval()\n",
    "            val_loss = compute_loss(val_loader)\n",
    "            val_acc = compute_accuracy(val_loader)\n",
    "            val_accs.append(val_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            print(f\"[{step + 1}/{num_training_steps}] validation loss: [{val_loss:.4f}] validation accuracy: [{val_acc:.4f}]\")\n",
    "            # Apply early stopping\n",
    "            should_stop, counter = early_stopping(vis_loss, val_loss, min_delta=0.01, tolerance=2, counter=counter)\n",
    "            if should_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    if should_stop:\n",
    "        break  # Exit e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial with params: (1, 128, 0.1, 0.0001, 128, 1.0, 1)\n",
      "  Validation Loss: 0.7194907665252686\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6794100403785706\n",
      "  Validation Accuracy: 0.5806754221388368\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.6822980046272278\n",
      "  Validation Accuracy: 0.574108818011257\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 128, 2.0, 1)\n",
      "  Validation Loss: 0.6995674967765808\n",
      "  Validation Accuracy: 0.5131332082551595\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.6873984336853027\n",
      "  Validation Accuracy: 0.573170731707317\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6906976699829102\n",
      "  Validation Accuracy: 0.5187617260787992\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 256, 1.0, 1)\n",
      "  Validation Loss: 0.6926606297492981\n",
      "  Validation Accuracy: 0.5121951219512195\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.6973957419395447\n",
      "  Validation Accuracy: 0.5084427767354597\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.6807047724723816\n",
      "  Validation Accuracy: 0.5928705440900562\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.6976694464683533\n",
      "  Validation Accuracy: 0.49437148217636023\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.6964069604873657\n",
      "  Validation Accuracy: 0.49906191369606\n",
      "Trial with params: (1, 128, 0.1, 0.0001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6865523457527161\n",
      "  Validation Accuracy: 0.575046904315197\n",
      "Trial with params: (1, 128, 0.1, 0.001, 128, 1.0, 1)\n",
      "  Validation Loss: 0.7356560826301575\n",
      "  Validation Accuracy: 0.4981238273921201\n",
      "Trial with params: (1, 128, 0.1, 0.001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6756705045700073\n",
      "  Validation Accuracy: 0.599437148217636\n",
      "Trial with params: (1, 128, 0.1, 0.001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.6639294624328613\n",
      "  Validation Accuracy: 0.6322701688555347\n",
      "Trial with params: (1, 128, 0.1, 0.001, 128, 2.0, 1)\n",
      "  Validation Loss: 0.7487958073616028\n",
      "  Validation Accuracy: 0.5028142589118199\n",
      "Trial with params: (1, 128, 0.1, 0.001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.660769522190094\n",
      "  Validation Accuracy: 0.6463414634146342\n",
      "Trial with params: (1, 128, 0.1, 0.001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6405077576637268\n",
      "  Validation Accuracy: 0.6622889305816135\n",
      "Trial with params: (1, 128, 0.1, 0.001, 256, 1.0, 1)\n",
      "  Validation Loss: 0.7031490206718445\n",
      "  Validation Accuracy: 0.49530956848030017\n",
      "Trial with params: (1, 128, 0.1, 0.001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.7099189758300781\n",
      "  Validation Accuracy: 0.5056285178236398\n",
      "Trial with params: (1, 128, 0.1, 0.001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.6533597111701965\n",
      "  Validation Accuracy: 0.6669793621013134\n",
      "Trial with params: (1, 128, 0.1, 0.001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.7597008347511292\n",
      "  Validation Accuracy: 0.4981238273921201\n",
      "Trial with params: (1, 128, 0.1, 0.001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.7696464657783508\n",
      "  Validation Accuracy: 0.50187617260788\n",
      "Trial with params: (1, 128, 0.1, 0.001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6506345272064209\n",
      "  Validation Accuracy: 0.6651031894934334\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 128, 1.0, 1)\n",
      "  Validation Loss: 0.6987679600715637\n",
      "  Validation Accuracy: 0.4981238273921201\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6890019178390503\n",
      "  Validation Accuracy: 0.5300187617260788\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.6888984441757202\n",
      "  Validation Accuracy: 0.5309568480300187\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 128, 2.0, 1)\n",
      "  Validation Loss: 0.7210870385169983\n",
      "  Validation Accuracy: 0.49530956848030017\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.6889761686325073\n",
      "  Validation Accuracy: 0.551594746716698\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6851328015327454\n",
      "  Validation Accuracy: 0.5712945590994372\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 256, 1.0, 1)\n",
      "  Validation Loss: 0.6994842886924744\n",
      "  Validation Accuracy: 0.49530956848030017\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.6989549994468689\n",
      "  Validation Accuracy: 0.49906191369606\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.690832257270813\n",
      "  Validation Accuracy: 0.5347091932457786\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.7379345893859863\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.7010629773139954\n",
      "  Validation Accuracy: 0.5046904315196998\n",
      "Trial with params: (1, 128, 0.2, 0.0001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6953726410865784\n",
      "  Validation Accuracy: 0.4878048780487805\n",
      "Trial with params: (1, 128, 0.2, 0.001, 128, 1.0, 1)\n",
      "  Validation Loss: 0.7468247413635254\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 128, 0.2, 0.001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6586976051330566\n",
      "  Validation Accuracy: 0.6594746716697936\n",
      "Trial with params: (1, 128, 0.2, 0.001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.6661453247070312\n",
      "  Validation Accuracy: 0.6322701688555347\n",
      "Trial with params: (1, 128, 0.2, 0.001, 128, 2.0, 1)\n",
      "  Validation Loss: 0.7490777969360352\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 128, 0.2, 0.001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.6661930680274963\n",
      "  Validation Accuracy: 0.6651031894934334\n",
      "Trial with params: (1, 128, 0.2, 0.001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6500566005706787\n",
      "  Validation Accuracy: 0.6697936210131332\n",
      "Trial with params: (1, 128, 0.2, 0.001, 256, 1.0, 1)\n",
      "  Validation Loss: 0.7882513999938965\n",
      "  Validation Accuracy: 0.4981238273921201\n",
      "Trial with params: (1, 128, 0.2, 0.001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.712997317314148\n",
      "  Validation Accuracy: 0.4981238273921201\n",
      "Trial with params: (1, 128, 0.2, 0.001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.5990719199180603\n",
      "  Validation Accuracy: 0.6941838649155723\n",
      "Trial with params: (1, 128, 0.2, 0.001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.7604289054870605\n",
      "  Validation Accuracy: 0.50187617260788\n",
      "Trial with params: (1, 128, 0.2, 0.001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.7444489598274231\n",
      "  Validation Accuracy: 0.49906191369606\n",
      "Trial with params: (1, 128, 0.2, 0.001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6571566462516785\n",
      "  Validation Accuracy: 0.6341463414634146\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 128, 1.0, 1)\n",
      "  Validation Loss: 0.6959035396575928\n",
      "  Validation Accuracy: 0.4924953095684803\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6768319010734558\n",
      "  Validation Accuracy: 0.624765478424015\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.678957462310791\n",
      "  Validation Accuracy: 0.5966228893058161\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 128, 2.0, 1)\n",
      "  Validation Loss: 0.7060323357582092\n",
      "  Validation Accuracy: 0.49437148217636023\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.6790783405303955\n",
      "  Validation Accuracy: 0.6088180112570356\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6701207756996155\n",
      "  Validation Accuracy: 0.6219512195121951\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 256, 1.0, 1)\n",
      "  Validation Loss: 0.7045843005180359\n",
      "  Validation Accuracy: 0.4981238273921201\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.6897789835929871\n",
      "  Validation Accuracy: 0.5150093808630394\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.6762934327125549\n",
      "  Validation Accuracy: 0.5872420262664165\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.6945714354515076\n",
      "  Validation Accuracy: 0.5056285178236398\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.7036483287811279\n",
      "  Validation Accuracy: 0.43902439024390244\n",
      "Trial with params: (1, 256, 0.1, 0.0001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6838571429252625\n",
      "  Validation Accuracy: 0.5787992495309568\n",
      "Trial with params: (1, 256, 0.1, 0.001, 128, 1.0, 1)\n",
      "  Validation Loss: 1.2881399393081665\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 256, 0.1, 0.001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6043981909751892\n",
      "  Validation Accuracy: 0.6669793621013134\n",
      "Trial with params: (1, 256, 0.1, 0.001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.6478614211082458\n",
      "  Validation Accuracy: 0.6632270168855535\n",
      "Trial with params: (1, 256, 0.1, 0.001, 128, 2.0, 1)\n",
      "  Validation Loss: 1.2425661087036133\n",
      "  Validation Accuracy: 0.49906191369606\n",
      "Trial with params: (1, 256, 0.1, 0.001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.6053301692008972\n",
      "  Validation Accuracy: 0.6876172607879925\n",
      "Trial with params: (1, 256, 0.1, 0.001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6263928413391113\n",
      "  Validation Accuracy: 0.6791744840525328\n",
      "Trial with params: (1, 256, 0.1, 0.001, 256, 1.0, 1)\n",
      "  Validation Loss: 1.0378824472427368\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 256, 0.1, 0.001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.7831649780273438\n",
      "  Validation Accuracy: 0.50187617260788\n",
      "Trial with params: (1, 256, 0.1, 0.001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.6400158405303955\n",
      "  Validation Accuracy: 0.6744840525328331\n",
      "Trial with params: (1, 256, 0.1, 0.001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.9902634620666504\n",
      "  Validation Accuracy: 0.50093808630394\n",
      "Trial with params: (1, 256, 0.1, 0.001, 256, 2.0, 2)\n",
      "  Validation Loss: 1.1875653266906738\n",
      "  Validation Accuracy: 0.50093808630394\n",
      "Trial with params: (1, 256, 0.1, 0.001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6477215886116028\n",
      "  Validation Accuracy: 0.6801125703564728\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 128, 1.0, 1)\n",
      "  Validation Loss: 0.6970764994621277\n",
      "  Validation Accuracy: 0.5056285178236398\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6862980127334595\n",
      "  Validation Accuracy: 0.5572232645403377\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.6744676828384399\n",
      "  Validation Accuracy: 0.6210131332082551\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 128, 2.0, 1)\n",
      "  Validation Loss: 0.706299901008606\n",
      "  Validation Accuracy: 0.50187617260788\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.6819907426834106\n",
      "  Validation Accuracy: 0.5806754221388368\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6782747507095337\n",
      "  Validation Accuracy: 0.6060037523452158\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 256, 1.0, 1)\n",
      "  Validation Loss: 0.6983484029769897\n",
      "  Validation Accuracy: 0.48686679174484054\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 256, 1.0, 2)\n",
      "  Validation Loss: 0.6966041326522827\n",
      "  Validation Accuracy: 0.49906191369606\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.6692081689834595\n",
      "  Validation Accuracy: 0.6116322701688556\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.7194564342498779\n",
      "  Validation Accuracy: 0.49624765478424016\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.6918962001800537\n",
      "  Validation Accuracy: 0.5215759849906192\n",
      "Trial with params: (1, 256, 0.2, 0.0001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6684404611587524\n",
      "  Validation Accuracy: 0.6360225140712945\n",
      "Trial with params: (1, 256, 0.2, 0.001, 128, 1.0, 1)\n",
      "  Validation Loss: 1.027324914932251\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 256, 0.2, 0.001, 128, 1.0, 2)\n",
      "  Validation Loss: 0.6538159847259521\n",
      "  Validation Accuracy: 0.6679174484052532\n",
      "Trial with params: (1, 256, 0.2, 0.001, 128, 1.0, 3)\n",
      "  Validation Loss: 0.641628086566925\n",
      "  Validation Accuracy: 0.6557223264540337\n",
      "Trial with params: (1, 256, 0.2, 0.001, 128, 2.0, 1)\n",
      "  Validation Loss: 1.1794776916503906\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 256, 0.2, 0.001, 128, 2.0, 2)\n",
      "  Validation Loss: 0.672248363494873\n",
      "  Validation Accuracy: 0.6416510318949343\n",
      "Trial with params: (1, 256, 0.2, 0.001, 128, 2.0, 3)\n",
      "  Validation Loss: 0.6422895789146423\n",
      "  Validation Accuracy: 0.6726078799249531\n",
      "Trial with params: (1, 256, 0.2, 0.001, 256, 1.0, 1)\n",
      "  Validation Loss: 1.054785132408142\n",
      "  Validation Accuracy: 0.5\n",
      "Trial with params: (1, 256, 0.2, 0.001, 256, 1.0, 2)\n",
      "  Validation Loss: 1.131801962852478\n",
      "  Validation Accuracy: 0.50093808630394\n",
      "Trial with params: (1, 256, 0.2, 0.001, 256, 1.0, 3)\n",
      "  Validation Loss: 0.5871635675430298\n",
      "  Validation Accuracy: 0.6969981238273921\n",
      "Trial with params: (1, 256, 0.2, 0.001, 256, 2.0, 1)\n",
      "  Validation Loss: 0.9439867734909058\n",
      "  Validation Accuracy: 0.50093808630394\n",
      "Trial with params: (1, 256, 0.2, 0.001, 256, 2.0, 2)\n",
      "  Validation Loss: 0.9445580840110779\n",
      "  Validation Accuracy: 0.49906191369606\n",
      "Trial with params: (1, 256, 0.2, 0.001, 256, 2.0, 3)\n",
      "  Validation Loss: 0.6573008298873901\n",
      "  Validation Accuracy: 0.6632270168855535\n",
      "Best result:\n",
      "  Validation Loss: 0.5871635675430298\n",
      "  Validation Accuracy: 0.6969981238273921\n",
      "  Best hyperparameters: (1, 256, 0.2, 0.001, 256, 1.0, 3)\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# Define hyperparameter ranges\n",
    "param_grid = {\n",
    "    \"num_rnn_layer\": range(1, 2),  # Integer range for number of RNN layers\n",
    "    \"hidden_dim\": [128, 256],  # Integer range for hidden dimension size\n",
    "    \"dropout_rate\": [0.1, 0.2],  # Continuous range for dropout rate\n",
    "    \"learning_rate\": [1e-4, 1e-3],  # Continuous range for learning rate\n",
    "    \"batch_size\": [128, 256],  # Integer range for batch size\n",
    "    \"max_grad_norm\": [1.0, 2.0],  # Continuous range for gradient clipping\n",
    "    \"num_train_epochs\": [1,2,3]  # Integer range for number of training epochs\n",
    "}\n",
    "\n",
    "# Track the best configuration\n",
    "best_val_loss = float('inf')\n",
    "best_val_accuracy = 0.0\n",
    "best_params = None\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "for params in itertools.product(\n",
    "    param_grid[\"num_rnn_layer\"],\n",
    "    param_grid[\"hidden_dim\"],\n",
    "    param_grid[\"dropout_rate\"],\n",
    "    param_grid[\"learning_rate\"],\n",
    "    param_grid[\"batch_size\"],\n",
    "    param_grid[\"max_grad_norm\"],\n",
    "    param_grid[\"num_train_epochs\"]\n",
    "):\n",
    "    # Unpack hyperparameters\n",
    "    num_rnn_layer, hidden_dim, dropout_rate, learning_rate, batch_size, max_grad_norm, num_train_epochs = params\n",
    "    \n",
    "    # Initialize model with current parameters\n",
    "    cls_model = SentimentRNN(\n",
    "        embedding=embedding,\n",
    "        hidden_size=hidden_dim,\n",
    "        embed_size=EMBED_DIM,\n",
    "        bidirectional=False,\n",
    "        num_rnn_layer=num_rnn_layer,\n",
    "        dropout_rate=dropout_rate,\n",
    "        layer_norm=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Set up optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(cls_model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    \n",
    "    # DataLoader for selected batch size\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Early stopping and metrics tracking variables\n",
    "    counter = 0\n",
    "    step = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    should_stop = False\n",
    "    early_stopped = False  # Flag to indicate early stopping for this trial\n",
    "    \n",
    "    for epoch in range(num_train_epochs):\n",
    "        # Training loop\n",
    "        for data in train_loader:\n",
    "            cls_model.train()\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            label = data[\"label\"].view(-1, 1).float().to(device)\n",
    "            \n",
    "            logits = cls_model(input_ids, attention_mask)\n",
    "            \n",
    "            loss = loss_fn(input=logits, target=label)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(cls_model.parameters(), max_norm=max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            vis_loss = loss.detach().cpu().item()\n",
    "            train_losses.append(vis_loss)\n",
    "            \n",
    "            # Validation step every `val_steps`\n",
    "            if (step + 1) % val_steps == 0 or step == 0:\n",
    "                cls_model.eval()\n",
    "                val_loss = compute_loss(val_loader)\n",
    "                val_acc = compute_accuracy(val_loader)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_acc)\n",
    "                \n",
    "                # Early stopping check\n",
    "                should_stop, counter = early_stopping(vis_loss, val_loss, min_delta=0.5, tolerance=2, counter=counter)\n",
    "                if should_stop:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    early_stopped = True  # Mark this trial as early stopped\n",
    "                    break\n",
    "\n",
    "            step += 1\n",
    "        \n",
    "        if should_stop:\n",
    "            break  # Exit epoch loop if early stopping is triggered\n",
    "\n",
    "    # Track the best parameters and validation loss\n",
    "    current_val_loss = val_losses[-1] if val_losses else float('inf')\n",
    "    current_val_accuracy = val_accs[-1] if val_accs else 0.0\n",
    "    if current_val_accuracy > best_val_accuracy and early_stopped==False:\n",
    "        best_val_loss = current_val_loss\n",
    "        best_val_accuracy = current_val_accuracy\n",
    "        best_params = params\n",
    "    \n",
    "    # Print the trial's results, including early stopping info\n",
    "    print(f\"Trial with params: {params}\")\n",
    "    print(f\"  Validation Loss: {current_val_loss}\")\n",
    "    print(f\"  Validation Accuracy: {current_val_accuracy}\")\n",
    "    if early_stopped:\n",
    "        print(\"  Early stopped\")\n",
    "    \n",
    "\n",
    "# Print the best result\n",
    "print(\"Best result:\")\n",
    "print(f\"  Validation Loss: {best_val_loss}\")\n",
    "print(f\"  Validation Accuracy: {best_val_accuracy}\")\n",
    "print(\"  Best hyperparameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 0.2, 0.001, 256, 1.0, 3)\n"
     ]
    }
   ],
   "source": [
    "## (1, 256, 0.2, 0.001, 128, 2.0, 3)--> higest accuracy\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:102, warm up: 10\n"
     ]
    }
   ],
   "source": [
    "val_steps = 100\n",
    "batch_size = 128\n",
    "dropout_rate = 0.2\n",
    "hidden_dim = 258\n",
    "learning_rate = 0.001\n",
    "num_rnn_layer = 1\n",
    "max_grad_norm = 2.0\n",
    "num_train_epochs = 3\n",
    "\n",
    "num_training_steps = num_train_epochs * len(train_loader)\n",
    "num_warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "print(f\"train:{num_training_steps}, warm up: {num_warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/102] train loss: [0.6976] (epoch [1/3])\n",
      "[1/102] validation loss: [1.1582] validation accuracy: [0.5009]\n",
      "[2/102] train loss: [1.0857] (epoch [1/3])\n",
      "[3/102] train loss: [0.8530] (epoch [1/3])\n",
      "[4/102] train loss: [0.7028] (epoch [1/3])\n",
      "[5/102] train loss: [0.6900] (epoch [1/3])\n",
      "[6/102] train loss: [0.7248] (epoch [1/3])\n",
      "[7/102] train loss: [0.7236] (epoch [1/3])\n",
      "[8/102] train loss: [0.6882] (epoch [1/3])\n",
      "[9/102] train loss: [0.6873] (epoch [1/3])\n",
      "[10/102] train loss: [0.6870] (epoch [1/3])\n",
      "[11/102] train loss: [0.6892] (epoch [1/3])\n",
      "[12/102] train loss: [0.6846] (epoch [1/3])\n",
      "[13/102] train loss: [0.7140] (epoch [1/3])\n",
      "[14/102] train loss: [0.6715] (epoch [1/3])\n",
      "[15/102] train loss: [0.6771] (epoch [1/3])\n",
      "[16/102] train loss: [0.6850] (epoch [1/3])\n",
      "[17/102] train loss: [0.6765] (epoch [1/3])\n",
      "[18/102] train loss: [0.6770] (epoch [1/3])\n",
      "[19/102] train loss: [0.6711] (epoch [1/3])\n",
      "[20/102] train loss: [0.6846] (epoch [1/3])\n",
      "[21/102] train loss: [0.6742] (epoch [1/3])\n",
      "[22/102] train loss: [0.6635] (epoch [1/3])\n",
      "[23/102] train loss: [0.6725] (epoch [1/3])\n",
      "[24/102] train loss: [0.6758] (epoch [1/3])\n",
      "[25/102] train loss: [0.6754] (epoch [1/3])\n",
      "[26/102] train loss: [0.6706] (epoch [1/3])\n",
      "[27/102] train loss: [0.6772] (epoch [1/3])\n",
      "[28/102] train loss: [0.6677] (epoch [1/3])\n",
      "[29/102] train loss: [0.6639] (epoch [1/3])\n",
      "[30/102] train loss: [0.6734] (epoch [1/3])\n",
      "[31/102] train loss: [0.6692] (epoch [1/3])\n",
      "[32/102] train loss: [0.6623] (epoch [1/3])\n",
      "[33/102] train loss: [0.6691] (epoch [1/3])\n",
      "[34/102] train loss: [0.6696] (epoch [1/3])\n",
      "[35/102] train loss: [0.6741] (epoch [1/3])\n",
      "[36/102] train loss: [0.6699] (epoch [1/3])\n",
      "[37/102] train loss: [0.6655] (epoch [1/3])\n",
      "[38/102] train loss: [0.6708] (epoch [1/3])\n",
      "[39/102] train loss: [0.6676] (epoch [1/3])\n",
      "[40/102] train loss: [0.6596] (epoch [1/3])\n",
      "[41/102] train loss: [0.6608] (epoch [1/3])\n",
      "[42/102] train loss: [0.6940] (epoch [1/3])\n",
      "[43/102] train loss: [0.6702] (epoch [1/3])\n",
      "[44/102] train loss: [0.6765] (epoch [1/3])\n",
      "[45/102] train loss: [0.6650] (epoch [1/3])\n",
      "[46/102] train loss: [0.6543] (epoch [1/3])\n",
      "[47/102] train loss: [0.6697] (epoch [1/3])\n",
      "[48/102] train loss: [0.6711] (epoch [1/3])\n",
      "[49/102] train loss: [0.6645] (epoch [1/3])\n",
      "[50/102] train loss: [0.6747] (epoch [1/3])\n",
      "[51/102] train loss: [0.6680] (epoch [1/3])\n",
      "[52/102] train loss: [0.6585] (epoch [1/3])\n",
      "[53/102] train loss: [0.6618] (epoch [1/3])\n",
      "[54/102] train loss: [0.6704] (epoch [1/3])\n",
      "[55/102] train loss: [0.6716] (epoch [1/3])\n",
      "[56/102] train loss: [0.6684] (epoch [1/3])\n",
      "[57/102] train loss: [0.6651] (epoch [1/3])\n",
      "[58/102] train loss: [0.6727] (epoch [1/3])\n",
      "[59/102] train loss: [0.6804] (epoch [1/3])\n",
      "[60/102] train loss: [0.6687] (epoch [1/3])\n",
      "[61/102] train loss: [0.6650] (epoch [1/3])\n",
      "[62/102] train loss: [0.6633] (epoch [1/3])\n",
      "[63/102] train loss: [0.6737] (epoch [1/3])\n",
      "[64/102] train loss: [0.6767] (epoch [1/3])\n",
      "[65/102] train loss: [0.6604] (epoch [1/3])\n",
      "[66/102] train loss: [0.6673] (epoch [1/3])\n",
      "[67/102] train loss: [0.6459] (epoch [1/3])\n",
      "[68/102] train loss: [0.6665] (epoch [2/3])\n",
      "[69/102] train loss: [0.6544] (epoch [2/3])\n",
      "[70/102] train loss: [0.6692] (epoch [2/3])\n",
      "[71/102] train loss: [0.6636] (epoch [2/3])\n",
      "[72/102] train loss: [0.6723] (epoch [2/3])\n",
      "[73/102] train loss: [0.6590] (epoch [2/3])\n",
      "[74/102] train loss: [0.6657] (epoch [2/3])\n",
      "[75/102] train loss: [0.6656] (epoch [2/3])\n",
      "[76/102] train loss: [0.6737] (epoch [2/3])\n",
      "[77/102] train loss: [0.6774] (epoch [2/3])\n",
      "[78/102] train loss: [0.6717] (epoch [2/3])\n",
      "[79/102] train loss: [0.6691] (epoch [2/3])\n",
      "[80/102] train loss: [0.6633] (epoch [2/3])\n",
      "[81/102] train loss: [0.6763] (epoch [2/3])\n",
      "[82/102] train loss: [0.6758] (epoch [2/3])\n",
      "[83/102] train loss: [0.6639] (epoch [2/3])\n",
      "[84/102] train loss: [0.6507] (epoch [2/3])\n",
      "[85/102] train loss: [0.6668] (epoch [2/3])\n",
      "[86/102] train loss: [0.6465] (epoch [2/3])\n",
      "[87/102] train loss: [0.6605] (epoch [2/3])\n",
      "[88/102] train loss: [0.6607] (epoch [2/3])\n",
      "[89/102] train loss: [0.6660] (epoch [2/3])\n",
      "[90/102] train loss: [0.6646] (epoch [2/3])\n",
      "[91/102] train loss: [0.6649] (epoch [2/3])\n",
      "[92/102] train loss: [0.6584] (epoch [2/3])\n",
      "[93/102] train loss: [0.6663] (epoch [2/3])\n",
      "[94/102] train loss: [0.6622] (epoch [2/3])\n",
      "[95/102] train loss: [0.6668] (epoch [2/3])\n",
      "[96/102] train loss: [0.6618] (epoch [2/3])\n",
      "[97/102] train loss: [0.6566] (epoch [2/3])\n",
      "[98/102] train loss: [0.6604] (epoch [2/3])\n",
      "[99/102] train loss: [0.6547] (epoch [2/3])\n",
      "[100/102] train loss: [0.6723] (epoch [2/3])\n",
      "[100/102] validation loss: [0.6657] validation accuracy: [0.6660]\n",
      "[101/102] train loss: [0.6633] (epoch [2/3])\n",
      "[102/102] train loss: [0.6612] (epoch [2/3])\n",
      "[103/102] train loss: [0.6808] (epoch [2/3])\n",
      "[104/102] train loss: [0.6680] (epoch [2/3])\n",
      "[105/102] train loss: [0.6772] (epoch [2/3])\n",
      "[106/102] train loss: [0.6608] (epoch [2/3])\n",
      "[107/102] train loss: [0.6798] (epoch [2/3])\n",
      "[108/102] train loss: [0.6710] (epoch [2/3])\n",
      "[109/102] train loss: [0.6686] (epoch [2/3])\n",
      "[110/102] train loss: [0.6750] (epoch [2/3])\n",
      "[111/102] train loss: [0.6489] (epoch [2/3])\n",
      "[112/102] train loss: [0.6757] (epoch [2/3])\n",
      "[113/102] train loss: [0.6599] (epoch [2/3])\n",
      "[114/102] train loss: [0.6721] (epoch [2/3])\n",
      "[115/102] train loss: [0.6634] (epoch [2/3])\n",
      "[116/102] train loss: [0.6520] (epoch [2/3])\n",
      "[117/102] train loss: [0.6712] (epoch [2/3])\n",
      "[118/102] train loss: [0.6700] (epoch [2/3])\n",
      "[119/102] train loss: [0.6584] (epoch [2/3])\n",
      "[120/102] train loss: [0.6598] (epoch [2/3])\n",
      "[121/102] train loss: [0.6595] (epoch [2/3])\n",
      "[122/102] train loss: [0.6697] (epoch [2/3])\n",
      "[123/102] train loss: [0.6695] (epoch [2/3])\n",
      "[124/102] train loss: [0.6717] (epoch [2/3])\n",
      "[125/102] train loss: [0.6725] (epoch [2/3])\n",
      "[126/102] train loss: [0.6664] (epoch [2/3])\n",
      "[127/102] train loss: [0.6803] (epoch [2/3])\n",
      "[128/102] train loss: [0.6683] (epoch [2/3])\n",
      "[129/102] train loss: [0.6511] (epoch [2/3])\n",
      "[130/102] train loss: [0.6731] (epoch [2/3])\n",
      "[131/102] train loss: [0.6645] (epoch [2/3])\n",
      "[132/102] train loss: [0.6692] (epoch [2/3])\n",
      "[133/102] train loss: [0.6613] (epoch [2/3])\n",
      "[134/102] train loss: [0.6617] (epoch [2/3])\n",
      "[135/102] train loss: [0.6702] (epoch [3/3])\n",
      "[136/102] train loss: [0.6675] (epoch [3/3])\n",
      "[137/102] train loss: [0.6569] (epoch [3/3])\n",
      "[138/102] train loss: [0.6728] (epoch [3/3])\n",
      "[139/102] train loss: [0.6687] (epoch [3/3])\n",
      "[140/102] train loss: [0.6743] (epoch [3/3])\n",
      "[141/102] train loss: [0.6653] (epoch [3/3])\n",
      "[142/102] train loss: [0.6812] (epoch [3/3])\n",
      "[143/102] train loss: [0.6673] (epoch [3/3])\n",
      "[144/102] train loss: [0.6630] (epoch [3/3])\n",
      "[145/102] train loss: [0.6690] (epoch [3/3])\n",
      "[146/102] train loss: [0.6641] (epoch [3/3])\n",
      "[147/102] train loss: [0.6644] (epoch [3/3])\n",
      "[148/102] train loss: [0.6716] (epoch [3/3])\n",
      "[149/102] train loss: [0.6758] (epoch [3/3])\n",
      "[150/102] train loss: [0.6645] (epoch [3/3])\n",
      "[151/102] train loss: [0.6495] (epoch [3/3])\n",
      "[152/102] train loss: [0.6699] (epoch [3/3])\n",
      "[153/102] train loss: [0.6677] (epoch [3/3])\n",
      "[154/102] train loss: [0.6515] (epoch [3/3])\n",
      "[155/102] train loss: [0.6688] (epoch [3/3])\n",
      "[156/102] train loss: [0.6732] (epoch [3/3])\n",
      "[157/102] train loss: [0.6791] (epoch [3/3])\n",
      "[158/102] train loss: [0.6615] (epoch [3/3])\n",
      "[159/102] train loss: [0.6519] (epoch [3/3])\n",
      "[160/102] train loss: [0.6547] (epoch [3/3])\n",
      "[161/102] train loss: [0.6740] (epoch [3/3])\n",
      "[162/102] train loss: [0.6746] (epoch [3/3])\n",
      "[163/102] train loss: [0.6692] (epoch [3/3])\n",
      "[164/102] train loss: [0.6658] (epoch [3/3])\n",
      "[165/102] train loss: [0.6605] (epoch [3/3])\n",
      "[166/102] train loss: [0.6529] (epoch [3/3])\n",
      "[167/102] train loss: [0.6609] (epoch [3/3])\n",
      "[168/102] train loss: [0.6576] (epoch [3/3])\n",
      "[169/102] train loss: [0.6715] (epoch [3/3])\n",
      "[170/102] train loss: [0.6710] (epoch [3/3])\n",
      "[171/102] train loss: [0.6658] (epoch [3/3])\n",
      "[172/102] train loss: [0.6603] (epoch [3/3])\n",
      "[173/102] train loss: [0.6883] (epoch [3/3])\n",
      "[174/102] train loss: [0.6605] (epoch [3/3])\n",
      "[175/102] train loss: [0.6649] (epoch [3/3])\n",
      "[176/102] train loss: [0.6720] (epoch [3/3])\n",
      "[177/102] train loss: [0.6593] (epoch [3/3])\n",
      "[178/102] train loss: [0.6650] (epoch [3/3])\n",
      "[179/102] train loss: [0.6611] (epoch [3/3])\n",
      "[180/102] train loss: [0.6717] (epoch [3/3])\n",
      "[181/102] train loss: [0.6545] (epoch [3/3])\n",
      "[182/102] train loss: [0.6778] (epoch [3/3])\n",
      "[183/102] train loss: [0.6690] (epoch [3/3])\n",
      "[184/102] train loss: [0.6651] (epoch [3/3])\n",
      "[185/102] train loss: [0.6594] (epoch [3/3])\n",
      "[186/102] train loss: [0.6500] (epoch [3/3])\n",
      "[187/102] train loss: [0.6701] (epoch [3/3])\n",
      "[188/102] train loss: [0.6776] (epoch [3/3])\n",
      "[189/102] train loss: [0.6548] (epoch [3/3])\n",
      "[190/102] train loss: [0.6764] (epoch [3/3])\n",
      "[191/102] train loss: [0.6721] (epoch [3/3])\n",
      "[192/102] train loss: [0.6658] (epoch [3/3])\n",
      "[193/102] train loss: [0.6614] (epoch [3/3])\n",
      "[194/102] train loss: [0.6522] (epoch [3/3])\n",
      "[195/102] train loss: [0.6639] (epoch [3/3])\n",
      "[196/102] train loss: [0.6727] (epoch [3/3])\n",
      "[197/102] train loss: [0.6656] (epoch [3/3])\n",
      "[198/102] train loss: [0.6831] (epoch [3/3])\n",
      "[199/102] train loss: [0.6623] (epoch [3/3])\n",
      "[200/102] train loss: [0.6642] (epoch [3/3])\n",
      "[200/102] validation loss: [0.6657] validation accuracy: [0.6660]\n",
      "[201/102] train loss: [0.6564] (epoch [3/3])\n"
     ]
    }
   ],
   "source": [
    "cls_model = SentimentRNN(\n",
    "    embedding=embedding,\n",
    "    hidden_size=hidden_dim,\n",
    "    embed_size=EMBED_DIM,\n",
    "    bidirectional=False,  # False for part 2\n",
    "    num_rnn_layer=num_rnn_layer,\n",
    "    dropout_rate=dropout_rate,\n",
    "    layer_norm=True\n",
    ").to(device)\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(cls_model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "step = 0\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "val_accs = []\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    \n",
    "    # train loop\n",
    "    for data in train_loader:\n",
    "        cls_model.train()\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attention_mask = data[\"attention_mask\"].to(device)\n",
    "        label = data[\"label\"].view(-1, 1).float().to(device)\n",
    "        \n",
    "        logits = cls_model.forward(input_ids, attention_mask)\n",
    "        \n",
    "        \n",
    "        loss = loss_fn.forward(\n",
    "            input = logits,\n",
    "            target = label\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clip (important for RNN, not necessary for LSTM/GRU/conv1d)\n",
    "        torch.nn.utils.clip_grad_norm_(cls_model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        optimizer.step() # update paramater\n",
    "        scheduler.step() \n",
    "        optimizer.zero_grad() # clear gradient\n",
    "        \n",
    "        vis_loss = loss.detach().cpu()\n",
    "        \n",
    "        print(f\"[{step + 1}/{num_training_steps}] train loss: [{vis_loss:.4f}] (epoch [{epoch + 1}/{num_train_epochs}])\")\n",
    "        \n",
    "        \n",
    "        train_losses.append(vis_loss)\n",
    "        i =0 \n",
    "\n",
    "        if (step + 1) % val_steps == 0 or step == 0:\n",
    "            # compute validation every \"val_steps\"\n",
    "           \n",
    "            cls_model.eval()\n",
    "            val_loss = compute_loss(val_loader)\n",
    "            val_acc = compute_accuracy(val_loader)\n",
    "            val_accs.append(val_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            print(f\"[{step + 1}/{num_training_steps}] validation loss: [{val_loss:.4f}] validation accuracy: [{val_acc:.4f}]\")\n",
    "            # Apply early stopping\n",
    "            should_stop, counter = early_stopping(vis_loss, val_loss, min_delta=0.5, tolerance=2, counter=counter)\n",
    "            if should_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    if should_stop:\n",
    "        break  # Exit e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: [1.3063]\n",
      "Train accuracy: [0.6694]\n",
      "Test Loss: [0.6645]\n",
      "Test accuracy: [0.6492]\n",
      "Validation Loss: [0.6657]\n",
      "Validation accuracy: [0.6660]\n"
     ]
    }
   ],
   "source": [
    "train_loss = compute_loss(train_loader)\n",
    "train_acc = compute_accuracy(train_loader)\n",
    "test_loss = compute_loss(test_loader)\n",
    "test_acc = compute_accuracy(test_loader)\n",
    "val_loss = compute_loss(val_loader)\n",
    "test_acc = compute_accuracy(test_loader)\n",
    "\n",
    "print(f\"Train Loss: [{train_loss:.4f}]\\nTrain accuracy: [{train_acc:.4f}]\")\n",
    "print(f\"Test Loss: [{test_loss:.4f}]\\nTest accuracy: [{test_acc:.4f}]\")\n",
    "print(f\"Validation Loss: [{val_loss:.4f}]\\nValidation accuracy: [{val_acc:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions and labels for confusion matrix computing\n",
    "def compute_pedictions_and_labels(\n",
    "        model : nn.Module, \n",
    "        test_loader : DataLoader, \n",
    "        device : torch.device\n",
    "    ) -> tuple:\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Lists to store all predictions and actual labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            labels = data[\"label\"].view(-1, 1).float().to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "     \n",
    "            predictions = (logits > 0).long()\n",
    "            \n",
    "            all_predictions.extend(predictions.view(-1).cpu().numpy())\n",
    "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
    "    \n",
    "    return all_predictions, all_labels\n",
    "\n",
    "all_predictions, all_labels = compute_pedictions_and_labels(cls_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization 2: confusion matrix\n",
    "\n",
    "def plot_confusion(\n",
    "        all_predictions : list, \n",
    "        all_labels : list\n",
    "    ) -> None:      \n",
    "            \n",
    "    cm = confusion_matrix(all_labels, all_predictions) # from sklearn\n",
    "            \n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', linewidths=0.2, cmap=\"YlGnBu\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "    plt.yticks([0.5, 1.5], ['Negative', 'Positive'], va='center')\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion(all_predictions, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "class BaseSentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Base RNN class for sentiment classification with different sentence representation methods.\n",
    "    This serves as the foundation for different representation strategies.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedding, \n",
    "        hidden_size=256, \n",
    "        embed_size=100,\n",
    "        num_rnn_layer=1,\n",
    "        dropout_rate=0.2,\n",
    "        layer_norm=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(\n",
    "            embed_size,\n",
    "            hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=num_rnn_layer,\n",
    "            dropout=dropout_rate if num_rnn_layer > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Output layers with layer normalization option\n",
    "        if layer_norm:\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.LayerNorm(hidden_size),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.LayerNorm(hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        raise NotImplementedError(\"Each representation method must implement its own forward pass\")\n",
    "\n",
    "class LastHiddenStateRNN(BaseSentimentRNN):\n",
    "    \"\"\"\n",
    "    Uses the last hidden state of the RNN as sentence representation.\n",
    "    Theoretical justification: The last hidden state contains information about the entire sequence\n",
    "    with more emphasis on recent tokens, which can be beneficial for sentiment analysis.\n",
    "    \"\"\"\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        \n",
    "        # Get the last non-padded position for each sequence\n",
    "        last_positions = attention_mask.sum(1) - 1\n",
    "        batch_size = output.size(0)\n",
    "        \n",
    "        # Select the last hidden state for each sequence\n",
    "        last_hidden = output[torch.arange(batch_size), last_positions]\n",
    "        return self.output_layer(last_hidden)\n",
    "\n",
    "class MeanPoolingRNN(BaseSentimentRNN):\n",
    "    \"\"\"\n",
    "    Uses mean pooling over all hidden states as sentence representation.\n",
    "    Theoretical justification: Averaging all hidden states gives equal importance to all words,\n",
    "    which can be beneficial when sentiment is distributed throughout the sentence.\n",
    "    \"\"\"\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        \n",
    "        # Apply attention mask and compute mean\n",
    "        attention_mask = attention_mask.unsqueeze(-1)\n",
    "        masked_output = output * attention_mask\n",
    "        summed = masked_output.sum(dim=1)\n",
    "        lengths = attention_mask.sum(dim=1)\n",
    "        mean_pooled = summed / lengths\n",
    "        \n",
    "        return self.output_layer(mean_pooled)\n",
    "\n",
    "class MaxPoolingRNN(BaseSentimentRNN):\n",
    "    \"\"\"\n",
    "    Uses max pooling over all hidden states as sentence representation.\n",
    "    Theoretical justification: Max pooling captures the most salient features from each dimension,\n",
    "    which can be effective for detecting strong sentiment signals regardless of position.\n",
    "    \"\"\"\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        \n",
    "        # Apply attention mask and compute max\n",
    "        attention_mask = attention_mask.unsqueeze(-1)\n",
    "        masked_output = output * attention_mask\n",
    "        max_pooled = torch.max(masked_output, dim=1)[0]\n",
    "        \n",
    "        return self.output_layer(max_pooled)\n",
    "\n",
    "class AttentionRNN(BaseSentimentRNN):\n",
    "    \"\"\"\n",
    "    Uses attention mechanism to weight different hidden states.\n",
    "    Theoretical justification: Attention allows the model to focus on the most relevant parts\n",
    "    of the sentence for sentiment classification, learning which words are more important.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.attention = nn.Linear(kwargs.get('hidden_size', 256), 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        attention_weights = self.attention(output)\n",
    "        attention_weights = attention_weights.squeeze(-1)\n",
    "        \n",
    "        # Mask padding tokens\n",
    "        attention_weights = attention_weights.masked_fill(~attention_mask.bool(), float('-inf'))\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)\n",
    "        \n",
    "        # Apply attention weights\n",
    "        attention_weights = attention_weights.unsqueeze(-1)\n",
    "        weighted_sum = (output * attention_weights).sum(dim=1)\n",
    "        \n",
    "        return self.output_layer(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModelEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding,\n",
    "        device,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        config\n",
    "    ):\n",
    "        self.embedding = embedding\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.config = config\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.results = {}\n",
    "\n",
    "    def train_model(self, model_class, model_name):\n",
    "        \"\"\"\n",
    "        Trains a single model with the specified configuration\n",
    "        \"\"\"\n",
    "        print(f\"\\nTraining {model_name} Model...\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = model_class(\n",
    "            embedding=self.embedding,\n",
    "            hidden_size=self.config['hidden_size'],\n",
    "            embed_size=self.config['embed_size'],\n",
    "            num_rnn_layer=self.config['num_rnn_layer'],\n",
    "            dropout_rate=self.config['dropout_rate'],\n",
    "            layer_norm=self.config['layer_norm']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.config['learning_rate']\n",
    "        )\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        best_model_state = None\n",
    "        train_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for epoch in range(self.config['num_train_epochs']):\n",
    "            model.train()\n",
    "            epoch_losses = []\n",
    "            \n",
    "            for step, batch in enumerate(self.train_loader):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"label\"].view(-1, 1).float().to(self.device)\n",
    "                \n",
    "                logits = model(input_ids, attention_mask)\n",
    "                loss = self.loss_fn(logits, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(),\n",
    "                    self.config['max_grad_norm']\n",
    "                )\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                epoch_losses.append(loss.item())\n",
    "                \n",
    "                if (step + 1) % self.config['val_steps'] == 0:\n",
    "                    val_acc = self.compute_accuracy(model, self.val_loader)\n",
    "                    val_accuracies.append(val_acc)\n",
    "                    print(f\"Epoch {epoch+1}, Step {step+1}, Val Acc: {val_acc:.4f}\")\n",
    "                    \n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = val_acc\n",
    "                        best_model_state = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            \n",
    "            # Compute validation accuracy at the end of each epoch\n",
    "            current_val_acc = self.compute_accuracy(model, self.val_loader)\n",
    "            print(f\"Epoch {epoch+1} Average Loss: {avg_epoch_loss:.4f}, Validation Accuracy: {current_val_acc:.4f}\")\n",
    "            \n",
    "            if current_val_acc > best_val_acc:\n",
    "                best_val_acc = current_val_acc\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # Load the best model state for final evaluation\n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        # Compute final accuracies\n",
    "        final_val_acc = self.compute_accuracy(model, self.val_loader)\n",
    "        test_acc = self.compute_accuracy(model, self.test_loader)\n",
    "        print(f\"{model_name} Final Results:\")\n",
    "        print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        self.results[model_name] = {\n",
    "            'model_state': best_model_state,\n",
    "            'train_losses': train_losses,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'final_val_acc': final_val_acc,\n",
    "            'test_acc': test_acc\n",
    "        }\n",
    "        \n",
    "        return model, test_acc\n",
    "\n",
    "    def compute_accuracy(self, model, data_loader):\n",
    "        \"\"\"\n",
    "        Computes accuracy for the given model and data loader\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"label\"].view(-1, 1).float().to(self.device)\n",
    "                \n",
    "                logits = model(input_ids, attention_mask)\n",
    "                predictions = (logits > 0).long()\n",
    "                \n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        return correct / total\n",
    "\n",
    "    def evaluate_all_methods(self):\n",
    "        \"\"\"\n",
    "        Evaluates all sentence representation methods\n",
    "        \"\"\"\n",
    "        models = {\n",
    "            'Last Hidden State': LastHiddenStateRNN,\n",
    "            'Mean Pooling': MeanPoolingRNN,\n",
    "            'Max Pooling': MaxPoolingRNN,\n",
    "            'Attention': AttentionRNN\n",
    "        }\n",
    "        \n",
    "        for name, model_class in models.items():\n",
    "            _, test_acc = self.train_model(model_class, name)\n",
    "\n",
    "    def print_comparative_results(self):\n",
    "        \"\"\"\n",
    "        Prints comparative results of all methods\n",
    "        \"\"\"\n",
    "        print(\"\\nComparative Results:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Method':<20} {'Test Accuracy':<15} {'Best Val Accuracy':<15} {'Final Val Accuracy':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for method, results in self.results.items():\n",
    "            print(f\"{method:<20} {results['test_acc']:.4f} {results['best_val_acc']:.4f} {results['final_val_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Last Hidden State Model...\n",
      "Epoch 1 Average Loss: 0.6707, Validation Accuracy: 0.6388\n",
      "Epoch 2 Average Loss: 0.5962, Validation Accuracy: 0.6895\n",
      "Epoch 3 Average Loss: 0.5719, Validation Accuracy: 0.7270\n",
      "Last Hidden State Final Results:\n",
      "Best Validation Accuracy: 0.7270\n",
      "Test Accuracy: 0.7167\n",
      "\n",
      "Training Mean Pooling Model...\n",
      "Epoch 1 Average Loss: 0.6117, Validation Accuracy: 0.7186\n",
      "Epoch 2 Average Loss: 0.5549, Validation Accuracy: 0.7251\n",
      "Epoch 3 Average Loss: 0.5432, Validation Accuracy: 0.7064\n",
      "Mean Pooling Final Results:\n",
      "Best Validation Accuracy: 0.7251\n",
      "Test Accuracy: 0.7280\n",
      "\n",
      "Training Max Pooling Model...\n",
      "Epoch 1 Average Loss: 0.6008, Validation Accuracy: 0.6998\n",
      "Epoch 2 Average Loss: 0.4809, Validation Accuracy: 0.7514\n",
      "Epoch 3 Average Loss: 0.4092, Validation Accuracy: 0.7514\n",
      "Max Pooling Final Results:\n",
      "Best Validation Accuracy: 0.7514\n",
      "Test Accuracy: 0.7608\n",
      "\n",
      "Training Attention Model...\n",
      "Epoch 1 Average Loss: 0.6020, Validation Accuracy: 0.7336\n",
      "Epoch 2 Average Loss: 0.5120, Validation Accuracy: 0.7561\n",
      "Epoch 3 Average Loss: 0.4924, Validation Accuracy: 0.7702\n",
      "Attention Final Results:\n",
      "Best Validation Accuracy: 0.7702\n",
      "Test Accuracy: 0.7448\n",
      "\n",
      "Comparative Results:\n",
      "----------------------------------------------------------------------\n",
      "Method               Test Accuracy   Best Val Accuracy Final Val Accuracy\n",
      "----------------------------------------------------------------------\n",
      "Last Hidden State    0.7167 0.7270 0.7270\n",
      "Mean Pooling         0.7280 0.7251 0.7251\n",
      "Max Pooling          0.7608 0.7514 0.7514\n",
      "Attention            0.7448 0.7702 0.7702\n"
     ]
    }
   ],
   "source": [
    "# Configuration dictionary\n",
    "config = {\n",
    "    'hidden_size': 256,\n",
    "    'embed_size': 100,\n",
    "    'num_rnn_layer': 1,\n",
    "    'dropout_rate': 0.2,\n",
    "    'layer_norm': True,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 128,\n",
    "    'max_grad_norm': 2.0,\n",
    "    'num_train_epochs': 3,\n",
    "    'val_steps': 100\n",
    "}\n",
    "\n",
    "evaluator = SentimentModelEvaluator(\n",
    "    embedding=embedding,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Run evaluation for all methods\n",
    "evaluator.evaluate_all_methods()\n",
    "\n",
    "# Print comparative results\n",
    "evaluator.print_comparative_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2c: Methods for Deriving Sentence Representations\n",
    "\n",
    "We implemented and compared four different methods for deriving sentence representations from RNN outputs. Each method offers a unique approach to aggregating the hidden states into a meaningful sentence vector.\n",
    "\n",
    "## Implementation Results\n",
    "\n",
    "| Method | Test Accuracy | Validation Accuracy |\n",
    "|--------|---------------|-------------------|\n",
    "| Last Hidden State | 71.67% | 72.70% |\n",
    "| Mean Pooling | 72.80% | 72.51% |\n",
    "| Max Pooling | 76.08% | 75.14% |\n",
    "| Attention | 74.48% | 77.02% |\n",
    "\n",
    "## Method Analysis\n",
    "\n",
    "### 1. Last Hidden State (71.67%)\n",
    "- **Implementation**: Uses the final RNN state as the sentence representation\n",
    "- **Performance**: Baseline performance, lowest accuracy among all methods\n",
    "- **Limitation**: May lose important information from earlier parts of the sentence\n",
    "\n",
    "### 2. Mean Pooling (72.80%)\n",
    "- **Implementation**: Averages all hidden states across the sequence\n",
    "- **Performance**: Shows improved performance over last hidden state\n",
    "- **Characteristic**: Effectively captures overall sentiment but may dilute strong signals\n",
    "\n",
    "### 3. Max Pooling (76.08%)\n",
    "- **Implementation**: Takes maximum values across all hidden states\n",
    "- **Performance**: Achieves the best test performance\n",
    "- **Strength**: Successfully captures the most salient features for sentiment classification\n",
    "- **Advantage**: Particularly effective at identifying strong sentiment indicators regardless of position\n",
    "\n",
    "### 4. Attention Mechanism (74.48%)\n",
    "- **Implementation**: Uses learned attention weights to create weighted sum of hidden states\n",
    "- **Performance**: Shows second-best test performance\n",
    "- **Notable**: Demonstrates highest validation accuracy (77.02%)\n",
    "- **Observation**: Slight performance gap between validation and test suggests potential overfitting\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **Best Method**: Max Pooling emerged as the most effective method, suggesting that capturing the strongest sentiment signals is more important than position-based or averaged representations\n",
    "\n",
    "2. **Method Comparison**: All advanced pooling methods outperformed the basic last hidden state approach\n",
    "\n",
    "3. **Future Improvement**: The attention mechanism shows promise but may benefit from additional regularisation to reduce the validation-test accuracy gap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
