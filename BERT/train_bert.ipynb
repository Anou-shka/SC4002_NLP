{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This structure is for BERT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, BertModel, PreTrainedTokenizer, get_cosine_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torch.nn.utils.rnn import pad_sequence # for dynamic padding\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pretrained model\n",
    "model : BertModel = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer : PreTrainedTokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>any enjoyment will be hinge from a personal th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>if legendary shlockmeister ed wood had ever ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>hardly a nuanced portrait of a young woman's b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>interminably bleak , to say nothing of boring .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>things really get weird , though not particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     the rock is destined to be the 21st century's ...      1\n",
       "1     the gorgeously elaborate continuation of \" the...      1\n",
       "2                        effective but too-tepid biopic      1\n",
       "3     if you sometimes like to go to the movies to h...      1\n",
       "4     emerges as something rare , an issue movie tha...      1\n",
       "...                                                 ...    ...\n",
       "8525  any enjoyment will be hinge from a personal th...      0\n",
       "8526  if legendary shlockmeister ed wood had ever ma...      0\n",
       "8527  hardly a nuanced portrait of a young woman's b...      0\n",
       "8528    interminably bleak , to say nothing of boring .      0\n",
       "8529  things really get weird , though not particula...      0\n",
       "\n",
       "[8530 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import datasets\n",
    "\n",
    "train_df = pd.read_csv(\"../preprocessed_dataset/train.csv\").iloc[:,1:]\n",
    "validation_df = pd.read_csv(\"../preprocessed_dataset/validation.csv\").iloc[:,1:]\n",
    "test_df = pd.read_csv(\"../preprocessed_dataset/test.csv\").iloc[:,1:]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 19082, 1362, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            bert : BertModel\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.fc = nn.Linear(768, 1) # total 768 dim output\n",
    "        \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids : torch.Tensor,\n",
    "            attention_mask : torch.Tensor\n",
    "        ) -> torch.Tensor:\n",
    "        outputs = self.bert.forward(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask\n",
    "        )\n",
    "        # get the output of [CLS] position (first position) for training \n",
    "        cls_output = outputs.last_hidden_state[:,0,:] # [B, seqlen, embed]\n",
    "        return self.fc.forward(cls_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 174, 22816, 1181, 22816, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"efsdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset and data loader\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class CustomizeDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            tokenizer : PreTrainedTokenizer,\n",
    "            df : pd.DataFrame\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(\n",
    "            self, \n",
    "            index : int\n",
    "        ) -> dict:\n",
    "        \n",
    "        inputs = self.df.iloc[index,0] # 0 is text\n",
    "        label = self.df.iloc[index, 1] # 1 is label\n",
    "        \n",
    "        tok = self.tokenizer(inputs)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\" : tok[\"input_ids\"],\n",
    "            \"label\" : label\n",
    "        }\n",
    "        \n",
    "# collater function\n",
    "class Collater:\n",
    "    def __init__(\n",
    "            self,\n",
    "            tokenizer : PreTrainedTokenizer\n",
    "        ) -> None:\n",
    "        self.tokenizer = tokenizer \n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        instances : list\n",
    "        ) -> Any:\n",
    "        input_ids = [torch.tensor(instance[\"input_ids\"], dtype = torch.int64) for instance in instances]\n",
    "        label = [torch.tensor(instance[\"label\"], dtype = torch.int64) for instance in instances]\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        attention_mask = input_ids.ne(self.tokenizer.pad_token_id).type(torch.int64)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"label\": torch.tensor(label),\n",
    "            \"attention_mask\": attention_mask # attention mask 本质就是找到不等于 pad_token_id 的位置，就是有效位置\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper paramaters\n",
    "\n",
    "num_train_epochs = 4\n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-6\n",
    "\n",
    "warmup_ratio=0.05\n",
    "max_grad_norm = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and data loader\n",
    "\n",
    "collate_fn = Collater(tokenizer)\n",
    "\n",
    "train_ds = CustomizeDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    df = train_df\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_ds,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_ds = CustomizeDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    df = validation_df\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_ds,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "test_ds = CustomizeDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    df = test_df\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_ds,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:2136, warm up: 106\n"
     ]
    }
   ],
   "source": [
    "# compute warmup status\n",
    "num_training_steps = num_train_epochs * len(train_loader)\n",
    "num_warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "print(f\"train:{num_training_steps}, warm up: {num_warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer, loss_fn and so on\n",
    "\n",
    "cls_model = SentimentClassifier(model)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = AdamW(\n",
    "    params = cls_model.parameters(),\n",
    "    lr = lr,\n",
    "    weight_decay = weight_decay\n",
    ")\n",
    "\n",
    "scheduler  = get_cosine_schedule_with_warmup(\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = num_warmup_steps,\n",
    "    num_training_steps = num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy\n",
    "\n",
    "def compute_accuracy(data_loader: DataLoader) -> float:\n",
    "    \n",
    "    cls_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            labels = data[\"label\"].view(-1, 1).float().to(device)\n",
    "            \n",
    "            logits = cls_model(input_ids, attention_mask=attention_mask)\n",
    "     \n",
    "            predictions = (logits > 0).long()\n",
    "            \n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2136] train loss: [0.6802] (epoch [1/4])\n",
      "[2/2136] train loss: [0.6365] (epoch [1/4])\n",
      "[3/2136] train loss: [0.7885] (epoch [1/4])\n",
      "[4/2136] train loss: [0.7278] (epoch [1/4])\n",
      "[5/2136] train loss: [0.7504] (epoch [1/4])\n",
      "[6/2136] train loss: [0.7761] (epoch [1/4])\n",
      "[7/2136] train loss: [0.7422] (epoch [1/4])\n",
      "[8/2136] train loss: [0.7169] (epoch [1/4])\n",
      "[9/2136] train loss: [0.7840] (epoch [1/4])\n",
      "[10/2136] train loss: [0.8355] (epoch [1/4])\n",
      "[11/2136] train loss: [0.6911] (epoch [1/4])\n",
      "[12/2136] train loss: [0.6757] (epoch [1/4])\n",
      "[13/2136] train loss: [0.7800] (epoch [1/4])\n",
      "[14/2136] train loss: [0.7433] (epoch [1/4])\n",
      "[15/2136] train loss: [0.8212] (epoch [1/4])\n",
      "[16/2136] train loss: [0.7852] (epoch [1/4])\n",
      "[17/2136] train loss: [0.7730] (epoch [1/4])\n",
      "[18/2136] train loss: [0.6851] (epoch [1/4])\n",
      "[19/2136] train loss: [0.7209] (epoch [1/4])\n",
      "[20/2136] train loss: [0.7254] (epoch [1/4])\n",
      "[21/2136] train loss: [0.7846] (epoch [1/4])\n",
      "[22/2136] train loss: [0.7598] (epoch [1/4])\n",
      "[23/2136] train loss: [0.7380] (epoch [1/4])\n",
      "[24/2136] train loss: [0.7187] (epoch [1/4])\n",
      "[25/2136] train loss: [0.7734] (epoch [1/4])\n",
      "[26/2136] train loss: [0.7385] (epoch [1/4])\n",
      "[27/2136] train loss: [0.7427] (epoch [1/4])\n",
      "[28/2136] train loss: [0.7654] (epoch [1/4])\n",
      "[29/2136] train loss: [0.6173] (epoch [1/4])\n",
      "[30/2136] train loss: [0.7427] (epoch [1/4])\n",
      "[31/2136] train loss: [0.6818] (epoch [1/4])\n",
      "[32/2136] train loss: [0.7014] (epoch [1/4])\n",
      "[33/2136] train loss: [0.6638] (epoch [1/4])\n",
      "[34/2136] train loss: [0.6974] (epoch [1/4])\n",
      "[35/2136] train loss: [0.6806] (epoch [1/4])\n",
      "[36/2136] train loss: [0.7129] (epoch [1/4])\n",
      "[37/2136] train loss: [0.6709] (epoch [1/4])\n",
      "[38/2136] train loss: [0.7440] (epoch [1/4])\n",
      "[39/2136] train loss: [0.7394] (epoch [1/4])\n",
      "[40/2136] train loss: [0.6595] (epoch [1/4])\n",
      "[41/2136] train loss: [0.6845] (epoch [1/4])\n",
      "[42/2136] train loss: [0.7186] (epoch [1/4])\n",
      "[43/2136] train loss: [0.6680] (epoch [1/4])\n",
      "[44/2136] train loss: [0.7955] (epoch [1/4])\n",
      "[45/2136] train loss: [0.6784] (epoch [1/4])\n",
      "[46/2136] train loss: [0.7611] (epoch [1/4])\n",
      "[47/2136] train loss: [0.6968] (epoch [1/4])\n",
      "[48/2136] train loss: [0.6803] (epoch [1/4])\n",
      "[49/2136] train loss: [0.7119] (epoch [1/4])\n",
      "[50/2136] train loss: [0.6890] (epoch [1/4])\n",
      "[51/2136] train loss: [0.8027] (epoch [1/4])\n",
      "[52/2136] train loss: [0.6523] (epoch [1/4])\n",
      "[53/2136] train loss: [0.7675] (epoch [1/4])\n",
      "[54/2136] train loss: [0.7345] (epoch [1/4])\n",
      "[55/2136] train loss: [0.7120] (epoch [1/4])\n",
      "[56/2136] train loss: [0.7958] (epoch [1/4])\n",
      "[57/2136] train loss: [0.7744] (epoch [1/4])\n",
      "[58/2136] train loss: [0.6786] (epoch [1/4])\n",
      "[59/2136] train loss: [0.6928] (epoch [1/4])\n",
      "[60/2136] train loss: [0.6243] (epoch [1/4])\n",
      "[61/2136] train loss: [0.7744] (epoch [1/4])\n",
      "[62/2136] train loss: [0.7419] (epoch [1/4])\n",
      "[63/2136] train loss: [0.7328] (epoch [1/4])\n",
      "[64/2136] train loss: [0.6662] (epoch [1/4])\n",
      "[65/2136] train loss: [0.7548] (epoch [1/4])\n",
      "[66/2136] train loss: [0.7468] (epoch [1/4])\n",
      "[67/2136] train loss: [0.7375] (epoch [1/4])\n",
      "[68/2136] train loss: [0.6949] (epoch [1/4])\n",
      "[69/2136] train loss: [0.7208] (epoch [1/4])\n",
      "[70/2136] train loss: [0.7456] (epoch [1/4])\n",
      "[71/2136] train loss: [0.7819] (epoch [1/4])\n",
      "[72/2136] train loss: [0.7047] (epoch [1/4])\n",
      "[73/2136] train loss: [0.7422] (epoch [1/4])\n",
      "[74/2136] train loss: [0.6618] (epoch [1/4])\n",
      "[75/2136] train loss: [0.6650] (epoch [1/4])\n",
      "[76/2136] train loss: [0.6681] (epoch [1/4])\n",
      "[77/2136] train loss: [0.7000] (epoch [1/4])\n",
      "[78/2136] train loss: [0.6408] (epoch [1/4])\n",
      "[79/2136] train loss: [0.7008] (epoch [1/4])\n",
      "[80/2136] train loss: [0.7113] (epoch [1/4])\n",
      "[81/2136] train loss: [0.6655] (epoch [1/4])\n",
      "[82/2136] train loss: [0.7345] (epoch [1/4])\n",
      "[83/2136] train loss: [0.6619] (epoch [1/4])\n",
      "[84/2136] train loss: [0.7419] (epoch [1/4])\n",
      "[85/2136] train loss: [0.7378] (epoch [1/4])\n",
      "[86/2136] train loss: [0.6318] (epoch [1/4])\n",
      "[87/2136] train loss: [0.7163] (epoch [1/4])\n",
      "[88/2136] train loss: [0.6794] (epoch [1/4])\n",
      "[89/2136] train loss: [0.6735] (epoch [1/4])\n",
      "[90/2136] train loss: [0.7095] (epoch [1/4])\n",
      "[91/2136] train loss: [0.6664] (epoch [1/4])\n",
      "[92/2136] train loss: [0.6940] (epoch [1/4])\n",
      "[93/2136] train loss: [0.6765] (epoch [1/4])\n",
      "[94/2136] train loss: [0.7057] (epoch [1/4])\n",
      "[95/2136] train loss: [0.7078] (epoch [1/4])\n",
      "[96/2136] train loss: [0.6688] (epoch [1/4])\n",
      "[97/2136] train loss: [0.7488] (epoch [1/4])\n",
      "[98/2136] train loss: [0.6680] (epoch [1/4])\n",
      "[99/2136] train loss: [0.6658] (epoch [1/4])\n",
      "[100/2136] train loss: [0.6865] (epoch [1/4])\n",
      "[101/2136] train loss: [0.6926] (epoch [1/4])\n",
      "[102/2136] train loss: [0.6429] (epoch [1/4])\n",
      "[103/2136] train loss: [0.6942] (epoch [1/4])\n",
      "[104/2136] train loss: [0.7190] (epoch [1/4])\n",
      "[105/2136] train loss: [0.7105] (epoch [1/4])\n",
      "[106/2136] train loss: [0.7068] (epoch [1/4])\n",
      "[107/2136] train loss: [0.7305] (epoch [1/4])\n",
      "[108/2136] train loss: [0.7422] (epoch [1/4])\n",
      "[109/2136] train loss: [0.6841] (epoch [1/4])\n",
      "[110/2136] train loss: [0.6998] (epoch [1/4])\n",
      "[111/2136] train loss: [0.6722] (epoch [1/4])\n",
      "[112/2136] train loss: [0.6525] (epoch [1/4])\n",
      "[113/2136] train loss: [0.7013] (epoch [1/4])\n",
      "[114/2136] train loss: [0.6669] (epoch [1/4])\n",
      "[115/2136] train loss: [0.7251] (epoch [1/4])\n",
      "[116/2136] train loss: [0.7166] (epoch [1/4])\n",
      "[117/2136] train loss: [0.6792] (epoch [1/4])\n",
      "[118/2136] train loss: [0.6896] (epoch [1/4])\n",
      "[119/2136] train loss: [0.7009] (epoch [1/4])\n",
      "[120/2136] train loss: [0.6927] (epoch [1/4])\n",
      "[121/2136] train loss: [0.7111] (epoch [1/4])\n",
      "[122/2136] train loss: [0.7210] (epoch [1/4])\n",
      "[123/2136] train loss: [0.6875] (epoch [1/4])\n",
      "[124/2136] train loss: [0.6734] (epoch [1/4])\n",
      "[125/2136] train loss: [0.7069] (epoch [1/4])\n",
      "[126/2136] train loss: [0.6804] (epoch [1/4])\n",
      "[127/2136] train loss: [0.6885] (epoch [1/4])\n",
      "[128/2136] train loss: [0.6699] (epoch [1/4])\n",
      "[129/2136] train loss: [0.6964] (epoch [1/4])\n",
      "[130/2136] train loss: [0.6904] (epoch [1/4])\n",
      "[131/2136] train loss: [0.6850] (epoch [1/4])\n",
      "[132/2136] train loss: [0.7143] (epoch [1/4])\n",
      "[133/2136] train loss: [0.7297] (epoch [1/4])\n",
      "[134/2136] train loss: [0.6756] (epoch [1/4])\n",
      "[135/2136] train loss: [0.6896] (epoch [1/4])\n",
      "[136/2136] train loss: [0.6931] (epoch [1/4])\n",
      "[137/2136] train loss: [0.6683] (epoch [1/4])\n",
      "[138/2136] train loss: [0.6824] (epoch [1/4])\n",
      "[139/2136] train loss: [0.6988] (epoch [1/4])\n",
      "[140/2136] train loss: [0.6755] (epoch [1/4])\n",
      "[141/2136] train loss: [0.6841] (epoch [1/4])\n",
      "[142/2136] train loss: [0.6702] (epoch [1/4])\n",
      "[143/2136] train loss: [0.7082] (epoch [1/4])\n",
      "[144/2136] train loss: [0.6861] (epoch [1/4])\n",
      "[145/2136] train loss: [0.6976] (epoch [1/4])\n",
      "[146/2136] train loss: [0.6934] (epoch [1/4])\n",
      "[147/2136] train loss: [0.6893] (epoch [1/4])\n",
      "[148/2136] train loss: [0.7087] (epoch [1/4])\n",
      "[149/2136] train loss: [0.6683] (epoch [1/4])\n",
      "[150/2136] train loss: [0.6944] (epoch [1/4])\n",
      "[151/2136] train loss: [0.7013] (epoch [1/4])\n",
      "[152/2136] train loss: [0.6724] (epoch [1/4])\n",
      "[153/2136] train loss: [0.6651] (epoch [1/4])\n",
      "[154/2136] train loss: [0.6800] (epoch [1/4])\n",
      "[155/2136] train loss: [0.6540] (epoch [1/4])\n",
      "[156/2136] train loss: [0.7153] (epoch [1/4])\n",
      "[157/2136] train loss: [0.6760] (epoch [1/4])\n",
      "[158/2136] train loss: [0.6988] (epoch [1/4])\n",
      "[159/2136] train loss: [0.6969] (epoch [1/4])\n",
      "[160/2136] train loss: [0.6836] (epoch [1/4])\n",
      "[161/2136] train loss: [0.6718] (epoch [1/4])\n",
      "[162/2136] train loss: [0.6728] (epoch [1/4])\n",
      "[163/2136] train loss: [0.6813] (epoch [1/4])\n",
      "[164/2136] train loss: [0.6993] (epoch [1/4])\n",
      "[165/2136] train loss: [0.6931] (epoch [1/4])\n",
      "[166/2136] train loss: [0.6910] (epoch [1/4])\n",
      "[167/2136] train loss: [0.6611] (epoch [1/4])\n",
      "[168/2136] train loss: [0.6989] (epoch [1/4])\n",
      "[169/2136] train loss: [0.7035] (epoch [1/4])\n",
      "[170/2136] train loss: [0.6597] (epoch [1/4])\n",
      "[171/2136] train loss: [0.6436] (epoch [1/4])\n",
      "[172/2136] train loss: [0.6978] (epoch [1/4])\n",
      "[173/2136] train loss: [0.6832] (epoch [1/4])\n",
      "[174/2136] train loss: [0.6325] (epoch [1/4])\n",
      "[175/2136] train loss: [0.6852] (epoch [1/4])\n",
      "[176/2136] train loss: [0.6521] (epoch [1/4])\n",
      "[177/2136] train loss: [0.6765] (epoch [1/4])\n",
      "[178/2136] train loss: [0.6896] (epoch [1/4])\n",
      "[179/2136] train loss: [0.6806] (epoch [1/4])\n",
      "[180/2136] train loss: [0.7075] (epoch [1/4])\n",
      "[181/2136] train loss: [0.6621] (epoch [1/4])\n",
      "[182/2136] train loss: [0.6539] (epoch [1/4])\n",
      "[183/2136] train loss: [0.6970] (epoch [1/4])\n",
      "[184/2136] train loss: [0.6993] (epoch [1/4])\n",
      "[185/2136] train loss: [0.6853] (epoch [1/4])\n",
      "[186/2136] train loss: [0.6958] (epoch [1/4])\n",
      "[187/2136] train loss: [0.6780] (epoch [1/4])\n",
      "[188/2136] train loss: [0.6648] (epoch [1/4])\n",
      "[189/2136] train loss: [0.6952] (epoch [1/4])\n",
      "[190/2136] train loss: [0.6699] (epoch [1/4])\n",
      "[191/2136] train loss: [0.7067] (epoch [1/4])\n",
      "[192/2136] train loss: [0.6434] (epoch [1/4])\n",
      "[193/2136] train loss: [0.6672] (epoch [1/4])\n",
      "[194/2136] train loss: [0.6925] (epoch [1/4])\n",
      "[195/2136] train loss: [0.6881] (epoch [1/4])\n",
      "[196/2136] train loss: [0.6837] (epoch [1/4])\n",
      "[197/2136] train loss: [0.6985] (epoch [1/4])\n",
      "[198/2136] train loss: [0.7014] (epoch [1/4])\n",
      "[199/2136] train loss: [0.6903] (epoch [1/4])\n",
      "[200/2136] train loss: [0.7189] (epoch [1/4])\n",
      "[201/2136] train loss: [0.6321] (epoch [1/4])\n",
      "[202/2136] train loss: [0.7185] (epoch [1/4])\n",
      "[203/2136] train loss: [0.6839] (epoch [1/4])\n",
      "[204/2136] train loss: [0.6855] (epoch [1/4])\n",
      "[205/2136] train loss: [0.6424] (epoch [1/4])\n",
      "[206/2136] train loss: [0.6664] (epoch [1/4])\n",
      "[207/2136] train loss: [0.6946] (epoch [1/4])\n",
      "[208/2136] train loss: [0.6742] (epoch [1/4])\n",
      "[209/2136] train loss: [0.7011] (epoch [1/4])\n",
      "[210/2136] train loss: [0.6658] (epoch [1/4])\n",
      "[211/2136] train loss: [0.6799] (epoch [1/4])\n",
      "[212/2136] train loss: [0.6714] (epoch [1/4])\n",
      "[213/2136] train loss: [0.7142] (epoch [1/4])\n",
      "[214/2136] train loss: [0.6579] (epoch [1/4])\n",
      "[215/2136] train loss: [0.6816] (epoch [1/4])\n",
      "[216/2136] train loss: [0.7059] (epoch [1/4])\n",
      "[217/2136] train loss: [0.6843] (epoch [1/4])\n",
      "[218/2136] train loss: [0.7036] (epoch [1/4])\n",
      "[219/2136] train loss: [0.6850] (epoch [1/4])\n",
      "[220/2136] train loss: [0.6715] (epoch [1/4])\n",
      "[221/2136] train loss: [0.6931] (epoch [1/4])\n",
      "[222/2136] train loss: [0.7149] (epoch [1/4])\n",
      "[223/2136] train loss: [0.6771] (epoch [1/4])\n",
      "[224/2136] train loss: [0.6537] (epoch [1/4])\n",
      "[225/2136] train loss: [0.6473] (epoch [1/4])\n",
      "[226/2136] train loss: [0.7009] (epoch [1/4])\n",
      "[227/2136] train loss: [0.6529] (epoch [1/4])\n",
      "[228/2136] train loss: [0.6562] (epoch [1/4])\n",
      "[229/2136] train loss: [0.6830] (epoch [1/4])\n",
      "[230/2136] train loss: [0.7070] (epoch [1/4])\n",
      "[231/2136] train loss: [0.6775] (epoch [1/4])\n",
      "[232/2136] train loss: [0.6659] (epoch [1/4])\n",
      "[233/2136] train loss: [0.6668] (epoch [1/4])\n",
      "[234/2136] train loss: [0.6433] (epoch [1/4])\n",
      "[235/2136] train loss: [0.6718] (epoch [1/4])\n",
      "[236/2136] train loss: [0.6694] (epoch [1/4])\n",
      "[237/2136] train loss: [0.6357] (epoch [1/4])\n",
      "[238/2136] train loss: [0.6894] (epoch [1/4])\n",
      "[239/2136] train loss: [0.6355] (epoch [1/4])\n",
      "[240/2136] train loss: [0.6637] (epoch [1/4])\n",
      "[241/2136] train loss: [0.6667] (epoch [1/4])\n",
      "[242/2136] train loss: [0.6604] (epoch [1/4])\n",
      "[243/2136] train loss: [0.6697] (epoch [1/4])\n",
      "[244/2136] train loss: [0.6328] (epoch [1/4])\n",
      "[245/2136] train loss: [0.6928] (epoch [1/4])\n",
      "[246/2136] train loss: [0.6725] (epoch [1/4])\n",
      "[247/2136] train loss: [0.6566] (epoch [1/4])\n",
      "[248/2136] train loss: [0.7001] (epoch [1/4])\n",
      "[249/2136] train loss: [0.7043] (epoch [1/4])\n",
      "[250/2136] train loss: [0.6600] (epoch [1/4])\n",
      "[251/2136] train loss: [0.6583] (epoch [1/4])\n",
      "[252/2136] train loss: [0.6525] (epoch [1/4])\n",
      "[253/2136] train loss: [0.6627] (epoch [1/4])\n",
      "[254/2136] train loss: [0.7040] (epoch [1/4])\n",
      "[255/2136] train loss: [0.6533] (epoch [1/4])\n",
      "[256/2136] train loss: [0.6856] (epoch [1/4])\n",
      "[257/2136] train loss: [0.6292] (epoch [1/4])\n",
      "[258/2136] train loss: [0.6492] (epoch [1/4])\n",
      "[259/2136] train loss: [0.6980] (epoch [1/4])\n",
      "[260/2136] train loss: [0.6577] (epoch [1/4])\n",
      "[261/2136] train loss: [0.6633] (epoch [1/4])\n",
      "[262/2136] train loss: [0.6784] (epoch [1/4])\n",
      "[263/2136] train loss: [0.7014] (epoch [1/4])\n",
      "[264/2136] train loss: [0.6957] (epoch [1/4])\n",
      "[265/2136] train loss: [0.6884] (epoch [1/4])\n",
      "[266/2136] train loss: [0.6169] (epoch [1/4])\n",
      "[267/2136] train loss: [0.6768] (epoch [1/4])\n",
      "[268/2136] train loss: [0.6099] (epoch [1/4])\n",
      "[269/2136] train loss: [0.6713] (epoch [1/4])\n",
      "[270/2136] train loss: [0.6217] (epoch [1/4])\n",
      "[271/2136] train loss: [0.6461] (epoch [1/4])\n",
      "[272/2136] train loss: [0.7021] (epoch [1/4])\n",
      "[273/2136] train loss: [0.6911] (epoch [1/4])\n",
      "[274/2136] train loss: [0.6678] (epoch [1/4])\n",
      "[275/2136] train loss: [0.6291] (epoch [1/4])\n",
      "[276/2136] train loss: [0.6747] (epoch [1/4])\n",
      "[277/2136] train loss: [0.6593] (epoch [1/4])\n",
      "[278/2136] train loss: [0.6409] (epoch [1/4])\n",
      "[279/2136] train loss: [0.6558] (epoch [1/4])\n",
      "[280/2136] train loss: [0.6531] (epoch [1/4])\n",
      "[281/2136] train loss: [0.6230] (epoch [1/4])\n",
      "[282/2136] train loss: [0.6296] (epoch [1/4])\n",
      "[283/2136] train loss: [0.6047] (epoch [1/4])\n",
      "[284/2136] train loss: [0.7137] (epoch [1/4])\n",
      "[285/2136] train loss: [0.6664] (epoch [1/4])\n",
      "[286/2136] train loss: [0.6764] (epoch [1/4])\n",
      "[287/2136] train loss: [0.6652] (epoch [1/4])\n",
      "[288/2136] train loss: [0.6204] (epoch [1/4])\n",
      "[289/2136] train loss: [0.6539] (epoch [1/4])\n",
      "[290/2136] train loss: [0.6593] (epoch [1/4])\n",
      "[291/2136] train loss: [0.7146] (epoch [1/4])\n",
      "[292/2136] train loss: [0.6741] (epoch [1/4])\n",
      "[293/2136] train loss: [0.6699] (epoch [1/4])\n",
      "[294/2136] train loss: [0.6838] (epoch [1/4])\n",
      "[295/2136] train loss: [0.6191] (epoch [1/4])\n",
      "[296/2136] train loss: [0.6452] (epoch [1/4])\n",
      "[297/2136] train loss: [0.6261] (epoch [1/4])\n",
      "[298/2136] train loss: [0.6352] (epoch [1/4])\n",
      "[299/2136] train loss: [0.6489] (epoch [1/4])\n",
      "[300/2136] train loss: [0.6595] (epoch [1/4])\n",
      "[301/2136] train loss: [0.6770] (epoch [1/4])\n",
      "[302/2136] train loss: [0.6631] (epoch [1/4])\n",
      "[303/2136] train loss: [0.6522] (epoch [1/4])\n",
      "[304/2136] train loss: [0.6579] (epoch [1/4])\n",
      "[305/2136] train loss: [0.6616] (epoch [1/4])\n",
      "[306/2136] train loss: [0.6460] (epoch [1/4])\n",
      "[307/2136] train loss: [0.6632] (epoch [1/4])\n",
      "[308/2136] train loss: [0.6420] (epoch [1/4])\n",
      "[309/2136] train loss: [0.6340] (epoch [1/4])\n",
      "[310/2136] train loss: [0.6645] (epoch [1/4])\n",
      "[311/2136] train loss: [0.6436] (epoch [1/4])\n",
      "[312/2136] train loss: [0.6291] (epoch [1/4])\n",
      "[313/2136] train loss: [0.6883] (epoch [1/4])\n",
      "[314/2136] train loss: [0.6257] (epoch [1/4])\n",
      "[315/2136] train loss: [0.6124] (epoch [1/4])\n",
      "[316/2136] train loss: [0.6235] (epoch [1/4])\n",
      "[317/2136] train loss: [0.6198] (epoch [1/4])\n",
      "[318/2136] train loss: [0.6148] (epoch [1/4])\n",
      "[319/2136] train loss: [0.6346] (epoch [1/4])\n",
      "[320/2136] train loss: [0.6210] (epoch [1/4])\n",
      "[321/2136] train loss: [0.6315] (epoch [1/4])\n",
      "[322/2136] train loss: [0.6479] (epoch [1/4])\n",
      "[323/2136] train loss: [0.5945] (epoch [1/4])\n",
      "[324/2136] train loss: [0.6241] (epoch [1/4])\n",
      "[325/2136] train loss: [0.6391] (epoch [1/4])\n",
      "[326/2136] train loss: [0.5775] (epoch [1/4])\n",
      "[327/2136] train loss: [0.6583] (epoch [1/4])\n",
      "[328/2136] train loss: [0.7118] (epoch [1/4])\n",
      "[329/2136] train loss: [0.6206] (epoch [1/4])\n",
      "[330/2136] train loss: [0.6352] (epoch [1/4])\n",
      "[331/2136] train loss: [0.5941] (epoch [1/4])\n",
      "[332/2136] train loss: [0.6520] (epoch [1/4])\n",
      "[333/2136] train loss: [0.6094] (epoch [1/4])\n",
      "[334/2136] train loss: [0.6112] (epoch [1/4])\n",
      "[335/2136] train loss: [0.6696] (epoch [1/4])\n",
      "[336/2136] train loss: [0.6644] (epoch [1/4])\n",
      "[337/2136] train loss: [0.6566] (epoch [1/4])\n",
      "[338/2136] train loss: [0.6741] (epoch [1/4])\n",
      "[339/2136] train loss: [0.6626] (epoch [1/4])\n",
      "[340/2136] train loss: [0.6385] (epoch [1/4])\n",
      "[341/2136] train loss: [0.6833] (epoch [1/4])\n",
      "[342/2136] train loss: [0.6240] (epoch [1/4])\n",
      "[343/2136] train loss: [0.6328] (epoch [1/4])\n",
      "[344/2136] train loss: [0.6716] (epoch [1/4])\n",
      "[345/2136] train loss: [0.5902] (epoch [1/4])\n",
      "[346/2136] train loss: [0.5980] (epoch [1/4])\n",
      "[347/2136] train loss: [0.6329] (epoch [1/4])\n",
      "[348/2136] train loss: [0.6721] (epoch [1/4])\n",
      "[349/2136] train loss: [0.6463] (epoch [1/4])\n",
      "[350/2136] train loss: [0.6137] (epoch [1/4])\n",
      "[351/2136] train loss: [0.6094] (epoch [1/4])\n",
      "[352/2136] train loss: [0.6338] (epoch [1/4])\n",
      "[353/2136] train loss: [0.6197] (epoch [1/4])\n",
      "[354/2136] train loss: [0.5959] (epoch [1/4])\n",
      "[355/2136] train loss: [0.6159] (epoch [1/4])\n",
      "[356/2136] train loss: [0.6212] (epoch [1/4])\n",
      "[357/2136] train loss: [0.6102] (epoch [1/4])\n",
      "[358/2136] train loss: [0.6018] (epoch [1/4])\n",
      "[359/2136] train loss: [0.6959] (epoch [1/4])\n",
      "[360/2136] train loss: [0.6532] (epoch [1/4])\n",
      "[361/2136] train loss: [0.6339] (epoch [1/4])\n",
      "[362/2136] train loss: [0.5382] (epoch [1/4])\n",
      "[363/2136] train loss: [0.5792] (epoch [1/4])\n",
      "[364/2136] train loss: [0.5662] (epoch [1/4])\n",
      "[365/2136] train loss: [0.6931] (epoch [1/4])\n",
      "[366/2136] train loss: [0.6128] (epoch [1/4])\n",
      "[367/2136] train loss: [0.6135] (epoch [1/4])\n",
      "[368/2136] train loss: [0.6690] (epoch [1/4])\n",
      "[369/2136] train loss: [0.6134] (epoch [1/4])\n",
      "[370/2136] train loss: [0.6352] (epoch [1/4])\n",
      "[371/2136] train loss: [0.6377] (epoch [1/4])\n",
      "[372/2136] train loss: [0.5537] (epoch [1/4])\n",
      "[373/2136] train loss: [0.6861] (epoch [1/4])\n",
      "[374/2136] train loss: [0.6408] (epoch [1/4])\n",
      "[375/2136] train loss: [0.5823] (epoch [1/4])\n",
      "[376/2136] train loss: [0.6665] (epoch [1/4])\n",
      "[377/2136] train loss: [0.6377] (epoch [1/4])\n",
      "[378/2136] train loss: [0.6557] (epoch [1/4])\n",
      "[379/2136] train loss: [0.5879] (epoch [1/4])\n",
      "[380/2136] train loss: [0.5816] (epoch [1/4])\n",
      "[381/2136] train loss: [0.5199] (epoch [1/4])\n",
      "[382/2136] train loss: [0.5784] (epoch [1/4])\n",
      "[383/2136] train loss: [0.5552] (epoch [1/4])\n",
      "[384/2136] train loss: [0.5701] (epoch [1/4])\n",
      "[385/2136] train loss: [0.4899] (epoch [1/4])\n",
      "[386/2136] train loss: [0.5757] (epoch [1/4])\n",
      "[387/2136] train loss: [0.6125] (epoch [1/4])\n",
      "[388/2136] train loss: [0.5546] (epoch [1/4])\n",
      "[389/2136] train loss: [0.6137] (epoch [1/4])\n",
      "[390/2136] train loss: [0.6077] (epoch [1/4])\n",
      "[391/2136] train loss: [0.5784] (epoch [1/4])\n",
      "[392/2136] train loss: [0.6150] (epoch [1/4])\n",
      "[393/2136] train loss: [0.5573] (epoch [1/4])\n",
      "[394/2136] train loss: [0.6685] (epoch [1/4])\n",
      "[395/2136] train loss: [0.5976] (epoch [1/4])\n",
      "[396/2136] train loss: [0.6367] (epoch [1/4])\n",
      "[397/2136] train loss: [0.6497] (epoch [1/4])\n",
      "[398/2136] train loss: [0.5509] (epoch [1/4])\n",
      "[399/2136] train loss: [0.6760] (epoch [1/4])\n",
      "[400/2136] train loss: [0.6267] (epoch [1/4])\n",
      "[401/2136] train loss: [0.6493] (epoch [1/4])\n",
      "[402/2136] train loss: [0.6384] (epoch [1/4])\n",
      "[403/2136] train loss: [0.6278] (epoch [1/4])\n",
      "[404/2136] train loss: [0.6116] (epoch [1/4])\n",
      "[405/2136] train loss: [0.5627] (epoch [1/4])\n",
      "[406/2136] train loss: [0.5983] (epoch [1/4])\n",
      "[407/2136] train loss: [0.5740] (epoch [1/4])\n",
      "[408/2136] train loss: [0.5078] (epoch [1/4])\n",
      "[409/2136] train loss: [0.5353] (epoch [1/4])\n",
      "[410/2136] train loss: [0.5816] (epoch [1/4])\n",
      "[411/2136] train loss: [0.5448] (epoch [1/4])\n",
      "[412/2136] train loss: [0.6019] (epoch [1/4])\n",
      "[413/2136] train loss: [0.5530] (epoch [1/4])\n",
      "[414/2136] train loss: [0.5413] (epoch [1/4])\n",
      "[415/2136] train loss: [0.5294] (epoch [1/4])\n",
      "[416/2136] train loss: [0.5599] (epoch [1/4])\n",
      "[417/2136] train loss: [0.5814] (epoch [1/4])\n",
      "[418/2136] train loss: [0.6265] (epoch [1/4])\n",
      "[419/2136] train loss: [0.5875] (epoch [1/4])\n",
      "[420/2136] train loss: [0.5969] (epoch [1/4])\n",
      "[421/2136] train loss: [0.5562] (epoch [1/4])\n",
      "[422/2136] train loss: [0.5542] (epoch [1/4])\n",
      "[423/2136] train loss: [0.6143] (epoch [1/4])\n",
      "[424/2136] train loss: [0.5312] (epoch [1/4])\n",
      "[425/2136] train loss: [0.5482] (epoch [1/4])\n",
      "[426/2136] train loss: [0.5496] (epoch [1/4])\n",
      "[427/2136] train loss: [0.6164] (epoch [1/4])\n",
      "[428/2136] train loss: [0.5965] (epoch [1/4])\n",
      "[429/2136] train loss: [0.5737] (epoch [1/4])\n",
      "[430/2136] train loss: [0.5265] (epoch [1/4])\n",
      "[431/2136] train loss: [0.5801] (epoch [1/4])\n",
      "[432/2136] train loss: [0.5393] (epoch [1/4])\n",
      "[433/2136] train loss: [0.5728] (epoch [1/4])\n",
      "[434/2136] train loss: [0.5791] (epoch [1/4])\n",
      "[435/2136] train loss: [0.5447] (epoch [1/4])\n",
      "[436/2136] train loss: [0.5011] (epoch [1/4])\n",
      "[437/2136] train loss: [0.6121] (epoch [1/4])\n",
      "[438/2136] train loss: [0.4730] (epoch [1/4])\n",
      "[439/2136] train loss: [0.5099] (epoch [1/4])\n",
      "[440/2136] train loss: [0.5829] (epoch [1/4])\n",
      "[441/2136] train loss: [0.6411] (epoch [1/4])\n",
      "[442/2136] train loss: [0.5253] (epoch [1/4])\n",
      "[443/2136] train loss: [0.5616] (epoch [1/4])\n",
      "[444/2136] train loss: [0.6798] (epoch [1/4])\n",
      "[445/2136] train loss: [0.5422] (epoch [1/4])\n",
      "[446/2136] train loss: [0.6639] (epoch [1/4])\n",
      "[447/2136] train loss: [0.4901] (epoch [1/4])\n",
      "[448/2136] train loss: [0.6125] (epoch [1/4])\n",
      "[449/2136] train loss: [0.5261] (epoch [1/4])\n",
      "[450/2136] train loss: [0.5301] (epoch [1/4])\n",
      "[451/2136] train loss: [0.6297] (epoch [1/4])\n",
      "[452/2136] train loss: [0.5088] (epoch [1/4])\n",
      "[453/2136] train loss: [0.5165] (epoch [1/4])\n",
      "[454/2136] train loss: [0.4951] (epoch [1/4])\n",
      "[455/2136] train loss: [0.4618] (epoch [1/4])\n",
      "[456/2136] train loss: [0.5686] (epoch [1/4])\n",
      "[457/2136] train loss: [0.6883] (epoch [1/4])\n",
      "[458/2136] train loss: [0.5808] (epoch [1/4])\n",
      "[459/2136] train loss: [0.4714] (epoch [1/4])\n",
      "[460/2136] train loss: [0.5120] (epoch [1/4])\n",
      "[461/2136] train loss: [0.5017] (epoch [1/4])\n",
      "[462/2136] train loss: [0.5626] (epoch [1/4])\n",
      "[463/2136] train loss: [0.5320] (epoch [1/4])\n",
      "[464/2136] train loss: [0.5892] (epoch [1/4])\n",
      "[465/2136] train loss: [0.4957] (epoch [1/4])\n",
      "[466/2136] train loss: [0.4733] (epoch [1/4])\n",
      "[467/2136] train loss: [0.5210] (epoch [1/4])\n",
      "[468/2136] train loss: [0.7678] (epoch [1/4])\n",
      "[469/2136] train loss: [0.4596] (epoch [1/4])\n",
      "[470/2136] train loss: [0.4071] (epoch [1/4])\n",
      "[471/2136] train loss: [0.4901] (epoch [1/4])\n",
      "[472/2136] train loss: [0.4045] (epoch [1/4])\n",
      "[473/2136] train loss: [0.5238] (epoch [1/4])\n",
      "[474/2136] train loss: [0.5911] (epoch [1/4])\n",
      "[475/2136] train loss: [0.6289] (epoch [1/4])\n",
      "[476/2136] train loss: [0.4294] (epoch [1/4])\n",
      "[477/2136] train loss: [0.4302] (epoch [1/4])\n",
      "[478/2136] train loss: [0.4678] (epoch [1/4])\n",
      "[479/2136] train loss: [0.5480] (epoch [1/4])\n",
      "[480/2136] train loss: [0.4061] (epoch [1/4])\n",
      "[481/2136] train loss: [0.4565] (epoch [1/4])\n",
      "[482/2136] train loss: [0.6491] (epoch [1/4])\n",
      "[483/2136] train loss: [0.5454] (epoch [1/4])\n",
      "[484/2136] train loss: [0.5100] (epoch [1/4])\n",
      "[485/2136] train loss: [0.4786] (epoch [1/4])\n",
      "[486/2136] train loss: [0.5794] (epoch [1/4])\n",
      "[487/2136] train loss: [0.4579] (epoch [1/4])\n",
      "[488/2136] train loss: [0.5165] (epoch [1/4])\n",
      "[489/2136] train loss: [0.4639] (epoch [1/4])\n",
      "[490/2136] train loss: [0.5052] (epoch [1/4])\n",
      "[491/2136] train loss: [0.4647] (epoch [1/4])\n",
      "[492/2136] train loss: [0.3989] (epoch [1/4])\n",
      "[493/2136] train loss: [0.4703] (epoch [1/4])\n",
      "[494/2136] train loss: [0.4256] (epoch [1/4])\n",
      "[495/2136] train loss: [0.5180] (epoch [1/4])\n",
      "[496/2136] train loss: [0.5030] (epoch [1/4])\n",
      "[497/2136] train loss: [0.4510] (epoch [1/4])\n",
      "[498/2136] train loss: [0.5018] (epoch [1/4])\n",
      "[499/2136] train loss: [0.5812] (epoch [1/4])\n",
      "[500/2136] train loss: [0.4915] (epoch [1/4])\n",
      "[501/2136] train loss: [0.4608] (epoch [1/4])\n",
      "[502/2136] train loss: [0.3909] (epoch [1/4])\n",
      "[503/2136] train loss: [0.3847] (epoch [1/4])\n",
      "[504/2136] train loss: [0.4398] (epoch [1/4])\n",
      "[505/2136] train loss: [0.5580] (epoch [1/4])\n",
      "[506/2136] train loss: [0.4337] (epoch [1/4])\n",
      "[507/2136] train loss: [0.4185] (epoch [1/4])\n",
      "[508/2136] train loss: [0.6661] (epoch [1/4])\n",
      "[509/2136] train loss: [0.4730] (epoch [1/4])\n",
      "[510/2136] train loss: [0.5916] (epoch [1/4])\n",
      "[511/2136] train loss: [0.4291] (epoch [1/4])\n",
      "[512/2136] train loss: [0.4103] (epoch [1/4])\n",
      "[513/2136] train loss: [0.4744] (epoch [1/4])\n",
      "[514/2136] train loss: [0.5519] (epoch [1/4])\n",
      "[515/2136] train loss: [0.5553] (epoch [1/4])\n",
      "[516/2136] train loss: [0.2806] (epoch [1/4])\n",
      "[517/2136] train loss: [0.3768] (epoch [1/4])\n",
      "[518/2136] train loss: [0.4765] (epoch [1/4])\n",
      "[519/2136] train loss: [0.5880] (epoch [1/4])\n",
      "[520/2136] train loss: [0.5144] (epoch [1/4])\n",
      "[521/2136] train loss: [0.4550] (epoch [1/4])\n",
      "[522/2136] train loss: [0.4711] (epoch [1/4])\n",
      "[523/2136] train loss: [0.4885] (epoch [1/4])\n",
      "[524/2136] train loss: [0.6104] (epoch [1/4])\n",
      "[525/2136] train loss: [0.3940] (epoch [1/4])\n",
      "[526/2136] train loss: [0.4447] (epoch [1/4])\n",
      "[527/2136] train loss: [0.5179] (epoch [1/4])\n",
      "[528/2136] train loss: [0.6622] (epoch [1/4])\n",
      "[529/2136] train loss: [0.5739] (epoch [1/4])\n",
      "[530/2136] train loss: [0.4447] (epoch [1/4])\n",
      "[531/2136] train loss: [0.5283] (epoch [1/4])\n",
      "[532/2136] train loss: [0.3928] (epoch [1/4])\n",
      "[533/2136] train loss: [0.3965] (epoch [1/4])\n",
      "[534/2136] train loss: [0.9156] (epoch [1/4])\n",
      "epoch [1/4] validation loss: [0.4285] validation accuracy: [0.8189493433395872]\n",
      "[535/2136] train loss: [0.6421] (epoch [2/4])\n",
      "[536/2136] train loss: [0.5159] (epoch [2/4])\n",
      "[537/2136] train loss: [0.5068] (epoch [2/4])\n",
      "[538/2136] train loss: [0.5282] (epoch [2/4])\n",
      "[539/2136] train loss: [0.5200] (epoch [2/4])\n",
      "[540/2136] train loss: [0.4208] (epoch [2/4])\n",
      "[541/2136] train loss: [0.5400] (epoch [2/4])\n",
      "[542/2136] train loss: [0.5473] (epoch [2/4])\n",
      "[543/2136] train loss: [0.5313] (epoch [2/4])\n",
      "[544/2136] train loss: [0.3305] (epoch [2/4])\n",
      "[545/2136] train loss: [0.4432] (epoch [2/4])\n",
      "[546/2136] train loss: [0.5563] (epoch [2/4])\n",
      "[547/2136] train loss: [0.5907] (epoch [2/4])\n",
      "[548/2136] train loss: [0.4862] (epoch [2/4])\n",
      "[549/2136] train loss: [0.2940] (epoch [2/4])\n",
      "[550/2136] train loss: [0.3627] (epoch [2/4])\n",
      "[551/2136] train loss: [0.3988] (epoch [2/4])\n",
      "[552/2136] train loss: [0.4698] (epoch [2/4])\n",
      "[553/2136] train loss: [0.3608] (epoch [2/4])\n",
      "[554/2136] train loss: [0.3754] (epoch [2/4])\n",
      "[555/2136] train loss: [0.2897] (epoch [2/4])\n",
      "[556/2136] train loss: [0.3408] (epoch [2/4])\n",
      "[557/2136] train loss: [0.2445] (epoch [2/4])\n",
      "[558/2136] train loss: [0.4893] (epoch [2/4])\n",
      "[559/2136] train loss: [0.3296] (epoch [2/4])\n",
      "[560/2136] train loss: [0.5987] (epoch [2/4])\n",
      "[561/2136] train loss: [0.3542] (epoch [2/4])\n",
      "[562/2136] train loss: [0.4221] (epoch [2/4])\n",
      "[563/2136] train loss: [0.2985] (epoch [2/4])\n",
      "[564/2136] train loss: [0.3295] (epoch [2/4])\n",
      "[565/2136] train loss: [0.5942] (epoch [2/4])\n",
      "[566/2136] train loss: [0.3246] (epoch [2/4])\n",
      "[567/2136] train loss: [0.3953] (epoch [2/4])\n",
      "[568/2136] train loss: [0.3326] (epoch [2/4])\n",
      "[569/2136] train loss: [0.4591] (epoch [2/4])\n",
      "[570/2136] train loss: [0.4218] (epoch [2/4])\n",
      "[571/2136] train loss: [0.5013] (epoch [2/4])\n",
      "[572/2136] train loss: [0.4994] (epoch [2/4])\n",
      "[573/2136] train loss: [0.3238] (epoch [2/4])\n",
      "[574/2136] train loss: [0.4874] (epoch [2/4])\n",
      "[575/2136] train loss: [0.3490] (epoch [2/4])\n",
      "[576/2136] train loss: [0.3016] (epoch [2/4])\n",
      "[577/2136] train loss: [0.3838] (epoch [2/4])\n",
      "[578/2136] train loss: [0.4190] (epoch [2/4])\n",
      "[579/2136] train loss: [0.4283] (epoch [2/4])\n",
      "[580/2136] train loss: [0.6444] (epoch [2/4])\n",
      "[581/2136] train loss: [0.3596] (epoch [2/4])\n",
      "[582/2136] train loss: [0.2693] (epoch [2/4])\n",
      "[583/2136] train loss: [0.5626] (epoch [2/4])\n",
      "[584/2136] train loss: [0.3695] (epoch [2/4])\n",
      "[585/2136] train loss: [0.2826] (epoch [2/4])\n",
      "[586/2136] train loss: [0.4631] (epoch [2/4])\n",
      "[587/2136] train loss: [0.3440] (epoch [2/4])\n",
      "[588/2136] train loss: [0.2951] (epoch [2/4])\n",
      "[589/2136] train loss: [0.4936] (epoch [2/4])\n",
      "[590/2136] train loss: [0.5063] (epoch [2/4])\n",
      "[591/2136] train loss: [0.5538] (epoch [2/4])\n",
      "[592/2136] train loss: [0.5207] (epoch [2/4])\n",
      "[593/2136] train loss: [0.3923] (epoch [2/4])\n",
      "[594/2136] train loss: [0.3670] (epoch [2/4])\n",
      "[595/2136] train loss: [0.2765] (epoch [2/4])\n",
      "[596/2136] train loss: [0.6675] (epoch [2/4])\n",
      "[597/2136] train loss: [0.4878] (epoch [2/4])\n",
      "[598/2136] train loss: [0.4624] (epoch [2/4])\n",
      "[599/2136] train loss: [0.2567] (epoch [2/4])\n",
      "[600/2136] train loss: [0.3023] (epoch [2/4])\n",
      "[601/2136] train loss: [0.4106] (epoch [2/4])\n",
      "[602/2136] train loss: [0.5439] (epoch [2/4])\n",
      "[603/2136] train loss: [0.5751] (epoch [2/4])\n",
      "[604/2136] train loss: [0.3217] (epoch [2/4])\n",
      "[605/2136] train loss: [0.4714] (epoch [2/4])\n",
      "[606/2136] train loss: [0.5205] (epoch [2/4])\n",
      "[607/2136] train loss: [0.5355] (epoch [2/4])\n",
      "[608/2136] train loss: [0.4530] (epoch [2/4])\n",
      "[609/2136] train loss: [0.3247] (epoch [2/4])\n",
      "[610/2136] train loss: [0.3842] (epoch [2/4])\n",
      "[611/2136] train loss: [0.4851] (epoch [2/4])\n",
      "[612/2136] train loss: [0.3949] (epoch [2/4])\n",
      "[613/2136] train loss: [0.3276] (epoch [2/4])\n",
      "[614/2136] train loss: [0.5089] (epoch [2/4])\n",
      "[615/2136] train loss: [0.5502] (epoch [2/4])\n",
      "[616/2136] train loss: [0.3261] (epoch [2/4])\n",
      "[617/2136] train loss: [0.5035] (epoch [2/4])\n",
      "[618/2136] train loss: [0.4151] (epoch [2/4])\n",
      "[619/2136] train loss: [0.3925] (epoch [2/4])\n",
      "[620/2136] train loss: [0.5036] (epoch [2/4])\n",
      "[621/2136] train loss: [0.4276] (epoch [2/4])\n",
      "[622/2136] train loss: [0.4824] (epoch [2/4])\n",
      "[623/2136] train loss: [0.4330] (epoch [2/4])\n",
      "[624/2136] train loss: [0.3506] (epoch [2/4])\n",
      "[625/2136] train loss: [0.3400] (epoch [2/4])\n",
      "[626/2136] train loss: [0.4227] (epoch [2/4])\n",
      "[627/2136] train loss: [0.4782] (epoch [2/4])\n",
      "[628/2136] train loss: [0.4553] (epoch [2/4])\n",
      "[629/2136] train loss: [0.3676] (epoch [2/4])\n",
      "[630/2136] train loss: [0.3940] (epoch [2/4])\n",
      "[631/2136] train loss: [0.6838] (epoch [2/4])\n",
      "[632/2136] train loss: [0.3403] (epoch [2/4])\n",
      "[633/2136] train loss: [0.5089] (epoch [2/4])\n",
      "[634/2136] train loss: [0.4144] (epoch [2/4])\n",
      "[635/2136] train loss: [0.4073] (epoch [2/4])\n",
      "[636/2136] train loss: [0.4077] (epoch [2/4])\n",
      "[637/2136] train loss: [0.4436] (epoch [2/4])\n",
      "[638/2136] train loss: [0.5970] (epoch [2/4])\n",
      "[639/2136] train loss: [0.3696] (epoch [2/4])\n",
      "[640/2136] train loss: [0.3977] (epoch [2/4])\n",
      "[641/2136] train loss: [0.5855] (epoch [2/4])\n",
      "[642/2136] train loss: [0.3064] (epoch [2/4])\n",
      "[643/2136] train loss: [0.2782] (epoch [2/4])\n",
      "[644/2136] train loss: [0.7440] (epoch [2/4])\n",
      "[645/2136] train loss: [0.2671] (epoch [2/4])\n",
      "[646/2136] train loss: [0.4413] (epoch [2/4])\n",
      "[647/2136] train loss: [0.3413] (epoch [2/4])\n",
      "[648/2136] train loss: [0.5082] (epoch [2/4])\n",
      "[649/2136] train loss: [0.2280] (epoch [2/4])\n",
      "[650/2136] train loss: [0.4773] (epoch [2/4])\n",
      "[651/2136] train loss: [0.5491] (epoch [2/4])\n",
      "[652/2136] train loss: [0.5631] (epoch [2/4])\n",
      "[653/2136] train loss: [0.3137] (epoch [2/4])\n",
      "[654/2136] train loss: [0.2355] (epoch [2/4])\n",
      "[655/2136] train loss: [0.5298] (epoch [2/4])\n",
      "[656/2136] train loss: [0.3481] (epoch [2/4])\n",
      "[657/2136] train loss: [0.2154] (epoch [2/4])\n",
      "[658/2136] train loss: [0.3542] (epoch [2/4])\n",
      "[659/2136] train loss: [0.5588] (epoch [2/4])\n",
      "[660/2136] train loss: [0.4733] (epoch [2/4])\n",
      "[661/2136] train loss: [0.3615] (epoch [2/4])\n",
      "[662/2136] train loss: [0.3351] (epoch [2/4])\n",
      "[663/2136] train loss: [0.1878] (epoch [2/4])\n",
      "[664/2136] train loss: [0.2988] (epoch [2/4])\n",
      "[665/2136] train loss: [0.4225] (epoch [2/4])\n",
      "[666/2136] train loss: [0.3814] (epoch [2/4])\n",
      "[667/2136] train loss: [0.4278] (epoch [2/4])\n",
      "[668/2136] train loss: [0.4998] (epoch [2/4])\n",
      "[669/2136] train loss: [0.3733] (epoch [2/4])\n",
      "[670/2136] train loss: [0.3320] (epoch [2/4])\n",
      "[671/2136] train loss: [0.2781] (epoch [2/4])\n",
      "[672/2136] train loss: [0.2627] (epoch [2/4])\n",
      "[673/2136] train loss: [0.2976] (epoch [2/4])\n",
      "[674/2136] train loss: [0.5588] (epoch [2/4])\n",
      "[675/2136] train loss: [0.2342] (epoch [2/4])\n",
      "[676/2136] train loss: [0.3957] (epoch [2/4])\n",
      "[677/2136] train loss: [0.5964] (epoch [2/4])\n",
      "[678/2136] train loss: [0.5454] (epoch [2/4])\n",
      "[679/2136] train loss: [0.3749] (epoch [2/4])\n",
      "[680/2136] train loss: [0.5520] (epoch [2/4])\n",
      "[681/2136] train loss: [0.4574] (epoch [2/4])\n",
      "[682/2136] train loss: [0.4759] (epoch [2/4])\n",
      "[683/2136] train loss: [0.2096] (epoch [2/4])\n",
      "[684/2136] train loss: [0.3537] (epoch [2/4])\n",
      "[685/2136] train loss: [0.3045] (epoch [2/4])\n",
      "[686/2136] train loss: [0.3049] (epoch [2/4])\n",
      "[687/2136] train loss: [0.2942] (epoch [2/4])\n",
      "[688/2136] train loss: [0.5695] (epoch [2/4])\n",
      "[689/2136] train loss: [0.4584] (epoch [2/4])\n",
      "[690/2136] train loss: [0.4517] (epoch [2/4])\n",
      "[691/2136] train loss: [0.3760] (epoch [2/4])\n",
      "[692/2136] train loss: [0.3597] (epoch [2/4])\n",
      "[693/2136] train loss: [0.4783] (epoch [2/4])\n",
      "[694/2136] train loss: [0.4090] (epoch [2/4])\n",
      "[695/2136] train loss: [0.4714] (epoch [2/4])\n",
      "[696/2136] train loss: [0.2703] (epoch [2/4])\n",
      "[697/2136] train loss: [0.2933] (epoch [2/4])\n",
      "[698/2136] train loss: [0.3691] (epoch [2/4])\n",
      "[699/2136] train loss: [0.3548] (epoch [2/4])\n",
      "[700/2136] train loss: [0.3335] (epoch [2/4])\n",
      "[701/2136] train loss: [0.7215] (epoch [2/4])\n",
      "[702/2136] train loss: [0.1552] (epoch [2/4])\n",
      "[703/2136] train loss: [0.3239] (epoch [2/4])\n",
      "[704/2136] train loss: [0.5002] (epoch [2/4])\n",
      "[705/2136] train loss: [0.2826] (epoch [2/4])\n",
      "[706/2136] train loss: [0.3134] (epoch [2/4])\n",
      "[707/2136] train loss: [0.2217] (epoch [2/4])\n",
      "[708/2136] train loss: [0.3320] (epoch [2/4])\n",
      "[709/2136] train loss: [0.5053] (epoch [2/4])\n",
      "[710/2136] train loss: [0.5217] (epoch [2/4])\n",
      "[711/2136] train loss: [0.2703] (epoch [2/4])\n",
      "[712/2136] train loss: [0.4204] (epoch [2/4])\n",
      "[713/2136] train loss: [0.3110] (epoch [2/4])\n",
      "[714/2136] train loss: [0.4279] (epoch [2/4])\n",
      "[715/2136] train loss: [0.3678] (epoch [2/4])\n",
      "[716/2136] train loss: [0.4691] (epoch [2/4])\n",
      "[717/2136] train loss: [0.5154] (epoch [2/4])\n",
      "[718/2136] train loss: [0.5479] (epoch [2/4])\n",
      "[719/2136] train loss: [0.5824] (epoch [2/4])\n",
      "[720/2136] train loss: [0.4987] (epoch [2/4])\n",
      "[721/2136] train loss: [0.3969] (epoch [2/4])\n",
      "[722/2136] train loss: [0.5469] (epoch [2/4])\n",
      "[723/2136] train loss: [0.2989] (epoch [2/4])\n",
      "[724/2136] train loss: [0.5739] (epoch [2/4])\n",
      "[725/2136] train loss: [0.2904] (epoch [2/4])\n",
      "[726/2136] train loss: [0.2828] (epoch [2/4])\n",
      "[727/2136] train loss: [0.4632] (epoch [2/4])\n",
      "[728/2136] train loss: [0.3247] (epoch [2/4])\n",
      "[729/2136] train loss: [0.2505] (epoch [2/4])\n",
      "[730/2136] train loss: [0.4579] (epoch [2/4])\n",
      "[731/2136] train loss: [0.4270] (epoch [2/4])\n",
      "[732/2136] train loss: [0.3739] (epoch [2/4])\n",
      "[733/2136] train loss: [0.3308] (epoch [2/4])\n",
      "[734/2136] train loss: [0.4863] (epoch [2/4])\n",
      "[735/2136] train loss: [0.4200] (epoch [2/4])\n",
      "[736/2136] train loss: [0.1976] (epoch [2/4])\n",
      "[737/2136] train loss: [0.1722] (epoch [2/4])\n",
      "[738/2136] train loss: [0.5233] (epoch [2/4])\n",
      "[739/2136] train loss: [0.5873] (epoch [2/4])\n",
      "[740/2136] train loss: [0.2227] (epoch [2/4])\n",
      "[741/2136] train loss: [0.3931] (epoch [2/4])\n",
      "[742/2136] train loss: [0.2045] (epoch [2/4])\n",
      "[743/2136] train loss: [0.3900] (epoch [2/4])\n",
      "[744/2136] train loss: [0.4355] (epoch [2/4])\n",
      "[745/2136] train loss: [0.2553] (epoch [2/4])\n",
      "[746/2136] train loss: [0.5141] (epoch [2/4])\n",
      "[747/2136] train loss: [0.2499] (epoch [2/4])\n",
      "[748/2136] train loss: [0.5238] (epoch [2/4])\n",
      "[749/2136] train loss: [0.3654] (epoch [2/4])\n",
      "[750/2136] train loss: [0.4778] (epoch [2/4])\n",
      "[751/2136] train loss: [0.2302] (epoch [2/4])\n",
      "[752/2136] train loss: [0.4570] (epoch [2/4])\n",
      "[753/2136] train loss: [0.4838] (epoch [2/4])\n",
      "[754/2136] train loss: [0.5423] (epoch [2/4])\n",
      "[755/2136] train loss: [0.9529] (epoch [2/4])\n",
      "[756/2136] train loss: [0.1568] (epoch [2/4])\n",
      "[757/2136] train loss: [0.4438] (epoch [2/4])\n",
      "[758/2136] train loss: [0.4034] (epoch [2/4])\n",
      "[759/2136] train loss: [0.2377] (epoch [2/4])\n",
      "[760/2136] train loss: [0.4991] (epoch [2/4])\n",
      "[761/2136] train loss: [0.1755] (epoch [2/4])\n",
      "[762/2136] train loss: [0.3256] (epoch [2/4])\n",
      "[763/2136] train loss: [0.3567] (epoch [2/4])\n",
      "[764/2136] train loss: [0.3529] (epoch [2/4])\n",
      "[765/2136] train loss: [0.6968] (epoch [2/4])\n",
      "[766/2136] train loss: [0.4820] (epoch [2/4])\n",
      "[767/2136] train loss: [0.2516] (epoch [2/4])\n",
      "[768/2136] train loss: [0.2613] (epoch [2/4])\n",
      "[769/2136] train loss: [0.3425] (epoch [2/4])\n",
      "[770/2136] train loss: [0.4127] (epoch [2/4])\n",
      "[771/2136] train loss: [0.4445] (epoch [2/4])\n",
      "[772/2136] train loss: [0.5250] (epoch [2/4])\n",
      "[773/2136] train loss: [0.4381] (epoch [2/4])\n",
      "[774/2136] train loss: [0.3580] (epoch [2/4])\n",
      "[775/2136] train loss: [0.4673] (epoch [2/4])\n",
      "[776/2136] train loss: [0.2867] (epoch [2/4])\n",
      "[777/2136] train loss: [0.3080] (epoch [2/4])\n",
      "[778/2136] train loss: [0.3732] (epoch [2/4])\n",
      "[779/2136] train loss: [0.2542] (epoch [2/4])\n",
      "[780/2136] train loss: [0.4686] (epoch [2/4])\n",
      "[781/2136] train loss: [0.4739] (epoch [2/4])\n",
      "[782/2136] train loss: [0.6411] (epoch [2/4])\n",
      "[783/2136] train loss: [0.3067] (epoch [2/4])\n",
      "[784/2136] train loss: [0.2867] (epoch [2/4])\n",
      "[785/2136] train loss: [0.1547] (epoch [2/4])\n",
      "[786/2136] train loss: [0.4054] (epoch [2/4])\n",
      "[787/2136] train loss: [0.4915] (epoch [2/4])\n",
      "[788/2136] train loss: [0.3450] (epoch [2/4])\n",
      "[789/2136] train loss: [0.4724] (epoch [2/4])\n",
      "[790/2136] train loss: [0.2519] (epoch [2/4])\n",
      "[791/2136] train loss: [0.4429] (epoch [2/4])\n",
      "[792/2136] train loss: [0.2391] (epoch [2/4])\n",
      "[793/2136] train loss: [0.3401] (epoch [2/4])\n",
      "[794/2136] train loss: [0.3311] (epoch [2/4])\n",
      "[795/2136] train loss: [0.4929] (epoch [2/4])\n",
      "[796/2136] train loss: [0.7414] (epoch [2/4])\n",
      "[797/2136] train loss: [0.2358] (epoch [2/4])\n",
      "[798/2136] train loss: [0.2358] (epoch [2/4])\n",
      "[799/2136] train loss: [0.4208] (epoch [2/4])\n",
      "[800/2136] train loss: [0.4122] (epoch [2/4])\n",
      "[801/2136] train loss: [0.4586] (epoch [2/4])\n",
      "[802/2136] train loss: [0.2199] (epoch [2/4])\n",
      "[803/2136] train loss: [0.5070] (epoch [2/4])\n",
      "[804/2136] train loss: [0.3807] (epoch [2/4])\n",
      "[805/2136] train loss: [0.3961] (epoch [2/4])\n",
      "[806/2136] train loss: [0.4736] (epoch [2/4])\n",
      "[807/2136] train loss: [0.3883] (epoch [2/4])\n",
      "[808/2136] train loss: [0.3232] (epoch [2/4])\n",
      "[809/2136] train loss: [0.2563] (epoch [2/4])\n",
      "[810/2136] train loss: [0.3246] (epoch [2/4])\n",
      "[811/2136] train loss: [0.5832] (epoch [2/4])\n",
      "[812/2136] train loss: [0.3897] (epoch [2/4])\n",
      "[813/2136] train loss: [0.2492] (epoch [2/4])\n",
      "[814/2136] train loss: [0.2296] (epoch [2/4])\n",
      "[815/2136] train loss: [0.3471] (epoch [2/4])\n",
      "[816/2136] train loss: [0.3337] (epoch [2/4])\n",
      "[817/2136] train loss: [0.3564] (epoch [2/4])\n",
      "[818/2136] train loss: [0.5522] (epoch [2/4])\n",
      "[819/2136] train loss: [0.4858] (epoch [2/4])\n",
      "[820/2136] train loss: [0.5647] (epoch [2/4])\n",
      "[821/2136] train loss: [0.4150] (epoch [2/4])\n",
      "[822/2136] train loss: [0.5909] (epoch [2/4])\n",
      "[823/2136] train loss: [0.4258] (epoch [2/4])\n",
      "[824/2136] train loss: [0.3206] (epoch [2/4])\n",
      "[825/2136] train loss: [0.3360] (epoch [2/4])\n",
      "[826/2136] train loss: [0.5047] (epoch [2/4])\n",
      "[827/2136] train loss: [0.3487] (epoch [2/4])\n",
      "[828/2136] train loss: [0.3718] (epoch [2/4])\n",
      "[829/2136] train loss: [0.4795] (epoch [2/4])\n",
      "[830/2136] train loss: [0.4012] (epoch [2/4])\n",
      "[831/2136] train loss: [0.4189] (epoch [2/4])\n",
      "[832/2136] train loss: [0.5131] (epoch [2/4])\n",
      "[833/2136] train loss: [0.2356] (epoch [2/4])\n",
      "[834/2136] train loss: [0.3800] (epoch [2/4])\n",
      "[835/2136] train loss: [0.4591] (epoch [2/4])\n",
      "[836/2136] train loss: [0.3932] (epoch [2/4])\n",
      "[837/2136] train loss: [0.2612] (epoch [2/4])\n",
      "[838/2136] train loss: [0.2049] (epoch [2/4])\n",
      "[839/2136] train loss: [0.4055] (epoch [2/4])\n",
      "[840/2136] train loss: [0.4859] (epoch [2/4])\n",
      "[841/2136] train loss: [0.2476] (epoch [2/4])\n",
      "[842/2136] train loss: [0.5480] (epoch [2/4])\n",
      "[843/2136] train loss: [0.3677] (epoch [2/4])\n",
      "[844/2136] train loss: [0.7018] (epoch [2/4])\n",
      "[845/2136] train loss: [0.3248] (epoch [2/4])\n",
      "[846/2136] train loss: [0.5120] (epoch [2/4])\n",
      "[847/2136] train loss: [0.5379] (epoch [2/4])\n",
      "[848/2136] train loss: [0.3607] (epoch [2/4])\n",
      "[849/2136] train loss: [0.2153] (epoch [2/4])\n",
      "[850/2136] train loss: [0.3564] (epoch [2/4])\n",
      "[851/2136] train loss: [0.4574] (epoch [2/4])\n",
      "[852/2136] train loss: [0.3453] (epoch [2/4])\n",
      "[853/2136] train loss: [0.4595] (epoch [2/4])\n",
      "[854/2136] train loss: [0.4023] (epoch [2/4])\n",
      "[855/2136] train loss: [0.1190] (epoch [2/4])\n",
      "[856/2136] train loss: [0.4109] (epoch [2/4])\n",
      "[857/2136] train loss: [0.3172] (epoch [2/4])\n",
      "[858/2136] train loss: [0.4268] (epoch [2/4])\n",
      "[859/2136] train loss: [0.3050] (epoch [2/4])\n",
      "[860/2136] train loss: [0.2362] (epoch [2/4])\n",
      "[861/2136] train loss: [0.3718] (epoch [2/4])\n",
      "[862/2136] train loss: [0.6042] (epoch [2/4])\n",
      "[863/2136] train loss: [0.5292] (epoch [2/4])\n",
      "[864/2136] train loss: [0.2894] (epoch [2/4])\n",
      "[865/2136] train loss: [0.4584] (epoch [2/4])\n",
      "[866/2136] train loss: [0.6280] (epoch [2/4])\n",
      "[867/2136] train loss: [0.2124] (epoch [2/4])\n",
      "[868/2136] train loss: [0.4059] (epoch [2/4])\n",
      "[869/2136] train loss: [0.1837] (epoch [2/4])\n",
      "[870/2136] train loss: [0.3206] (epoch [2/4])\n",
      "[871/2136] train loss: [0.3734] (epoch [2/4])\n",
      "[872/2136] train loss: [0.3643] (epoch [2/4])\n",
      "[873/2136] train loss: [0.5103] (epoch [2/4])\n",
      "[874/2136] train loss: [0.3076] (epoch [2/4])\n",
      "[875/2136] train loss: [0.6040] (epoch [2/4])\n",
      "[876/2136] train loss: [0.1843] (epoch [2/4])\n",
      "[877/2136] train loss: [0.2022] (epoch [2/4])\n",
      "[878/2136] train loss: [0.3221] (epoch [2/4])\n",
      "[879/2136] train loss: [0.7405] (epoch [2/4])\n",
      "[880/2136] train loss: [0.4833] (epoch [2/4])\n",
      "[881/2136] train loss: [0.4630] (epoch [2/4])\n",
      "[882/2136] train loss: [0.2651] (epoch [2/4])\n",
      "[883/2136] train loss: [0.4658] (epoch [2/4])\n",
      "[884/2136] train loss: [0.5029] (epoch [2/4])\n",
      "[885/2136] train loss: [0.3516] (epoch [2/4])\n",
      "[886/2136] train loss: [0.3669] (epoch [2/4])\n",
      "[887/2136] train loss: [0.3792] (epoch [2/4])\n",
      "[888/2136] train loss: [0.5305] (epoch [2/4])\n",
      "[889/2136] train loss: [0.4491] (epoch [2/4])\n",
      "[890/2136] train loss: [0.1975] (epoch [2/4])\n",
      "[891/2136] train loss: [0.4998] (epoch [2/4])\n",
      "[892/2136] train loss: [0.3123] (epoch [2/4])\n",
      "[893/2136] train loss: [0.3676] (epoch [2/4])\n",
      "[894/2136] train loss: [0.5015] (epoch [2/4])\n",
      "[895/2136] train loss: [0.5328] (epoch [2/4])\n",
      "[896/2136] train loss: [0.2914] (epoch [2/4])\n",
      "[897/2136] train loss: [0.5348] (epoch [2/4])\n",
      "[898/2136] train loss: [0.4463] (epoch [2/4])\n",
      "[899/2136] train loss: [0.4165] (epoch [2/4])\n",
      "[900/2136] train loss: [0.4039] (epoch [2/4])\n",
      "[901/2136] train loss: [0.4104] (epoch [2/4])\n",
      "[902/2136] train loss: [0.4886] (epoch [2/4])\n",
      "[903/2136] train loss: [0.3990] (epoch [2/4])\n",
      "[904/2136] train loss: [0.5205] (epoch [2/4])\n",
      "[905/2136] train loss: [0.3849] (epoch [2/4])\n",
      "[906/2136] train loss: [0.3568] (epoch [2/4])\n",
      "[907/2136] train loss: [0.3032] (epoch [2/4])\n",
      "[908/2136] train loss: [0.4125] (epoch [2/4])\n",
      "[909/2136] train loss: [0.4392] (epoch [2/4])\n",
      "[910/2136] train loss: [0.5485] (epoch [2/4])\n",
      "[911/2136] train loss: [0.2486] (epoch [2/4])\n",
      "[912/2136] train loss: [0.3565] (epoch [2/4])\n",
      "[913/2136] train loss: [0.4974] (epoch [2/4])\n",
      "[914/2136] train loss: [0.4394] (epoch [2/4])\n",
      "[915/2136] train loss: [0.5411] (epoch [2/4])\n",
      "[916/2136] train loss: [0.4322] (epoch [2/4])\n",
      "[917/2136] train loss: [0.3891] (epoch [2/4])\n",
      "[918/2136] train loss: [0.3752] (epoch [2/4])\n",
      "[919/2136] train loss: [0.3641] (epoch [2/4])\n",
      "[920/2136] train loss: [0.1719] (epoch [2/4])\n",
      "[921/2136] train loss: [0.5227] (epoch [2/4])\n",
      "[922/2136] train loss: [0.5139] (epoch [2/4])\n",
      "[923/2136] train loss: [0.2964] (epoch [2/4])\n",
      "[924/2136] train loss: [0.4136] (epoch [2/4])\n",
      "[925/2136] train loss: [0.4355] (epoch [2/4])\n",
      "[926/2136] train loss: [0.2949] (epoch [2/4])\n",
      "[927/2136] train loss: [0.3284] (epoch [2/4])\n",
      "[928/2136] train loss: [0.4823] (epoch [2/4])\n",
      "[929/2136] train loss: [0.2063] (epoch [2/4])\n",
      "[930/2136] train loss: [0.6154] (epoch [2/4])\n",
      "[931/2136] train loss: [0.4514] (epoch [2/4])\n",
      "[932/2136] train loss: [0.4405] (epoch [2/4])\n",
      "[933/2136] train loss: [0.4470] (epoch [2/4])\n",
      "[934/2136] train loss: [0.2533] (epoch [2/4])\n",
      "[935/2136] train loss: [0.2945] (epoch [2/4])\n",
      "[936/2136] train loss: [0.5079] (epoch [2/4])\n",
      "[937/2136] train loss: [0.2170] (epoch [2/4])\n",
      "[938/2136] train loss: [0.3616] (epoch [2/4])\n",
      "[939/2136] train loss: [0.5529] (epoch [2/4])\n",
      "[940/2136] train loss: [0.2454] (epoch [2/4])\n",
      "[941/2136] train loss: [0.5421] (epoch [2/4])\n",
      "[942/2136] train loss: [0.1659] (epoch [2/4])\n",
      "[943/2136] train loss: [0.2609] (epoch [2/4])\n",
      "[944/2136] train loss: [0.4705] (epoch [2/4])\n",
      "[945/2136] train loss: [0.3434] (epoch [2/4])\n",
      "[946/2136] train loss: [0.1871] (epoch [2/4])\n",
      "[947/2136] train loss: [0.2620] (epoch [2/4])\n",
      "[948/2136] train loss: [0.4245] (epoch [2/4])\n",
      "[949/2136] train loss: [0.2997] (epoch [2/4])\n",
      "[950/2136] train loss: [0.4576] (epoch [2/4])\n",
      "[951/2136] train loss: [0.4650] (epoch [2/4])\n",
      "[952/2136] train loss: [0.2598] (epoch [2/4])\n",
      "[953/2136] train loss: [0.4809] (epoch [2/4])\n",
      "[954/2136] train loss: [0.3478] (epoch [2/4])\n",
      "[955/2136] train loss: [0.2531] (epoch [2/4])\n",
      "[956/2136] train loss: [0.3987] (epoch [2/4])\n",
      "[957/2136] train loss: [0.2781] (epoch [2/4])\n",
      "[958/2136] train loss: [0.2770] (epoch [2/4])\n",
      "[959/2136] train loss: [0.2557] (epoch [2/4])\n",
      "[960/2136] train loss: [0.3252] (epoch [2/4])\n",
      "[961/2136] train loss: [0.2907] (epoch [2/4])\n",
      "[962/2136] train loss: [0.8338] (epoch [2/4])\n",
      "[963/2136] train loss: [0.3524] (epoch [2/4])\n",
      "[964/2136] train loss: [0.5828] (epoch [2/4])\n",
      "[965/2136] train loss: [0.2173] (epoch [2/4])\n",
      "[966/2136] train loss: [0.3799] (epoch [2/4])\n",
      "[967/2136] train loss: [0.4908] (epoch [2/4])\n",
      "[968/2136] train loss: [0.3104] (epoch [2/4])\n",
      "[969/2136] train loss: [0.3329] (epoch [2/4])\n",
      "[970/2136] train loss: [0.3960] (epoch [2/4])\n",
      "[971/2136] train loss: [0.5966] (epoch [2/4])\n",
      "[972/2136] train loss: [0.3238] (epoch [2/4])\n",
      "[973/2136] train loss: [0.5596] (epoch [2/4])\n",
      "[974/2136] train loss: [0.2343] (epoch [2/4])\n",
      "[975/2136] train loss: [0.3673] (epoch [2/4])\n",
      "[976/2136] train loss: [0.4937] (epoch [2/4])\n",
      "[977/2136] train loss: [0.3601] (epoch [2/4])\n",
      "[978/2136] train loss: [0.3656] (epoch [2/4])\n",
      "[979/2136] train loss: [0.3868] (epoch [2/4])\n",
      "[980/2136] train loss: [0.4747] (epoch [2/4])\n",
      "[981/2136] train loss: [0.3596] (epoch [2/4])\n",
      "[982/2136] train loss: [0.5097] (epoch [2/4])\n",
      "[983/2136] train loss: [0.3257] (epoch [2/4])\n",
      "[984/2136] train loss: [0.3547] (epoch [2/4])\n",
      "[985/2136] train loss: [0.4345] (epoch [2/4])\n",
      "[986/2136] train loss: [0.5475] (epoch [2/4])\n",
      "[987/2136] train loss: [0.3404] (epoch [2/4])\n",
      "[988/2136] train loss: [0.4846] (epoch [2/4])\n",
      "[989/2136] train loss: [0.3427] (epoch [2/4])\n",
      "[990/2136] train loss: [0.3912] (epoch [2/4])\n",
      "[991/2136] train loss: [0.2565] (epoch [2/4])\n",
      "[992/2136] train loss: [0.6059] (epoch [2/4])\n",
      "[993/2136] train loss: [0.3448] (epoch [2/4])\n",
      "[994/2136] train loss: [0.5373] (epoch [2/4])\n",
      "[995/2136] train loss: [0.2015] (epoch [2/4])\n",
      "[996/2136] train loss: [0.2673] (epoch [2/4])\n",
      "[997/2136] train loss: [0.2870] (epoch [2/4])\n",
      "[998/2136] train loss: [0.3476] (epoch [2/4])\n",
      "[999/2136] train loss: [0.5124] (epoch [2/4])\n",
      "[1000/2136] train loss: [0.3772] (epoch [2/4])\n",
      "[1001/2136] train loss: [0.2194] (epoch [2/4])\n",
      "[1002/2136] train loss: [0.2160] (epoch [2/4])\n",
      "[1003/2136] train loss: [0.2816] (epoch [2/4])\n",
      "[1004/2136] train loss: [0.5047] (epoch [2/4])\n",
      "[1005/2136] train loss: [0.5408] (epoch [2/4])\n",
      "[1006/2136] train loss: [0.1805] (epoch [2/4])\n",
      "[1007/2136] train loss: [0.2062] (epoch [2/4])\n",
      "[1008/2136] train loss: [0.2089] (epoch [2/4])\n",
      "[1009/2136] train loss: [0.5526] (epoch [2/4])\n",
      "[1010/2136] train loss: [0.2826] (epoch [2/4])\n",
      "[1011/2136] train loss: [0.3518] (epoch [2/4])\n",
      "[1012/2136] train loss: [0.5519] (epoch [2/4])\n",
      "[1013/2136] train loss: [0.2391] (epoch [2/4])\n",
      "[1014/2136] train loss: [0.2290] (epoch [2/4])\n",
      "[1015/2136] train loss: [0.2420] (epoch [2/4])\n",
      "[1016/2136] train loss: [0.4635] (epoch [2/4])\n",
      "[1017/2136] train loss: [0.4267] (epoch [2/4])\n",
      "[1018/2136] train loss: [0.2337] (epoch [2/4])\n",
      "[1019/2136] train loss: [0.2515] (epoch [2/4])\n",
      "[1020/2136] train loss: [0.2089] (epoch [2/4])\n",
      "[1021/2136] train loss: [0.3338] (epoch [2/4])\n",
      "[1022/2136] train loss: [0.2920] (epoch [2/4])\n",
      "[1023/2136] train loss: [0.4286] (epoch [2/4])\n",
      "[1024/2136] train loss: [0.3650] (epoch [2/4])\n",
      "[1025/2136] train loss: [0.2534] (epoch [2/4])\n",
      "[1026/2136] train loss: [0.2389] (epoch [2/4])\n",
      "[1027/2136] train loss: [0.1784] (epoch [2/4])\n",
      "[1028/2136] train loss: [0.5714] (epoch [2/4])\n",
      "[1029/2136] train loss: [0.3187] (epoch [2/4])\n",
      "[1030/2136] train loss: [0.5481] (epoch [2/4])\n",
      "[1031/2136] train loss: [0.1428] (epoch [2/4])\n",
      "[1032/2136] train loss: [0.2138] (epoch [2/4])\n",
      "[1033/2136] train loss: [0.3985] (epoch [2/4])\n",
      "[1034/2136] train loss: [0.4715] (epoch [2/4])\n",
      "[1035/2136] train loss: [0.1304] (epoch [2/4])\n",
      "[1036/2136] train loss: [0.4534] (epoch [2/4])\n",
      "[1037/2136] train loss: [0.4125] (epoch [2/4])\n",
      "[1038/2136] train loss: [0.1502] (epoch [2/4])\n",
      "[1039/2136] train loss: [0.3577] (epoch [2/4])\n",
      "[1040/2136] train loss: [0.4915] (epoch [2/4])\n",
      "[1041/2136] train loss: [0.5766] (epoch [2/4])\n",
      "[1042/2136] train loss: [0.3992] (epoch [2/4])\n",
      "[1043/2136] train loss: [0.2411] (epoch [2/4])\n",
      "[1044/2136] train loss: [0.5051] (epoch [2/4])\n",
      "[1045/2136] train loss: [0.2216] (epoch [2/4])\n",
      "[1046/2136] train loss: [0.3718] (epoch [2/4])\n",
      "[1047/2136] train loss: [0.3672] (epoch [2/4])\n",
      "[1048/2136] train loss: [0.5760] (epoch [2/4])\n",
      "[1049/2136] train loss: [0.1706] (epoch [2/4])\n",
      "[1050/2136] train loss: [0.4626] (epoch [2/4])\n",
      "[1051/2136] train loss: [0.2719] (epoch [2/4])\n",
      "[1052/2136] train loss: [0.3388] (epoch [2/4])\n",
      "[1053/2136] train loss: [0.1105] (epoch [2/4])\n",
      "[1054/2136] train loss: [0.5539] (epoch [2/4])\n",
      "[1055/2136] train loss: [0.4254] (epoch [2/4])\n",
      "[1056/2136] train loss: [0.2885] (epoch [2/4])\n",
      "[1057/2136] train loss: [0.1871] (epoch [2/4])\n",
      "[1058/2136] train loss: [0.3902] (epoch [2/4])\n",
      "[1059/2136] train loss: [0.2166] (epoch [2/4])\n",
      "[1060/2136] train loss: [0.2479] (epoch [2/4])\n",
      "[1061/2136] train loss: [0.4092] (epoch [2/4])\n",
      "[1062/2136] train loss: [0.4209] (epoch [2/4])\n",
      "[1063/2136] train loss: [0.3828] (epoch [2/4])\n",
      "[1064/2136] train loss: [0.4059] (epoch [2/4])\n",
      "[1065/2136] train loss: [0.3181] (epoch [2/4])\n",
      "[1066/2136] train loss: [0.3588] (epoch [2/4])\n",
      "[1067/2136] train loss: [0.2871] (epoch [2/4])\n",
      "[1068/2136] train loss: [0.0506] (epoch [2/4])\n",
      "epoch [2/4] validation loss: [0.3676] validation accuracy: [0.8339587242026266]\n",
      "[1069/2136] train loss: [0.2868] (epoch [3/4])\n",
      "[1070/2136] train loss: [0.1182] (epoch [3/4])\n",
      "[1071/2136] train loss: [0.8036] (epoch [3/4])\n",
      "[1072/2136] train loss: [0.5055] (epoch [3/4])\n",
      "[1073/2136] train loss: [0.3670] (epoch [3/4])\n",
      "[1074/2136] train loss: [0.2967] (epoch [3/4])\n",
      "[1075/2136] train loss: [0.2987] (epoch [3/4])\n",
      "[1076/2136] train loss: [0.6013] (epoch [3/4])\n",
      "[1077/2136] train loss: [0.4843] (epoch [3/4])\n",
      "[1078/2136] train loss: [0.3771] (epoch [3/4])\n",
      "[1079/2136] train loss: [0.3397] (epoch [3/4])\n",
      "[1080/2136] train loss: [0.6046] (epoch [3/4])\n",
      "[1081/2136] train loss: [0.2601] (epoch [3/4])\n",
      "[1082/2136] train loss: [0.2910] (epoch [3/4])\n",
      "[1083/2136] train loss: [0.3867] (epoch [3/4])\n",
      "[1084/2136] train loss: [0.3753] (epoch [3/4])\n",
      "[1085/2136] train loss: [0.3120] (epoch [3/4])\n",
      "[1086/2136] train loss: [0.2496] (epoch [3/4])\n",
      "[1087/2136] train loss: [0.2444] (epoch [3/4])\n",
      "[1088/2136] train loss: [0.3867] (epoch [3/4])\n",
      "[1089/2136] train loss: [0.2481] (epoch [3/4])\n",
      "[1090/2136] train loss: [0.3701] (epoch [3/4])\n",
      "[1091/2136] train loss: [0.3880] (epoch [3/4])\n",
      "[1092/2136] train loss: [0.3984] (epoch [3/4])\n",
      "[1093/2136] train loss: [0.3512] (epoch [3/4])\n",
      "[1094/2136] train loss: [0.3644] (epoch [3/4])\n",
      "[1095/2136] train loss: [0.1970] (epoch [3/4])\n",
      "[1096/2136] train loss: [0.2842] (epoch [3/4])\n",
      "[1097/2136] train loss: [0.2118] (epoch [3/4])\n",
      "[1098/2136] train loss: [0.5607] (epoch [3/4])\n",
      "[1099/2136] train loss: [0.3179] (epoch [3/4])\n",
      "[1100/2136] train loss: [0.1557] (epoch [3/4])\n",
      "[1101/2136] train loss: [0.3733] (epoch [3/4])\n",
      "[1102/2136] train loss: [0.2138] (epoch [3/4])\n",
      "[1103/2136] train loss: [0.3723] (epoch [3/4])\n",
      "[1104/2136] train loss: [0.6002] (epoch [3/4])\n",
      "[1105/2136] train loss: [0.4251] (epoch [3/4])\n",
      "[1106/2136] train loss: [0.3837] (epoch [3/4])\n",
      "[1107/2136] train loss: [0.2846] (epoch [3/4])\n",
      "[1108/2136] train loss: [0.6843] (epoch [3/4])\n",
      "[1109/2136] train loss: [0.3540] (epoch [3/4])\n",
      "[1110/2136] train loss: [0.3203] (epoch [3/4])\n",
      "[1111/2136] train loss: [0.4984] (epoch [3/4])\n",
      "[1112/2136] train loss: [0.4056] (epoch [3/4])\n",
      "[1113/2136] train loss: [0.3397] (epoch [3/4])\n",
      "[1114/2136] train loss: [0.4653] (epoch [3/4])\n",
      "[1115/2136] train loss: [0.3627] (epoch [3/4])\n",
      "[1116/2136] train loss: [0.1455] (epoch [3/4])\n",
      "[1117/2136] train loss: [0.4818] (epoch [3/4])\n",
      "[1118/2136] train loss: [0.3847] (epoch [3/4])\n",
      "[1119/2136] train loss: [0.2243] (epoch [3/4])\n",
      "[1120/2136] train loss: [0.5444] (epoch [3/4])\n",
      "[1121/2136] train loss: [0.5354] (epoch [3/4])\n",
      "[1122/2136] train loss: [0.5508] (epoch [3/4])\n",
      "[1123/2136] train loss: [0.3988] (epoch [3/4])\n",
      "[1124/2136] train loss: [0.2811] (epoch [3/4])\n",
      "[1125/2136] train loss: [0.4240] (epoch [3/4])\n",
      "[1126/2136] train loss: [0.1748] (epoch [3/4])\n",
      "[1127/2136] train loss: [0.2368] (epoch [3/4])\n",
      "[1128/2136] train loss: [0.3239] (epoch [3/4])\n",
      "[1129/2136] train loss: [0.3357] (epoch [3/4])\n",
      "[1130/2136] train loss: [0.2006] (epoch [3/4])\n",
      "[1131/2136] train loss: [0.3244] (epoch [3/4])\n",
      "[1132/2136] train loss: [0.6291] (epoch [3/4])\n",
      "[1133/2136] train loss: [0.1520] (epoch [3/4])\n",
      "[1134/2136] train loss: [0.2553] (epoch [3/4])\n",
      "[1135/2136] train loss: [0.2444] (epoch [3/4])\n",
      "[1136/2136] train loss: [0.4513] (epoch [3/4])\n",
      "[1137/2136] train loss: [0.3806] (epoch [3/4])\n",
      "[1138/2136] train loss: [0.1291] (epoch [3/4])\n",
      "[1139/2136] train loss: [0.4464] (epoch [3/4])\n",
      "[1140/2136] train loss: [0.2113] (epoch [3/4])\n",
      "[1141/2136] train loss: [0.4938] (epoch [3/4])\n",
      "[1142/2136] train loss: [0.4083] (epoch [3/4])\n",
      "[1143/2136] train loss: [0.3899] (epoch [3/4])\n",
      "[1144/2136] train loss: [0.4997] (epoch [3/4])\n",
      "[1145/2136] train loss: [0.4163] (epoch [3/4])\n",
      "[1146/2136] train loss: [0.2807] (epoch [3/4])\n",
      "[1147/2136] train loss: [0.4966] (epoch [3/4])\n",
      "[1148/2136] train loss: [0.3899] (epoch [3/4])\n",
      "[1149/2136] train loss: [0.3626] (epoch [3/4])\n",
      "[1150/2136] train loss: [0.2311] (epoch [3/4])\n",
      "[1151/2136] train loss: [0.3901] (epoch [3/4])\n",
      "[1152/2136] train loss: [0.5095] (epoch [3/4])\n",
      "[1153/2136] train loss: [0.3858] (epoch [3/4])\n",
      "[1154/2136] train loss: [0.5981] (epoch [3/4])\n",
      "[1155/2136] train loss: [0.2612] (epoch [3/4])\n",
      "[1156/2136] train loss: [0.2099] (epoch [3/4])\n",
      "[1157/2136] train loss: [0.2038] (epoch [3/4])\n",
      "[1158/2136] train loss: [0.4722] (epoch [3/4])\n",
      "[1159/2136] train loss: [0.2199] (epoch [3/4])\n",
      "[1160/2136] train loss: [0.3437] (epoch [3/4])\n",
      "[1161/2136] train loss: [0.3893] (epoch [3/4])\n",
      "[1162/2136] train loss: [0.6726] (epoch [3/4])\n",
      "[1163/2136] train loss: [0.2462] (epoch [3/4])\n",
      "[1164/2136] train loss: [0.2273] (epoch [3/4])\n",
      "[1165/2136] train loss: [0.3591] (epoch [3/4])\n",
      "[1166/2136] train loss: [0.2310] (epoch [3/4])\n",
      "[1167/2136] train loss: [0.3016] (epoch [3/4])\n",
      "[1168/2136] train loss: [0.2575] (epoch [3/4])\n",
      "[1169/2136] train loss: [0.3548] (epoch [3/4])\n",
      "[1170/2136] train loss: [0.1028] (epoch [3/4])\n",
      "[1171/2136] train loss: [0.5802] (epoch [3/4])\n",
      "[1172/2136] train loss: [0.3767] (epoch [3/4])\n",
      "[1173/2136] train loss: [0.4184] (epoch [3/4])\n",
      "[1174/2136] train loss: [0.5055] (epoch [3/4])\n",
      "[1175/2136] train loss: [0.4256] (epoch [3/4])\n",
      "[1176/2136] train loss: [0.3678] (epoch [3/4])\n",
      "[1177/2136] train loss: [0.3999] (epoch [3/4])\n",
      "[1178/2136] train loss: [0.3603] (epoch [3/4])\n",
      "[1179/2136] train loss: [0.2933] (epoch [3/4])\n",
      "[1180/2136] train loss: [0.4451] (epoch [3/4])\n",
      "[1181/2136] train loss: [0.2545] (epoch [3/4])\n",
      "[1182/2136] train loss: [0.4559] (epoch [3/4])\n",
      "[1183/2136] train loss: [0.3815] (epoch [3/4])\n",
      "[1184/2136] train loss: [0.1492] (epoch [3/4])\n",
      "[1185/2136] train loss: [0.2454] (epoch [3/4])\n",
      "[1186/2136] train loss: [0.4423] (epoch [3/4])\n",
      "[1187/2136] train loss: [0.6625] (epoch [3/4])\n",
      "[1188/2136] train loss: [0.3029] (epoch [3/4])\n",
      "[1189/2136] train loss: [0.2489] (epoch [3/4])\n",
      "[1190/2136] train loss: [0.4395] (epoch [3/4])\n",
      "[1191/2136] train loss: [0.3560] (epoch [3/4])\n",
      "[1192/2136] train loss: [0.5431] (epoch [3/4])\n",
      "[1193/2136] train loss: [0.2188] (epoch [3/4])\n",
      "[1194/2136] train loss: [0.5595] (epoch [3/4])\n",
      "[1195/2136] train loss: [0.3107] (epoch [3/4])\n",
      "[1196/2136] train loss: [0.1707] (epoch [3/4])\n",
      "[1197/2136] train loss: [0.1621] (epoch [3/4])\n",
      "[1198/2136] train loss: [0.4030] (epoch [3/4])\n",
      "[1199/2136] train loss: [0.3730] (epoch [3/4])\n",
      "[1200/2136] train loss: [0.4894] (epoch [3/4])\n",
      "[1201/2136] train loss: [0.4189] (epoch [3/4])\n",
      "[1202/2136] train loss: [0.3260] (epoch [3/4])\n",
      "[1203/2136] train loss: [0.1954] (epoch [3/4])\n",
      "[1204/2136] train loss: [0.5097] (epoch [3/4])\n",
      "[1205/2136] train loss: [0.3042] (epoch [3/4])\n",
      "[1206/2136] train loss: [0.1535] (epoch [3/4])\n",
      "[1207/2136] train loss: [0.4676] (epoch [3/4])\n",
      "[1208/2136] train loss: [0.2839] (epoch [3/4])\n",
      "[1209/2136] train loss: [0.3395] (epoch [3/4])\n",
      "[1210/2136] train loss: [0.3336] (epoch [3/4])\n",
      "[1211/2136] train loss: [0.3481] (epoch [3/4])\n",
      "[1212/2136] train loss: [0.2773] (epoch [3/4])\n",
      "[1213/2136] train loss: [0.4538] (epoch [3/4])\n",
      "[1214/2136] train loss: [0.4404] (epoch [3/4])\n",
      "[1215/2136] train loss: [0.3800] (epoch [3/4])\n",
      "[1216/2136] train loss: [0.1443] (epoch [3/4])\n",
      "[1217/2136] train loss: [0.2071] (epoch [3/4])\n",
      "[1218/2136] train loss: [0.4817] (epoch [3/4])\n",
      "[1219/2136] train loss: [0.5084] (epoch [3/4])\n",
      "[1220/2136] train loss: [0.1977] (epoch [3/4])\n",
      "[1221/2136] train loss: [0.2366] (epoch [3/4])\n",
      "[1222/2136] train loss: [0.4333] (epoch [3/4])\n",
      "[1223/2136] train loss: [0.3178] (epoch [3/4])\n",
      "[1224/2136] train loss: [0.4149] (epoch [3/4])\n",
      "[1225/2136] train loss: [0.2090] (epoch [3/4])\n",
      "[1226/2136] train loss: [0.3743] (epoch [3/4])\n",
      "[1227/2136] train loss: [0.4284] (epoch [3/4])\n",
      "[1228/2136] train loss: [0.6368] (epoch [3/4])\n",
      "[1229/2136] train loss: [0.3218] (epoch [3/4])\n",
      "[1230/2136] train loss: [0.5138] (epoch [3/4])\n",
      "[1231/2136] train loss: [0.3980] (epoch [3/4])\n",
      "[1232/2136] train loss: [0.2293] (epoch [3/4])\n",
      "[1233/2136] train loss: [0.4306] (epoch [3/4])\n",
      "[1234/2136] train loss: [0.3192] (epoch [3/4])\n",
      "[1235/2136] train loss: [0.2073] (epoch [3/4])\n",
      "[1236/2136] train loss: [0.3946] (epoch [3/4])\n",
      "[1237/2136] train loss: [0.3838] (epoch [3/4])\n",
      "[1238/2136] train loss: [0.2934] (epoch [3/4])\n",
      "[1239/2136] train loss: [0.3947] (epoch [3/4])\n",
      "[1240/2136] train loss: [0.5864] (epoch [3/4])\n",
      "[1241/2136] train loss: [0.4460] (epoch [3/4])\n",
      "[1242/2136] train loss: [0.5211] (epoch [3/4])\n",
      "[1243/2136] train loss: [0.3994] (epoch [3/4])\n",
      "[1244/2136] train loss: [0.2367] (epoch [3/4])\n",
      "[1245/2136] train loss: [0.1622] (epoch [3/4])\n",
      "[1246/2136] train loss: [0.2250] (epoch [3/4])\n",
      "[1247/2136] train loss: [0.5450] (epoch [3/4])\n",
      "[1248/2136] train loss: [0.1905] (epoch [3/4])\n",
      "[1249/2136] train loss: [0.2178] (epoch [3/4])\n",
      "[1250/2136] train loss: [0.3984] (epoch [3/4])\n",
      "[1251/2136] train loss: [0.2964] (epoch [3/4])\n",
      "[1252/2136] train loss: [0.1675] (epoch [3/4])\n",
      "[1253/2136] train loss: [0.4703] (epoch [3/4])\n",
      "[1254/2136] train loss: [0.2753] (epoch [3/4])\n",
      "[1255/2136] train loss: [0.3674] (epoch [3/4])\n",
      "[1256/2136] train loss: [0.4264] (epoch [3/4])\n",
      "[1257/2136] train loss: [0.4274] (epoch [3/4])\n",
      "[1258/2136] train loss: [0.2052] (epoch [3/4])\n",
      "[1259/2136] train loss: [0.3344] (epoch [3/4])\n",
      "[1260/2136] train loss: [0.4115] (epoch [3/4])\n",
      "[1261/2136] train loss: [0.6002] (epoch [3/4])\n",
      "[1262/2136] train loss: [0.5026] (epoch [3/4])\n",
      "[1263/2136] train loss: [0.3889] (epoch [3/4])\n",
      "[1264/2136] train loss: [0.2949] (epoch [3/4])\n",
      "[1265/2136] train loss: [0.2306] (epoch [3/4])\n",
      "[1266/2136] train loss: [0.5196] (epoch [3/4])\n",
      "[1267/2136] train loss: [0.7462] (epoch [3/4])\n",
      "[1268/2136] train loss: [0.2451] (epoch [3/4])\n",
      "[1269/2136] train loss: [0.2374] (epoch [3/4])\n",
      "[1270/2136] train loss: [0.2395] (epoch [3/4])\n",
      "[1271/2136] train loss: [0.5363] (epoch [3/4])\n",
      "[1272/2136] train loss: [0.6732] (epoch [3/4])\n",
      "[1273/2136] train loss: [0.2398] (epoch [3/4])\n",
      "[1274/2136] train loss: [0.1465] (epoch [3/4])\n",
      "[1275/2136] train loss: [0.4076] (epoch [3/4])\n",
      "[1276/2136] train loss: [0.2432] (epoch [3/4])\n",
      "[1277/2136] train loss: [0.2758] (epoch [3/4])\n",
      "[1278/2136] train loss: [0.3345] (epoch [3/4])\n",
      "[1279/2136] train loss: [0.6038] (epoch [3/4])\n",
      "[1280/2136] train loss: [0.3109] (epoch [3/4])\n",
      "[1281/2136] train loss: [0.3203] (epoch [3/4])\n",
      "[1282/2136] train loss: [0.3853] (epoch [3/4])\n",
      "[1283/2136] train loss: [0.5583] (epoch [3/4])\n",
      "[1284/2136] train loss: [0.4422] (epoch [3/4])\n",
      "[1285/2136] train loss: [0.3761] (epoch [3/4])\n",
      "[1286/2136] train loss: [0.3791] (epoch [3/4])\n",
      "[1287/2136] train loss: [0.4085] (epoch [3/4])\n",
      "[1288/2136] train loss: [0.3104] (epoch [3/4])\n",
      "[1289/2136] train loss: [0.1977] (epoch [3/4])\n",
      "[1290/2136] train loss: [0.4115] (epoch [3/4])\n",
      "[1291/2136] train loss: [0.4702] (epoch [3/4])\n",
      "[1292/2136] train loss: [0.3776] (epoch [3/4])\n",
      "[1293/2136] train loss: [0.1604] (epoch [3/4])\n",
      "[1294/2136] train loss: [0.2995] (epoch [3/4])\n",
      "[1295/2136] train loss: [0.2700] (epoch [3/4])\n",
      "[1296/2136] train loss: [0.1826] (epoch [3/4])\n",
      "[1297/2136] train loss: [0.1294] (epoch [3/4])\n",
      "[1298/2136] train loss: [0.4675] (epoch [3/4])\n",
      "[1299/2136] train loss: [0.5300] (epoch [3/4])\n",
      "[1300/2136] train loss: [0.2278] (epoch [3/4])\n",
      "[1301/2136] train loss: [0.3437] (epoch [3/4])\n",
      "[1302/2136] train loss: [0.4135] (epoch [3/4])\n",
      "[1303/2136] train loss: [0.3405] (epoch [3/4])\n",
      "[1304/2136] train loss: [0.4220] (epoch [3/4])\n",
      "[1305/2136] train loss: [0.1505] (epoch [3/4])\n",
      "[1306/2136] train loss: [0.3580] (epoch [3/4])\n",
      "[1307/2136] train loss: [0.3114] (epoch [3/4])\n",
      "[1308/2136] train loss: [0.3513] (epoch [3/4])\n",
      "[1309/2136] train loss: [0.6035] (epoch [3/4])\n",
      "[1310/2136] train loss: [0.1490] (epoch [3/4])\n",
      "[1311/2136] train loss: [0.4509] (epoch [3/4])\n",
      "[1312/2136] train loss: [0.5200] (epoch [3/4])\n",
      "[1313/2136] train loss: [0.2452] (epoch [3/4])\n",
      "[1314/2136] train loss: [0.4545] (epoch [3/4])\n",
      "[1315/2136] train loss: [0.3818] (epoch [3/4])\n",
      "[1316/2136] train loss: [0.2286] (epoch [3/4])\n",
      "[1317/2136] train loss: [0.2779] (epoch [3/4])\n",
      "[1318/2136] train loss: [0.2132] (epoch [3/4])\n",
      "[1319/2136] train loss: [0.2159] (epoch [3/4])\n",
      "[1320/2136] train loss: [0.3062] (epoch [3/4])\n",
      "[1321/2136] train loss: [0.1713] (epoch [3/4])\n",
      "[1322/2136] train loss: [0.2010] (epoch [3/4])\n",
      "[1323/2136] train loss: [0.3413] (epoch [3/4])\n",
      "[1324/2136] train loss: [0.3169] (epoch [3/4])\n",
      "[1325/2136] train loss: [0.1400] (epoch [3/4])\n",
      "[1326/2136] train loss: [0.1173] (epoch [3/4])\n",
      "[1327/2136] train loss: [0.3082] (epoch [3/4])\n",
      "[1328/2136] train loss: [0.2292] (epoch [3/4])\n",
      "[1329/2136] train loss: [0.1873] (epoch [3/4])\n",
      "[1330/2136] train loss: [0.3373] (epoch [3/4])\n",
      "[1331/2136] train loss: [0.2881] (epoch [3/4])\n",
      "[1332/2136] train loss: [0.2762] (epoch [3/4])\n",
      "[1333/2136] train loss: [0.4708] (epoch [3/4])\n",
      "[1334/2136] train loss: [0.7112] (epoch [3/4])\n",
      "[1335/2136] train loss: [0.1803] (epoch [3/4])\n",
      "[1336/2136] train loss: [0.2347] (epoch [3/4])\n",
      "[1337/2136] train loss: [0.1419] (epoch [3/4])\n",
      "[1338/2136] train loss: [0.4206] (epoch [3/4])\n",
      "[1339/2136] train loss: [0.2726] (epoch [3/4])\n",
      "[1340/2136] train loss: [0.4370] (epoch [3/4])\n",
      "[1341/2136] train loss: [0.3112] (epoch [3/4])\n",
      "[1342/2136] train loss: [0.1680] (epoch [3/4])\n",
      "[1343/2136] train loss: [0.2440] (epoch [3/4])\n",
      "[1344/2136] train loss: [0.4193] (epoch [3/4])\n",
      "[1345/2136] train loss: [0.3618] (epoch [3/4])\n",
      "[1346/2136] train loss: [0.1941] (epoch [3/4])\n",
      "[1347/2136] train loss: [0.3915] (epoch [3/4])\n",
      "[1348/2136] train loss: [0.4826] (epoch [3/4])\n",
      "[1349/2136] train loss: [0.1902] (epoch [3/4])\n",
      "[1350/2136] train loss: [0.1858] (epoch [3/4])\n",
      "[1351/2136] train loss: [0.4912] (epoch [3/4])\n",
      "[1352/2136] train loss: [0.1316] (epoch [3/4])\n",
      "[1353/2136] train loss: [0.3455] (epoch [3/4])\n",
      "[1354/2136] train loss: [0.1998] (epoch [3/4])\n",
      "[1355/2136] train loss: [0.3246] (epoch [3/4])\n",
      "[1356/2136] train loss: [0.1628] (epoch [3/4])\n",
      "[1357/2136] train loss: [0.7252] (epoch [3/4])\n",
      "[1358/2136] train loss: [0.3839] (epoch [3/4])\n",
      "[1359/2136] train loss: [0.5894] (epoch [3/4])\n",
      "[1360/2136] train loss: [0.2649] (epoch [3/4])\n",
      "[1361/2136] train loss: [0.1718] (epoch [3/4])\n",
      "[1362/2136] train loss: [0.2904] (epoch [3/4])\n",
      "[1363/2136] train loss: [0.2970] (epoch [3/4])\n",
      "[1364/2136] train loss: [0.3593] (epoch [3/4])\n",
      "[1365/2136] train loss: [0.3325] (epoch [3/4])\n",
      "[1366/2136] train loss: [0.4053] (epoch [3/4])\n",
      "[1367/2136] train loss: [0.5530] (epoch [3/4])\n",
      "[1368/2136] train loss: [0.1705] (epoch [3/4])\n",
      "[1369/2136] train loss: [0.6442] (epoch [3/4])\n",
      "[1370/2136] train loss: [0.4032] (epoch [3/4])\n",
      "[1371/2136] train loss: [0.2668] (epoch [3/4])\n",
      "[1372/2136] train loss: [0.2832] (epoch [3/4])\n",
      "[1373/2136] train loss: [0.2886] (epoch [3/4])\n",
      "[1374/2136] train loss: [0.5200] (epoch [3/4])\n",
      "[1375/2136] train loss: [0.6857] (epoch [3/4])\n",
      "[1376/2136] train loss: [0.3508] (epoch [3/4])\n",
      "[1377/2136] train loss: [0.3645] (epoch [3/4])\n",
      "[1378/2136] train loss: [0.2841] (epoch [3/4])\n",
      "[1379/2136] train loss: [0.3094] (epoch [3/4])\n",
      "[1380/2136] train loss: [0.3012] (epoch [3/4])\n",
      "[1381/2136] train loss: [0.3194] (epoch [3/4])\n",
      "[1382/2136] train loss: [0.4689] (epoch [3/4])\n",
      "[1383/2136] train loss: [0.3858] (epoch [3/4])\n",
      "[1384/2136] train loss: [0.4671] (epoch [3/4])\n",
      "[1385/2136] train loss: [0.5218] (epoch [3/4])\n",
      "[1386/2136] train loss: [0.2702] (epoch [3/4])\n",
      "[1387/2136] train loss: [0.1765] (epoch [3/4])\n",
      "[1388/2136] train loss: [0.2894] (epoch [3/4])\n",
      "[1389/2136] train loss: [0.5254] (epoch [3/4])\n",
      "[1390/2136] train loss: [0.3873] (epoch [3/4])\n",
      "[1391/2136] train loss: [0.3577] (epoch [3/4])\n",
      "[1392/2136] train loss: [0.4725] (epoch [3/4])\n",
      "[1393/2136] train loss: [0.3934] (epoch [3/4])\n",
      "[1394/2136] train loss: [0.1952] (epoch [3/4])\n",
      "[1395/2136] train loss: [0.4997] (epoch [3/4])\n",
      "[1396/2136] train loss: [0.2100] (epoch [3/4])\n",
      "[1397/2136] train loss: [0.3556] (epoch [3/4])\n",
      "[1398/2136] train loss: [0.1522] (epoch [3/4])\n",
      "[1399/2136] train loss: [0.3471] (epoch [3/4])\n",
      "[1400/2136] train loss: [0.3114] (epoch [3/4])\n",
      "[1401/2136] train loss: [0.2732] (epoch [3/4])\n",
      "[1402/2136] train loss: [0.2097] (epoch [3/4])\n",
      "[1403/2136] train loss: [0.3376] (epoch [3/4])\n",
      "[1404/2136] train loss: [0.2320] (epoch [3/4])\n",
      "[1405/2136] train loss: [0.6833] (epoch [3/4])\n",
      "[1406/2136] train loss: [0.3563] (epoch [3/4])\n",
      "[1407/2136] train loss: [0.3577] (epoch [3/4])\n",
      "[1408/2136] train loss: [0.2642] (epoch [3/4])\n",
      "[1409/2136] train loss: [0.4304] (epoch [3/4])\n",
      "[1410/2136] train loss: [0.1173] (epoch [3/4])\n",
      "[1411/2136] train loss: [0.3637] (epoch [3/4])\n",
      "[1412/2136] train loss: [0.3815] (epoch [3/4])\n",
      "[1413/2136] train loss: [0.5055] (epoch [3/4])\n",
      "[1414/2136] train loss: [0.4166] (epoch [3/4])\n",
      "[1415/2136] train loss: [0.3397] (epoch [3/4])\n",
      "[1416/2136] train loss: [0.5647] (epoch [3/4])\n",
      "[1417/2136] train loss: [0.5167] (epoch [3/4])\n",
      "[1418/2136] train loss: [0.2588] (epoch [3/4])\n",
      "[1419/2136] train loss: [0.2021] (epoch [3/4])\n",
      "[1420/2136] train loss: [0.2773] (epoch [3/4])\n",
      "[1421/2136] train loss: [0.2662] (epoch [3/4])\n",
      "[1422/2136] train loss: [0.4047] (epoch [3/4])\n",
      "[1423/2136] train loss: [0.6179] (epoch [3/4])\n",
      "[1424/2136] train loss: [0.3455] (epoch [3/4])\n",
      "[1425/2136] train loss: [0.3477] (epoch [3/4])\n",
      "[1426/2136] train loss: [0.3357] (epoch [3/4])\n",
      "[1427/2136] train loss: [0.6522] (epoch [3/4])\n",
      "[1428/2136] train loss: [0.3396] (epoch [3/4])\n",
      "[1429/2136] train loss: [0.2146] (epoch [3/4])\n",
      "[1430/2136] train loss: [0.3689] (epoch [3/4])\n",
      "[1431/2136] train loss: [0.4215] (epoch [3/4])\n",
      "[1432/2136] train loss: [0.2492] (epoch [3/4])\n",
      "[1433/2136] train loss: [0.2551] (epoch [3/4])\n",
      "[1434/2136] train loss: [0.2904] (epoch [3/4])\n",
      "[1435/2136] train loss: [0.5659] (epoch [3/4])\n",
      "[1436/2136] train loss: [0.5478] (epoch [3/4])\n",
      "[1437/2136] train loss: [0.4803] (epoch [3/4])\n",
      "[1438/2136] train loss: [0.4552] (epoch [3/4])\n",
      "[1439/2136] train loss: [0.5107] (epoch [3/4])\n",
      "[1440/2136] train loss: [0.3435] (epoch [3/4])\n",
      "[1441/2136] train loss: [0.3733] (epoch [3/4])\n",
      "[1442/2136] train loss: [0.2749] (epoch [3/4])\n",
      "[1443/2136] train loss: [0.5119] (epoch [3/4])\n",
      "[1444/2136] train loss: [0.3322] (epoch [3/4])\n",
      "[1445/2136] train loss: [0.5124] (epoch [3/4])\n",
      "[1446/2136] train loss: [0.2519] (epoch [3/4])\n",
      "[1447/2136] train loss: [0.4211] (epoch [3/4])\n",
      "[1448/2136] train loss: [0.3203] (epoch [3/4])\n",
      "[1449/2136] train loss: [0.3766] (epoch [3/4])\n",
      "[1450/2136] train loss: [0.3502] (epoch [3/4])\n",
      "[1451/2136] train loss: [0.4506] (epoch [3/4])\n",
      "[1452/2136] train loss: [0.1413] (epoch [3/4])\n",
      "[1453/2136] train loss: [0.1743] (epoch [3/4])\n",
      "[1454/2136] train loss: [0.2525] (epoch [3/4])\n",
      "[1455/2136] train loss: [0.2932] (epoch [3/4])\n",
      "[1456/2136] train loss: [0.4847] (epoch [3/4])\n",
      "[1457/2136] train loss: [0.4000] (epoch [3/4])\n",
      "[1458/2136] train loss: [0.2424] (epoch [3/4])\n",
      "[1459/2136] train loss: [0.1261] (epoch [3/4])\n",
      "[1460/2136] train loss: [0.2665] (epoch [3/4])\n",
      "[1461/2136] train loss: [0.2425] (epoch [3/4])\n",
      "[1462/2136] train loss: [0.4314] (epoch [3/4])\n",
      "[1463/2136] train loss: [0.2730] (epoch [3/4])\n",
      "[1464/2136] train loss: [0.4774] (epoch [3/4])\n",
      "[1465/2136] train loss: [0.2964] (epoch [3/4])\n",
      "[1466/2136] train loss: [0.3434] (epoch [3/4])\n",
      "[1467/2136] train loss: [0.2606] (epoch [3/4])\n",
      "[1468/2136] train loss: [0.2752] (epoch [3/4])\n",
      "[1469/2136] train loss: [0.4205] (epoch [3/4])\n",
      "[1470/2136] train loss: [0.3822] (epoch [3/4])\n",
      "[1471/2136] train loss: [0.2341] (epoch [3/4])\n",
      "[1472/2136] train loss: [0.7391] (epoch [3/4])\n",
      "[1473/2136] train loss: [0.1972] (epoch [3/4])\n",
      "[1474/2136] train loss: [0.1893] (epoch [3/4])\n",
      "[1475/2136] train loss: [0.7570] (epoch [3/4])\n",
      "[1476/2136] train loss: [0.2214] (epoch [3/4])\n",
      "[1477/2136] train loss: [0.3573] (epoch [3/4])\n",
      "[1478/2136] train loss: [0.2597] (epoch [3/4])\n",
      "[1479/2136] train loss: [0.5442] (epoch [3/4])\n",
      "[1480/2136] train loss: [0.4470] (epoch [3/4])\n",
      "[1481/2136] train loss: [0.4833] (epoch [3/4])\n",
      "[1482/2136] train loss: [0.3653] (epoch [3/4])\n",
      "[1483/2136] train loss: [0.6010] (epoch [3/4])\n",
      "[1484/2136] train loss: [0.1898] (epoch [3/4])\n",
      "[1485/2136] train loss: [0.3239] (epoch [3/4])\n",
      "[1486/2136] train loss: [0.4287] (epoch [3/4])\n",
      "[1487/2136] train loss: [0.4175] (epoch [3/4])\n",
      "[1488/2136] train loss: [0.1554] (epoch [3/4])\n",
      "[1489/2136] train loss: [0.3096] (epoch [3/4])\n",
      "[1490/2136] train loss: [0.5716] (epoch [3/4])\n",
      "[1491/2136] train loss: [0.4251] (epoch [3/4])\n",
      "[1492/2136] train loss: [0.2195] (epoch [3/4])\n",
      "[1493/2136] train loss: [0.2885] (epoch [3/4])\n",
      "[1494/2136] train loss: [0.3039] (epoch [3/4])\n",
      "[1495/2136] train loss: [0.2596] (epoch [3/4])\n",
      "[1496/2136] train loss: [0.2080] (epoch [3/4])\n",
      "[1497/2136] train loss: [0.3062] (epoch [3/4])\n",
      "[1498/2136] train loss: [0.3507] (epoch [3/4])\n",
      "[1499/2136] train loss: [0.4913] (epoch [3/4])\n",
      "[1500/2136] train loss: [0.4444] (epoch [3/4])\n",
      "[1501/2136] train loss: [0.1855] (epoch [3/4])\n",
      "[1502/2136] train loss: [0.2170] (epoch [3/4])\n",
      "[1503/2136] train loss: [0.2292] (epoch [3/4])\n",
      "[1504/2136] train loss: [0.2355] (epoch [3/4])\n",
      "[1505/2136] train loss: [0.1602] (epoch [3/4])\n",
      "[1506/2136] train loss: [0.2204] (epoch [3/4])\n",
      "[1507/2136] train loss: [0.2091] (epoch [3/4])\n",
      "[1508/2136] train loss: [0.2801] (epoch [3/4])\n",
      "[1509/2136] train loss: [0.2151] (epoch [3/4])\n",
      "[1510/2136] train loss: [0.2878] (epoch [3/4])\n",
      "[1511/2136] train loss: [0.2501] (epoch [3/4])\n",
      "[1512/2136] train loss: [0.1477] (epoch [3/4])\n",
      "[1513/2136] train loss: [0.5463] (epoch [3/4])\n",
      "[1514/2136] train loss: [0.6400] (epoch [3/4])\n",
      "[1515/2136] train loss: [0.3834] (epoch [3/4])\n",
      "[1516/2136] train loss: [0.2806] (epoch [3/4])\n",
      "[1517/2136] train loss: [0.3178] (epoch [3/4])\n",
      "[1518/2136] train loss: [0.2251] (epoch [3/4])\n",
      "[1519/2136] train loss: [0.4166] (epoch [3/4])\n",
      "[1520/2136] train loss: [0.3571] (epoch [3/4])\n",
      "[1521/2136] train loss: [0.2131] (epoch [3/4])\n",
      "[1522/2136] train loss: [0.4987] (epoch [3/4])\n",
      "[1523/2136] train loss: [0.5320] (epoch [3/4])\n",
      "[1524/2136] train loss: [0.2844] (epoch [3/4])\n",
      "[1525/2136] train loss: [0.1866] (epoch [3/4])\n",
      "[1526/2136] train loss: [0.2159] (epoch [3/4])\n",
      "[1527/2136] train loss: [0.4023] (epoch [3/4])\n",
      "[1528/2136] train loss: [0.5334] (epoch [3/4])\n",
      "[1529/2136] train loss: [0.1649] (epoch [3/4])\n",
      "[1530/2136] train loss: [0.7359] (epoch [3/4])\n",
      "[1531/2136] train loss: [0.3015] (epoch [3/4])\n",
      "[1532/2136] train loss: [0.3831] (epoch [3/4])\n",
      "[1533/2136] train loss: [0.3333] (epoch [3/4])\n",
      "[1534/2136] train loss: [0.2834] (epoch [3/4])\n",
      "[1535/2136] train loss: [0.1948] (epoch [3/4])\n",
      "[1536/2136] train loss: [0.2073] (epoch [3/4])\n",
      "[1537/2136] train loss: [0.1478] (epoch [3/4])\n",
      "[1538/2136] train loss: [0.3047] (epoch [3/4])\n",
      "[1539/2136] train loss: [0.1923] (epoch [3/4])\n",
      "[1540/2136] train loss: [0.5427] (epoch [3/4])\n",
      "[1541/2136] train loss: [0.2217] (epoch [3/4])\n",
      "[1542/2136] train loss: [0.4188] (epoch [3/4])\n",
      "[1543/2136] train loss: [0.4787] (epoch [3/4])\n",
      "[1544/2136] train loss: [0.3437] (epoch [3/4])\n",
      "[1545/2136] train loss: [0.3484] (epoch [3/4])\n",
      "[1546/2136] train loss: [0.5134] (epoch [3/4])\n",
      "[1547/2136] train loss: [0.3066] (epoch [3/4])\n",
      "[1548/2136] train loss: [0.4865] (epoch [3/4])\n",
      "[1549/2136] train loss: [0.5131] (epoch [3/4])\n",
      "[1550/2136] train loss: [0.8010] (epoch [3/4])\n",
      "[1551/2136] train loss: [0.2586] (epoch [3/4])\n",
      "[1552/2136] train loss: [0.4983] (epoch [3/4])\n",
      "[1553/2136] train loss: [0.7893] (epoch [3/4])\n",
      "[1554/2136] train loss: [0.1960] (epoch [3/4])\n",
      "[1555/2136] train loss: [0.4340] (epoch [3/4])\n",
      "[1556/2136] train loss: [0.2860] (epoch [3/4])\n",
      "[1557/2136] train loss: [0.2755] (epoch [3/4])\n",
      "[1558/2136] train loss: [0.3384] (epoch [3/4])\n",
      "[1559/2136] train loss: [0.5246] (epoch [3/4])\n",
      "[1560/2136] train loss: [0.4318] (epoch [3/4])\n",
      "[1561/2136] train loss: [0.3659] (epoch [3/4])\n",
      "[1562/2136] train loss: [0.2296] (epoch [3/4])\n",
      "[1563/2136] train loss: [0.5797] (epoch [3/4])\n",
      "[1564/2136] train loss: [0.4380] (epoch [3/4])\n",
      "[1565/2136] train loss: [0.4335] (epoch [3/4])\n",
      "[1566/2136] train loss: [0.3517] (epoch [3/4])\n",
      "[1567/2136] train loss: [0.4672] (epoch [3/4])\n",
      "[1568/2136] train loss: [0.5277] (epoch [3/4])\n",
      "[1569/2136] train loss: [0.4650] (epoch [3/4])\n",
      "[1570/2136] train loss: [0.2323] (epoch [3/4])\n",
      "[1571/2136] train loss: [0.2681] (epoch [3/4])\n",
      "[1572/2136] train loss: [0.3179] (epoch [3/4])\n",
      "[1573/2136] train loss: [0.5130] (epoch [3/4])\n",
      "[1574/2136] train loss: [0.3327] (epoch [3/4])\n",
      "[1575/2136] train loss: [0.4128] (epoch [3/4])\n",
      "[1576/2136] train loss: [0.5122] (epoch [3/4])\n",
      "[1577/2136] train loss: [0.3452] (epoch [3/4])\n",
      "[1578/2136] train loss: [0.5737] (epoch [3/4])\n",
      "[1579/2136] train loss: [0.5391] (epoch [3/4])\n",
      "[1580/2136] train loss: [0.3039] (epoch [3/4])\n",
      "[1581/2136] train loss: [0.1647] (epoch [3/4])\n",
      "[1582/2136] train loss: [0.1538] (epoch [3/4])\n",
      "[1583/2136] train loss: [0.2570] (epoch [3/4])\n",
      "[1584/2136] train loss: [0.2712] (epoch [3/4])\n",
      "[1585/2136] train loss: [0.2868] (epoch [3/4])\n",
      "[1586/2136] train loss: [0.4637] (epoch [3/4])\n",
      "[1587/2136] train loss: [0.2684] (epoch [3/4])\n",
      "[1588/2136] train loss: [0.4379] (epoch [3/4])\n",
      "[1589/2136] train loss: [0.2069] (epoch [3/4])\n",
      "[1590/2136] train loss: [0.4370] (epoch [3/4])\n",
      "[1591/2136] train loss: [0.2460] (epoch [3/4])\n",
      "[1592/2136] train loss: [0.2171] (epoch [3/4])\n",
      "[1593/2136] train loss: [0.2500] (epoch [3/4])\n",
      "[1594/2136] train loss: [0.3344] (epoch [3/4])\n",
      "[1595/2136] train loss: [0.6790] (epoch [3/4])\n",
      "[1596/2136] train loss: [0.2426] (epoch [3/4])\n",
      "[1597/2136] train loss: [0.1000] (epoch [3/4])\n",
      "[1598/2136] train loss: [0.4502] (epoch [3/4])\n",
      "[1599/2136] train loss: [0.5062] (epoch [3/4])\n",
      "[1600/2136] train loss: [0.4381] (epoch [3/4])\n",
      "[1601/2136] train loss: [0.5717] (epoch [3/4])\n",
      "[1602/2136] train loss: [0.6324] (epoch [3/4])\n",
      "epoch [3/4] validation loss: [0.3621] validation accuracy: [0.8320825515947468]\n",
      "[1603/2136] train loss: [0.4229] (epoch [4/4])\n",
      "[1604/2136] train loss: [0.2576] (epoch [4/4])\n",
      "[1605/2136] train loss: [0.3292] (epoch [4/4])\n",
      "[1606/2136] train loss: [0.7086] (epoch [4/4])\n",
      "[1607/2136] train loss: [0.2694] (epoch [4/4])\n",
      "[1608/2136] train loss: [0.4705] (epoch [4/4])\n",
      "[1609/2136] train loss: [0.3888] (epoch [4/4])\n",
      "[1610/2136] train loss: [0.3088] (epoch [4/4])\n",
      "[1611/2136] train loss: [0.3689] (epoch [4/4])\n",
      "[1612/2136] train loss: [0.4432] (epoch [4/4])\n",
      "[1613/2136] train loss: [0.2699] (epoch [4/4])\n",
      "[1614/2136] train loss: [0.4524] (epoch [4/4])\n",
      "[1615/2136] train loss: [0.2340] (epoch [4/4])\n",
      "[1616/2136] train loss: [0.3621] (epoch [4/4])\n",
      "[1617/2136] train loss: [0.6573] (epoch [4/4])\n",
      "[1618/2136] train loss: [0.1879] (epoch [4/4])\n",
      "[1619/2136] train loss: [0.3499] (epoch [4/4])\n",
      "[1620/2136] train loss: [0.3880] (epoch [4/4])\n",
      "[1621/2136] train loss: [0.4593] (epoch [4/4])\n",
      "[1622/2136] train loss: [0.2404] (epoch [4/4])\n",
      "[1623/2136] train loss: [0.1013] (epoch [4/4])\n",
      "[1624/2136] train loss: [0.2054] (epoch [4/4])\n",
      "[1625/2136] train loss: [0.3370] (epoch [4/4])\n",
      "[1626/2136] train loss: [0.5795] (epoch [4/4])\n",
      "[1627/2136] train loss: [0.1920] (epoch [4/4])\n",
      "[1628/2136] train loss: [0.3185] (epoch [4/4])\n",
      "[1629/2136] train loss: [0.2478] (epoch [4/4])\n",
      "[1630/2136] train loss: [0.3625] (epoch [4/4])\n",
      "[1631/2136] train loss: [0.1832] (epoch [4/4])\n",
      "[1632/2136] train loss: [0.2523] (epoch [4/4])\n",
      "[1633/2136] train loss: [0.2064] (epoch [4/4])\n",
      "[1634/2136] train loss: [0.4742] (epoch [4/4])\n",
      "[1635/2136] train loss: [0.4205] (epoch [4/4])\n",
      "[1636/2136] train loss: [0.3396] (epoch [4/4])\n",
      "[1637/2136] train loss: [0.1899] (epoch [4/4])\n",
      "[1638/2136] train loss: [0.2449] (epoch [4/4])\n",
      "[1639/2136] train loss: [0.1969] (epoch [4/4])\n",
      "[1640/2136] train loss: [0.2449] (epoch [4/4])\n",
      "[1641/2136] train loss: [0.2997] (epoch [4/4])\n",
      "[1642/2136] train loss: [0.3479] (epoch [4/4])\n",
      "[1643/2136] train loss: [0.4486] (epoch [4/4])\n",
      "[1644/2136] train loss: [0.3872] (epoch [4/4])\n",
      "[1645/2136] train loss: [0.4279] (epoch [4/4])\n",
      "[1646/2136] train loss: [0.5174] (epoch [4/4])\n",
      "[1647/2136] train loss: [0.3286] (epoch [4/4])\n",
      "[1648/2136] train loss: [0.1724] (epoch [4/4])\n",
      "[1649/2136] train loss: [0.5708] (epoch [4/4])\n",
      "[1650/2136] train loss: [0.3958] (epoch [4/4])\n",
      "[1651/2136] train loss: [0.1561] (epoch [4/4])\n",
      "[1652/2136] train loss: [0.3054] (epoch [4/4])\n",
      "[1653/2136] train loss: [0.3362] (epoch [4/4])\n",
      "[1654/2136] train loss: [0.2633] (epoch [4/4])\n",
      "[1655/2136] train loss: [0.4731] (epoch [4/4])\n",
      "[1656/2136] train loss: [0.3384] (epoch [4/4])\n",
      "[1657/2136] train loss: [0.1626] (epoch [4/4])\n",
      "[1658/2136] train loss: [0.2828] (epoch [4/4])\n",
      "[1659/2136] train loss: [0.3338] (epoch [4/4])\n",
      "[1660/2136] train loss: [0.5163] (epoch [4/4])\n",
      "[1661/2136] train loss: [0.3274] (epoch [4/4])\n",
      "[1662/2136] train loss: [0.2174] (epoch [4/4])\n",
      "[1663/2136] train loss: [0.2534] (epoch [4/4])\n",
      "[1664/2136] train loss: [0.1459] (epoch [4/4])\n",
      "[1665/2136] train loss: [0.4190] (epoch [4/4])\n",
      "[1666/2136] train loss: [0.1969] (epoch [4/4])\n",
      "[1667/2136] train loss: [0.4479] (epoch [4/4])\n",
      "[1668/2136] train loss: [0.4506] (epoch [4/4])\n",
      "[1669/2136] train loss: [0.2434] (epoch [4/4])\n",
      "[1670/2136] train loss: [0.2510] (epoch [4/4])\n",
      "[1671/2136] train loss: [0.1721] (epoch [4/4])\n",
      "[1672/2136] train loss: [0.4137] (epoch [4/4])\n",
      "[1673/2136] train loss: [0.2274] (epoch [4/4])\n",
      "[1674/2136] train loss: [0.2683] (epoch [4/4])\n",
      "[1675/2136] train loss: [0.5010] (epoch [4/4])\n",
      "[1676/2136] train loss: [0.2232] (epoch [4/4])\n",
      "[1677/2136] train loss: [0.3452] (epoch [4/4])\n",
      "[1678/2136] train loss: [0.1477] (epoch [4/4])\n",
      "[1679/2136] train loss: [0.3283] (epoch [4/4])\n",
      "[1680/2136] train loss: [0.4374] (epoch [4/4])\n",
      "[1681/2136] train loss: [0.5461] (epoch [4/4])\n",
      "[1682/2136] train loss: [0.1942] (epoch [4/4])\n",
      "[1683/2136] train loss: [0.3293] (epoch [4/4])\n",
      "[1684/2136] train loss: [0.2667] (epoch [4/4])\n",
      "[1685/2136] train loss: [0.4796] (epoch [4/4])\n",
      "[1686/2136] train loss: [0.1753] (epoch [4/4])\n",
      "[1687/2136] train loss: [0.1530] (epoch [4/4])\n",
      "[1688/2136] train loss: [0.2046] (epoch [4/4])\n",
      "[1689/2136] train loss: [0.2853] (epoch [4/4])\n",
      "[1690/2136] train loss: [0.2428] (epoch [4/4])\n",
      "[1691/2136] train loss: [0.4948] (epoch [4/4])\n",
      "[1692/2136] train loss: [0.3757] (epoch [4/4])\n",
      "[1693/2136] train loss: [0.4241] (epoch [4/4])\n",
      "[1694/2136] train loss: [0.4139] (epoch [4/4])\n",
      "[1695/2136] train loss: [0.2064] (epoch [4/4])\n",
      "[1696/2136] train loss: [0.4390] (epoch [4/4])\n",
      "[1697/2136] train loss: [0.2233] (epoch [4/4])\n",
      "[1698/2136] train loss: [0.4067] (epoch [4/4])\n",
      "[1699/2136] train loss: [0.2446] (epoch [4/4])\n",
      "[1700/2136] train loss: [0.3766] (epoch [4/4])\n",
      "[1701/2136] train loss: [0.1429] (epoch [4/4])\n",
      "[1702/2136] train loss: [0.3983] (epoch [4/4])\n",
      "[1703/2136] train loss: [0.5236] (epoch [4/4])\n",
      "[1704/2136] train loss: [0.2419] (epoch [4/4])\n",
      "[1705/2136] train loss: [0.1235] (epoch [4/4])\n",
      "[1706/2136] train loss: [0.4247] (epoch [4/4])\n",
      "[1707/2136] train loss: [0.5428] (epoch [4/4])\n",
      "[1708/2136] train loss: [0.5810] (epoch [4/4])\n",
      "[1709/2136] train loss: [0.1578] (epoch [4/4])\n",
      "[1710/2136] train loss: [0.2306] (epoch [4/4])\n",
      "[1711/2136] train loss: [0.3267] (epoch [4/4])\n",
      "[1712/2136] train loss: [0.1998] (epoch [4/4])\n",
      "[1713/2136] train loss: [0.2197] (epoch [4/4])\n",
      "[1714/2136] train loss: [0.3052] (epoch [4/4])\n",
      "[1715/2136] train loss: [0.2957] (epoch [4/4])\n",
      "[1716/2136] train loss: [0.5764] (epoch [4/4])\n",
      "[1717/2136] train loss: [0.3150] (epoch [4/4])\n",
      "[1718/2136] train loss: [0.6144] (epoch [4/4])\n",
      "[1719/2136] train loss: [0.3034] (epoch [4/4])\n",
      "[1720/2136] train loss: [0.2855] (epoch [4/4])\n",
      "[1721/2136] train loss: [0.1600] (epoch [4/4])\n",
      "[1722/2136] train loss: [0.2471] (epoch [4/4])\n",
      "[1723/2136] train loss: [0.1366] (epoch [4/4])\n",
      "[1724/2136] train loss: [0.3446] (epoch [4/4])\n",
      "[1725/2136] train loss: [0.5598] (epoch [4/4])\n",
      "[1726/2136] train loss: [0.2216] (epoch [4/4])\n",
      "[1727/2136] train loss: [0.4642] (epoch [4/4])\n",
      "[1728/2136] train loss: [0.2596] (epoch [4/4])\n",
      "[1729/2136] train loss: [0.3620] (epoch [4/4])\n",
      "[1730/2136] train loss: [0.1968] (epoch [4/4])\n",
      "[1731/2136] train loss: [0.3283] (epoch [4/4])\n",
      "[1732/2136] train loss: [0.3545] (epoch [4/4])\n",
      "[1733/2136] train loss: [0.2100] (epoch [4/4])\n",
      "[1734/2136] train loss: [0.5040] (epoch [4/4])\n",
      "[1735/2136] train loss: [0.4613] (epoch [4/4])\n",
      "[1736/2136] train loss: [0.4054] (epoch [4/4])\n",
      "[1737/2136] train loss: [0.3830] (epoch [4/4])\n",
      "[1738/2136] train loss: [0.3155] (epoch [4/4])\n",
      "[1739/2136] train loss: [0.4981] (epoch [4/4])\n",
      "[1740/2136] train loss: [0.4491] (epoch [4/4])\n",
      "[1741/2136] train loss: [0.4113] (epoch [4/4])\n",
      "[1742/2136] train loss: [0.2502] (epoch [4/4])\n",
      "[1743/2136] train loss: [0.2970] (epoch [4/4])\n",
      "[1744/2136] train loss: [0.5664] (epoch [4/4])\n",
      "[1745/2136] train loss: [0.2982] (epoch [4/4])\n",
      "[1746/2136] train loss: [0.2061] (epoch [4/4])\n",
      "[1747/2136] train loss: [0.2380] (epoch [4/4])\n",
      "[1748/2136] train loss: [0.2689] (epoch [4/4])\n",
      "[1749/2136] train loss: [0.2191] (epoch [4/4])\n",
      "[1750/2136] train loss: [0.2995] (epoch [4/4])\n",
      "[1751/2136] train loss: [0.6665] (epoch [4/4])\n",
      "[1752/2136] train loss: [0.2889] (epoch [4/4])\n",
      "[1753/2136] train loss: [0.5116] (epoch [4/4])\n",
      "[1754/2136] train loss: [0.2930] (epoch [4/4])\n",
      "[1755/2136] train loss: [0.4177] (epoch [4/4])\n",
      "[1756/2136] train loss: [0.2345] (epoch [4/4])\n",
      "[1757/2136] train loss: [0.2049] (epoch [4/4])\n",
      "[1758/2136] train loss: [0.3081] (epoch [4/4])\n",
      "[1759/2136] train loss: [0.3509] (epoch [4/4])\n",
      "[1760/2136] train loss: [0.1792] (epoch [4/4])\n",
      "[1761/2136] train loss: [0.4355] (epoch [4/4])\n",
      "[1762/2136] train loss: [0.1949] (epoch [4/4])\n",
      "[1763/2136] train loss: [0.4216] (epoch [4/4])\n",
      "[1764/2136] train loss: [0.3397] (epoch [4/4])\n",
      "[1765/2136] train loss: [0.1480] (epoch [4/4])\n",
      "[1766/2136] train loss: [0.4241] (epoch [4/4])\n",
      "[1767/2136] train loss: [0.4496] (epoch [4/4])\n",
      "[1768/2136] train loss: [0.3982] (epoch [4/4])\n",
      "[1769/2136] train loss: [0.5457] (epoch [4/4])\n",
      "[1770/2136] train loss: [0.3124] (epoch [4/4])\n",
      "[1771/2136] train loss: [0.1304] (epoch [4/4])\n",
      "[1772/2136] train loss: [0.1215] (epoch [4/4])\n",
      "[1773/2136] train loss: [0.3698] (epoch [4/4])\n",
      "[1774/2136] train loss: [0.3589] (epoch [4/4])\n",
      "[1775/2136] train loss: [0.4457] (epoch [4/4])\n",
      "[1776/2136] train loss: [0.3524] (epoch [4/4])\n",
      "[1777/2136] train loss: [0.2887] (epoch [4/4])\n",
      "[1778/2136] train loss: [0.1550] (epoch [4/4])\n",
      "[1779/2136] train loss: [0.1340] (epoch [4/4])\n",
      "[1780/2136] train loss: [0.4988] (epoch [4/4])\n",
      "[1781/2136] train loss: [0.2558] (epoch [4/4])\n",
      "[1782/2136] train loss: [0.3736] (epoch [4/4])\n",
      "[1783/2136] train loss: [0.6388] (epoch [4/4])\n",
      "[1784/2136] train loss: [0.1532] (epoch [4/4])\n",
      "[1785/2136] train loss: [0.5104] (epoch [4/4])\n",
      "[1786/2136] train loss: [0.2825] (epoch [4/4])\n",
      "[1787/2136] train loss: [0.2105] (epoch [4/4])\n",
      "[1788/2136] train loss: [0.3423] (epoch [4/4])\n",
      "[1789/2136] train loss: [0.4536] (epoch [4/4])\n",
      "[1790/2136] train loss: [0.2245] (epoch [4/4])\n",
      "[1791/2136] train loss: [0.5124] (epoch [4/4])\n",
      "[1792/2136] train loss: [0.3007] (epoch [4/4])\n",
      "[1793/2136] train loss: [0.3119] (epoch [4/4])\n",
      "[1794/2136] train loss: [0.3285] (epoch [4/4])\n",
      "[1795/2136] train loss: [0.5150] (epoch [4/4])\n",
      "[1796/2136] train loss: [0.2599] (epoch [4/4])\n",
      "[1797/2136] train loss: [0.2448] (epoch [4/4])\n",
      "[1798/2136] train loss: [0.1795] (epoch [4/4])\n",
      "[1799/2136] train loss: [0.3424] (epoch [4/4])\n",
      "[1800/2136] train loss: [0.6615] (epoch [4/4])\n",
      "[1801/2136] train loss: [0.1490] (epoch [4/4])\n",
      "[1802/2136] train loss: [0.1421] (epoch [4/4])\n",
      "[1803/2136] train loss: [0.4931] (epoch [4/4])\n",
      "[1804/2136] train loss: [0.0997] (epoch [4/4])\n",
      "[1805/2136] train loss: [0.3266] (epoch [4/4])\n",
      "[1806/2136] train loss: [0.2245] (epoch [4/4])\n",
      "[1807/2136] train loss: [0.3875] (epoch [4/4])\n",
      "[1808/2136] train loss: [0.3792] (epoch [4/4])\n",
      "[1809/2136] train loss: [0.2892] (epoch [4/4])\n",
      "[1810/2136] train loss: [0.1995] (epoch [4/4])\n",
      "[1811/2136] train loss: [0.5194] (epoch [4/4])\n",
      "[1812/2136] train loss: [0.1380] (epoch [4/4])\n",
      "[1813/2136] train loss: [0.1788] (epoch [4/4])\n",
      "[1814/2136] train loss: [0.1993] (epoch [4/4])\n",
      "[1815/2136] train loss: [0.2000] (epoch [4/4])\n",
      "[1816/2136] train loss: [0.3509] (epoch [4/4])\n",
      "[1817/2136] train loss: [0.5347] (epoch [4/4])\n",
      "[1818/2136] train loss: [0.3472] (epoch [4/4])\n",
      "[1819/2136] train loss: [0.1682] (epoch [4/4])\n",
      "[1820/2136] train loss: [0.2049] (epoch [4/4])\n",
      "[1821/2136] train loss: [0.3754] (epoch [4/4])\n",
      "[1822/2136] train loss: [0.1722] (epoch [4/4])\n",
      "[1823/2136] train loss: [0.4375] (epoch [4/4])\n",
      "[1824/2136] train loss: [0.1967] (epoch [4/4])\n",
      "[1825/2136] train loss: [0.1782] (epoch [4/4])\n",
      "[1826/2136] train loss: [0.3347] (epoch [4/4])\n",
      "[1827/2136] train loss: [0.3986] (epoch [4/4])\n",
      "[1828/2136] train loss: [0.3458] (epoch [4/4])\n",
      "[1829/2136] train loss: [0.7115] (epoch [4/4])\n",
      "[1830/2136] train loss: [0.2778] (epoch [4/4])\n",
      "[1831/2136] train loss: [0.2793] (epoch [4/4])\n",
      "[1832/2136] train loss: [0.3272] (epoch [4/4])\n",
      "[1833/2136] train loss: [0.5634] (epoch [4/4])\n",
      "[1834/2136] train loss: [0.4156] (epoch [4/4])\n",
      "[1835/2136] train loss: [0.3322] (epoch [4/4])\n",
      "[1836/2136] train loss: [0.4329] (epoch [4/4])\n",
      "[1837/2136] train loss: [0.3872] (epoch [4/4])\n",
      "[1838/2136] train loss: [0.1341] (epoch [4/4])\n",
      "[1839/2136] train loss: [0.4933] (epoch [4/4])\n",
      "[1840/2136] train loss: [0.2693] (epoch [4/4])\n",
      "[1841/2136] train loss: [0.4130] (epoch [4/4])\n",
      "[1842/2136] train loss: [0.5264] (epoch [4/4])\n",
      "[1843/2136] train loss: [0.2422] (epoch [4/4])\n",
      "[1844/2136] train loss: [0.3195] (epoch [4/4])\n",
      "[1845/2136] train loss: [0.5476] (epoch [4/4])\n",
      "[1846/2136] train loss: [0.3288] (epoch [4/4])\n",
      "[1847/2136] train loss: [0.3172] (epoch [4/4])\n",
      "[1848/2136] train loss: [0.2147] (epoch [4/4])\n",
      "[1849/2136] train loss: [0.6419] (epoch [4/4])\n",
      "[1850/2136] train loss: [0.1066] (epoch [4/4])\n",
      "[1851/2136] train loss: [0.3017] (epoch [4/4])\n",
      "[1852/2136] train loss: [0.3484] (epoch [4/4])\n",
      "[1853/2136] train loss: [0.3576] (epoch [4/4])\n",
      "[1854/2136] train loss: [0.1142] (epoch [4/4])\n",
      "[1855/2136] train loss: [0.5896] (epoch [4/4])\n",
      "[1856/2136] train loss: [0.3112] (epoch [4/4])\n",
      "[1857/2136] train loss: [0.1984] (epoch [4/4])\n",
      "[1858/2136] train loss: [0.2968] (epoch [4/4])\n",
      "[1859/2136] train loss: [0.4311] (epoch [4/4])\n",
      "[1860/2136] train loss: [0.3193] (epoch [4/4])\n",
      "[1861/2136] train loss: [0.2628] (epoch [4/4])\n",
      "[1862/2136] train loss: [0.3383] (epoch [4/4])\n",
      "[1863/2136] train loss: [0.2007] (epoch [4/4])\n",
      "[1864/2136] train loss: [0.1948] (epoch [4/4])\n",
      "[1865/2136] train loss: [0.4891] (epoch [4/4])\n",
      "[1866/2136] train loss: [0.3493] (epoch [4/4])\n",
      "[1867/2136] train loss: [0.3283] (epoch [4/4])\n",
      "[1868/2136] train loss: [0.5689] (epoch [4/4])\n",
      "[1869/2136] train loss: [0.4150] (epoch [4/4])\n",
      "[1870/2136] train loss: [0.3232] (epoch [4/4])\n",
      "[1871/2136] train loss: [0.4395] (epoch [4/4])\n",
      "[1872/2136] train loss: [0.2373] (epoch [4/4])\n",
      "[1873/2136] train loss: [0.5149] (epoch [4/4])\n",
      "[1874/2136] train loss: [0.1916] (epoch [4/4])\n",
      "[1875/2136] train loss: [0.1494] (epoch [4/4])\n",
      "[1876/2136] train loss: [0.5616] (epoch [4/4])\n",
      "[1877/2136] train loss: [0.2735] (epoch [4/4])\n",
      "[1878/2136] train loss: [0.3395] (epoch [4/4])\n",
      "[1879/2136] train loss: [0.2602] (epoch [4/4])\n",
      "[1880/2136] train loss: [0.1587] (epoch [4/4])\n",
      "[1881/2136] train loss: [0.1923] (epoch [4/4])\n",
      "[1882/2136] train loss: [0.3984] (epoch [4/4])\n",
      "[1883/2136] train loss: [0.1116] (epoch [4/4])\n",
      "[1884/2136] train loss: [0.2783] (epoch [4/4])\n",
      "[1885/2136] train loss: [0.3524] (epoch [4/4])\n",
      "[1886/2136] train loss: [0.4077] (epoch [4/4])\n",
      "[1887/2136] train loss: [0.3306] (epoch [4/4])\n",
      "[1888/2136] train loss: [0.2843] (epoch [4/4])\n",
      "[1889/2136] train loss: [0.2848] (epoch [4/4])\n",
      "[1890/2136] train loss: [0.1756] (epoch [4/4])\n",
      "[1891/2136] train loss: [0.2502] (epoch [4/4])\n",
      "[1892/2136] train loss: [0.4778] (epoch [4/4])\n",
      "[1893/2136] train loss: [0.3562] (epoch [4/4])\n",
      "[1894/2136] train loss: [0.2739] (epoch [4/4])\n",
      "[1895/2136] train loss: [0.3982] (epoch [4/4])\n",
      "[1896/2136] train loss: [0.4303] (epoch [4/4])\n",
      "[1897/2136] train loss: [0.2882] (epoch [4/4])\n",
      "[1898/2136] train loss: [0.1975] (epoch [4/4])\n",
      "[1899/2136] train loss: [0.1214] (epoch [4/4])\n",
      "[1900/2136] train loss: [0.2117] (epoch [4/4])\n",
      "[1901/2136] train loss: [0.5310] (epoch [4/4])\n",
      "[1902/2136] train loss: [0.3945] (epoch [4/4])\n",
      "[1903/2136] train loss: [0.4311] (epoch [4/4])\n",
      "[1904/2136] train loss: [0.4748] (epoch [4/4])\n",
      "[1905/2136] train loss: [0.4109] (epoch [4/4])\n",
      "[1906/2136] train loss: [0.2726] (epoch [4/4])\n",
      "[1907/2136] train loss: [0.2780] (epoch [4/4])\n",
      "[1908/2136] train loss: [0.3864] (epoch [4/4])\n",
      "[1909/2136] train loss: [0.2531] (epoch [4/4])\n",
      "[1910/2136] train loss: [0.2660] (epoch [4/4])\n",
      "[1911/2136] train loss: [0.2688] (epoch [4/4])\n",
      "[1912/2136] train loss: [0.3078] (epoch [4/4])\n",
      "[1913/2136] train loss: [0.2092] (epoch [4/4])\n",
      "[1914/2136] train loss: [0.4133] (epoch [4/4])\n",
      "[1915/2136] train loss: [0.2611] (epoch [4/4])\n",
      "[1916/2136] train loss: [0.2967] (epoch [4/4])\n",
      "[1917/2136] train loss: [0.3880] (epoch [4/4])\n",
      "[1918/2136] train loss: [0.3954] (epoch [4/4])\n",
      "[1919/2136] train loss: [0.5605] (epoch [4/4])\n",
      "[1920/2136] train loss: [0.3257] (epoch [4/4])\n",
      "[1921/2136] train loss: [0.5749] (epoch [4/4])\n",
      "[1922/2136] train loss: [0.3814] (epoch [4/4])\n",
      "[1923/2136] train loss: [0.2271] (epoch [4/4])\n",
      "[1924/2136] train loss: [0.3167] (epoch [4/4])\n",
      "[1925/2136] train loss: [0.4088] (epoch [4/4])\n",
      "[1926/2136] train loss: [0.3890] (epoch [4/4])\n",
      "[1927/2136] train loss: [0.1216] (epoch [4/4])\n",
      "[1928/2136] train loss: [0.2913] (epoch [4/4])\n",
      "[1929/2136] train loss: [0.4225] (epoch [4/4])\n",
      "[1930/2136] train loss: [0.3359] (epoch [4/4])\n",
      "[1931/2136] train loss: [0.2155] (epoch [4/4])\n",
      "[1932/2136] train loss: [0.1568] (epoch [4/4])\n",
      "[1933/2136] train loss: [0.2985] (epoch [4/4])\n",
      "[1934/2136] train loss: [0.1984] (epoch [4/4])\n",
      "[1935/2136] train loss: [0.3781] (epoch [4/4])\n",
      "[1936/2136] train loss: [0.1341] (epoch [4/4])\n",
      "[1937/2136] train loss: [0.4426] (epoch [4/4])\n",
      "[1938/2136] train loss: [0.6037] (epoch [4/4])\n",
      "[1939/2136] train loss: [0.2625] (epoch [4/4])\n",
      "[1940/2136] train loss: [0.4117] (epoch [4/4])\n",
      "[1941/2136] train loss: [0.5133] (epoch [4/4])\n",
      "[1942/2136] train loss: [0.4122] (epoch [4/4])\n",
      "[1943/2136] train loss: [0.3297] (epoch [4/4])\n",
      "[1944/2136] train loss: [0.1586] (epoch [4/4])\n",
      "[1945/2136] train loss: [0.3472] (epoch [4/4])\n",
      "[1946/2136] train loss: [0.2885] (epoch [4/4])\n",
      "[1947/2136] train loss: [0.4044] (epoch [4/4])\n",
      "[1948/2136] train loss: [0.2351] (epoch [4/4])\n",
      "[1949/2136] train loss: [0.3233] (epoch [4/4])\n",
      "[1950/2136] train loss: [0.3240] (epoch [4/4])\n",
      "[1951/2136] train loss: [0.1440] (epoch [4/4])\n",
      "[1952/2136] train loss: [0.7053] (epoch [4/4])\n",
      "[1953/2136] train loss: [0.2574] (epoch [4/4])\n",
      "[1954/2136] train loss: [0.1569] (epoch [4/4])\n",
      "[1955/2136] train loss: [0.1178] (epoch [4/4])\n",
      "[1956/2136] train loss: [0.3890] (epoch [4/4])\n",
      "[1957/2136] train loss: [0.6500] (epoch [4/4])\n",
      "[1958/2136] train loss: [0.3371] (epoch [4/4])\n",
      "[1959/2136] train loss: [0.4317] (epoch [4/4])\n",
      "[1960/2136] train loss: [0.3905] (epoch [4/4])\n",
      "[1961/2136] train loss: [0.2494] (epoch [4/4])\n",
      "[1962/2136] train loss: [0.2014] (epoch [4/4])\n",
      "[1963/2136] train loss: [0.3409] (epoch [4/4])\n",
      "[1964/2136] train loss: [0.2602] (epoch [4/4])\n",
      "[1965/2136] train loss: [0.5122] (epoch [4/4])\n",
      "[1966/2136] train loss: [0.1899] (epoch [4/4])\n",
      "[1967/2136] train loss: [0.3684] (epoch [4/4])\n",
      "[1968/2136] train loss: [0.4927] (epoch [4/4])\n",
      "[1969/2136] train loss: [0.3464] (epoch [4/4])\n",
      "[1970/2136] train loss: [0.4873] (epoch [4/4])\n",
      "[1971/2136] train loss: [0.3511] (epoch [4/4])\n",
      "[1972/2136] train loss: [0.5226] (epoch [4/4])\n",
      "[1973/2136] train loss: [0.4253] (epoch [4/4])\n",
      "[1974/2136] train loss: [0.2530] (epoch [4/4])\n",
      "[1975/2136] train loss: [0.1821] (epoch [4/4])\n",
      "[1976/2136] train loss: [0.4920] (epoch [4/4])\n",
      "[1977/2136] train loss: [0.3185] (epoch [4/4])\n",
      "[1978/2136] train loss: [0.4175] (epoch [4/4])\n",
      "[1979/2136] train loss: [0.3906] (epoch [4/4])\n",
      "[1980/2136] train loss: [0.2803] (epoch [4/4])\n",
      "[1981/2136] train loss: [0.5554] (epoch [4/4])\n",
      "[1982/2136] train loss: [0.1651] (epoch [4/4])\n",
      "[1983/2136] train loss: [0.2768] (epoch [4/4])\n",
      "[1984/2136] train loss: [0.4549] (epoch [4/4])\n",
      "[1985/2136] train loss: [0.3251] (epoch [4/4])\n",
      "[1986/2136] train loss: [0.5567] (epoch [4/4])\n",
      "[1987/2136] train loss: [0.3315] (epoch [4/4])\n",
      "[1988/2136] train loss: [0.2091] (epoch [4/4])\n",
      "[1989/2136] train loss: [0.1195] (epoch [4/4])\n",
      "[1990/2136] train loss: [0.5103] (epoch [4/4])\n",
      "[1991/2136] train loss: [0.4112] (epoch [4/4])\n",
      "[1992/2136] train loss: [0.5061] (epoch [4/4])\n",
      "[1993/2136] train loss: [0.4762] (epoch [4/4])\n",
      "[1994/2136] train loss: [0.2253] (epoch [4/4])\n",
      "[1995/2136] train loss: [0.3593] (epoch [4/4])\n",
      "[1996/2136] train loss: [0.4844] (epoch [4/4])\n",
      "[1997/2136] train loss: [0.1674] (epoch [4/4])\n",
      "[1998/2136] train loss: [0.2882] (epoch [4/4])\n",
      "[1999/2136] train loss: [0.2882] (epoch [4/4])\n",
      "[2000/2136] train loss: [0.2394] (epoch [4/4])\n",
      "[2001/2136] train loss: [0.1658] (epoch [4/4])\n",
      "[2002/2136] train loss: [0.3327] (epoch [4/4])\n",
      "[2003/2136] train loss: [0.2524] (epoch [4/4])\n",
      "[2004/2136] train loss: [0.3358] (epoch [4/4])\n",
      "[2005/2136] train loss: [0.6122] (epoch [4/4])\n",
      "[2006/2136] train loss: [0.4271] (epoch [4/4])\n",
      "[2007/2136] train loss: [0.3841] (epoch [4/4])\n",
      "[2008/2136] train loss: [0.2319] (epoch [4/4])\n",
      "[2009/2136] train loss: [0.3798] (epoch [4/4])\n",
      "[2010/2136] train loss: [0.5240] (epoch [4/4])\n",
      "[2011/2136] train loss: [0.4687] (epoch [4/4])\n",
      "[2012/2136] train loss: [0.5391] (epoch [4/4])\n",
      "[2013/2136] train loss: [0.2770] (epoch [4/4])\n",
      "[2014/2136] train loss: [0.3786] (epoch [4/4])\n",
      "[2015/2136] train loss: [0.5537] (epoch [4/4])\n",
      "[2016/2136] train loss: [0.1104] (epoch [4/4])\n",
      "[2017/2136] train loss: [0.3884] (epoch [4/4])\n",
      "[2018/2136] train loss: [0.1704] (epoch [4/4])\n",
      "[2019/2136] train loss: [0.3715] (epoch [4/4])\n",
      "[2020/2136] train loss: [0.2576] (epoch [4/4])\n",
      "[2021/2136] train loss: [0.4313] (epoch [4/4])\n",
      "[2022/2136] train loss: [0.1525] (epoch [4/4])\n",
      "[2023/2136] train loss: [0.2315] (epoch [4/4])\n",
      "[2024/2136] train loss: [0.5263] (epoch [4/4])\n",
      "[2025/2136] train loss: [0.4678] (epoch [4/4])\n",
      "[2026/2136] train loss: [0.4051] (epoch [4/4])\n",
      "[2027/2136] train loss: [0.2456] (epoch [4/4])\n",
      "[2028/2136] train loss: [0.3689] (epoch [4/4])\n",
      "[2029/2136] train loss: [0.1971] (epoch [4/4])\n",
      "[2030/2136] train loss: [0.4569] (epoch [4/4])\n",
      "[2031/2136] train loss: [0.6027] (epoch [4/4])\n",
      "[2032/2136] train loss: [0.2188] (epoch [4/4])\n",
      "[2033/2136] train loss: [0.2574] (epoch [4/4])\n",
      "[2034/2136] train loss: [0.3941] (epoch [4/4])\n",
      "[2035/2136] train loss: [0.1632] (epoch [4/4])\n",
      "[2036/2136] train loss: [0.2234] (epoch [4/4])\n",
      "[2037/2136] train loss: [0.2740] (epoch [4/4])\n",
      "[2038/2136] train loss: [0.1676] (epoch [4/4])\n",
      "[2039/2136] train loss: [0.6960] (epoch [4/4])\n",
      "[2040/2136] train loss: [0.3383] (epoch [4/4])\n",
      "[2041/2136] train loss: [0.4677] (epoch [4/4])\n",
      "[2042/2136] train loss: [0.3581] (epoch [4/4])\n",
      "[2043/2136] train loss: [0.1526] (epoch [4/4])\n",
      "[2044/2136] train loss: [0.2360] (epoch [4/4])\n",
      "[2045/2136] train loss: [0.2816] (epoch [4/4])\n",
      "[2046/2136] train loss: [0.5160] (epoch [4/4])\n",
      "[2047/2136] train loss: [0.3285] (epoch [4/4])\n",
      "[2048/2136] train loss: [0.4222] (epoch [4/4])\n",
      "[2049/2136] train loss: [0.3385] (epoch [4/4])\n",
      "[2050/2136] train loss: [0.3794] (epoch [4/4])\n",
      "[2051/2136] train loss: [0.4458] (epoch [4/4])\n",
      "[2052/2136] train loss: [0.4454] (epoch [4/4])\n",
      "[2053/2136] train loss: [0.3695] (epoch [4/4])\n",
      "[2054/2136] train loss: [0.2204] (epoch [4/4])\n",
      "[2055/2136] train loss: [0.5280] (epoch [4/4])\n",
      "[2056/2136] train loss: [0.2932] (epoch [4/4])\n",
      "[2057/2136] train loss: [0.2226] (epoch [4/4])\n",
      "[2058/2136] train loss: [0.3102] (epoch [4/4])\n",
      "[2059/2136] train loss: [0.4434] (epoch [4/4])\n",
      "[2060/2136] train loss: [0.3380] (epoch [4/4])\n",
      "[2061/2136] train loss: [0.2524] (epoch [4/4])\n",
      "[2062/2136] train loss: [0.4669] (epoch [4/4])\n",
      "[2063/2136] train loss: [0.5949] (epoch [4/4])\n",
      "[2064/2136] train loss: [0.2209] (epoch [4/4])\n",
      "[2065/2136] train loss: [0.4135] (epoch [4/4])\n",
      "[2066/2136] train loss: [0.2677] (epoch [4/4])\n",
      "[2067/2136] train loss: [0.1831] (epoch [4/4])\n",
      "[2068/2136] train loss: [0.2521] (epoch [4/4])\n",
      "[2069/2136] train loss: [0.1641] (epoch [4/4])\n",
      "[2070/2136] train loss: [0.4568] (epoch [4/4])\n",
      "[2071/2136] train loss: [0.7361] (epoch [4/4])\n",
      "[2072/2136] train loss: [0.8110] (epoch [4/4])\n",
      "[2073/2136] train loss: [0.2125] (epoch [4/4])\n",
      "[2074/2136] train loss: [0.4999] (epoch [4/4])\n",
      "[2075/2136] train loss: [0.5901] (epoch [4/4])\n",
      "[2076/2136] train loss: [0.3216] (epoch [4/4])\n",
      "[2077/2136] train loss: [0.1611] (epoch [4/4])\n",
      "[2078/2136] train loss: [0.2100] (epoch [4/4])\n",
      "[2079/2136] train loss: [0.3803] (epoch [4/4])\n",
      "[2080/2136] train loss: [0.3378] (epoch [4/4])\n",
      "[2081/2136] train loss: [0.3387] (epoch [4/4])\n",
      "[2082/2136] train loss: [0.2019] (epoch [4/4])\n",
      "[2083/2136] train loss: [0.2157] (epoch [4/4])\n",
      "[2084/2136] train loss: [0.2753] (epoch [4/4])\n",
      "[2085/2136] train loss: [0.2203] (epoch [4/4])\n",
      "[2086/2136] train loss: [0.6494] (epoch [4/4])\n",
      "[2087/2136] train loss: [0.2990] (epoch [4/4])\n",
      "[2088/2136] train loss: [0.4473] (epoch [4/4])\n",
      "[2089/2136] train loss: [0.7647] (epoch [4/4])\n",
      "[2090/2136] train loss: [0.3194] (epoch [4/4])\n",
      "[2091/2136] train loss: [0.3811] (epoch [4/4])\n",
      "[2092/2136] train loss: [0.2685] (epoch [4/4])\n",
      "[2093/2136] train loss: [0.2485] (epoch [4/4])\n",
      "[2094/2136] train loss: [0.4705] (epoch [4/4])\n",
      "[2095/2136] train loss: [0.2806] (epoch [4/4])\n",
      "[2096/2136] train loss: [0.2992] (epoch [4/4])\n",
      "[2097/2136] train loss: [0.1967] (epoch [4/4])\n",
      "[2098/2136] train loss: [0.2816] (epoch [4/4])\n",
      "[2099/2136] train loss: [0.2813] (epoch [4/4])\n",
      "[2100/2136] train loss: [0.6103] (epoch [4/4])\n",
      "[2101/2136] train loss: [0.3747] (epoch [4/4])\n",
      "[2102/2136] train loss: [0.5523] (epoch [4/4])\n",
      "[2103/2136] train loss: [0.7184] (epoch [4/4])\n",
      "[2104/2136] train loss: [0.4276] (epoch [4/4])\n",
      "[2105/2136] train loss: [0.3759] (epoch [4/4])\n",
      "[2106/2136] train loss: [0.5473] (epoch [4/4])\n",
      "[2107/2136] train loss: [0.2553] (epoch [4/4])\n",
      "[2108/2136] train loss: [0.6292] (epoch [4/4])\n",
      "[2109/2136] train loss: [0.1604] (epoch [4/4])\n",
      "[2110/2136] train loss: [0.4358] (epoch [4/4])\n",
      "[2111/2136] train loss: [0.4933] (epoch [4/4])\n",
      "[2112/2136] train loss: [0.2095] (epoch [4/4])\n",
      "[2113/2136] train loss: [0.4476] (epoch [4/4])\n",
      "[2114/2136] train loss: [0.1461] (epoch [4/4])\n",
      "[2115/2136] train loss: [0.2031] (epoch [4/4])\n",
      "[2116/2136] train loss: [0.1882] (epoch [4/4])\n",
      "[2117/2136] train loss: [0.2683] (epoch [4/4])\n",
      "[2118/2136] train loss: [0.5092] (epoch [4/4])\n",
      "[2119/2136] train loss: [0.5822] (epoch [4/4])\n",
      "[2120/2136] train loss: [0.2003] (epoch [4/4])\n",
      "[2121/2136] train loss: [0.4402] (epoch [4/4])\n",
      "[2122/2136] train loss: [0.2479] (epoch [4/4])\n",
      "[2123/2136] train loss: [0.2109] (epoch [4/4])\n",
      "[2124/2136] train loss: [0.2923] (epoch [4/4])\n",
      "[2125/2136] train loss: [0.2478] (epoch [4/4])\n",
      "[2126/2136] train loss: [0.6098] (epoch [4/4])\n",
      "[2127/2136] train loss: [0.2520] (epoch [4/4])\n",
      "[2128/2136] train loss: [0.3369] (epoch [4/4])\n",
      "[2129/2136] train loss: [0.2824] (epoch [4/4])\n",
      "[2130/2136] train loss: [0.3687] (epoch [4/4])\n",
      "[2131/2136] train loss: [0.6556] (epoch [4/4])\n",
      "[2132/2136] train loss: [0.2530] (epoch [4/4])\n",
      "[2133/2136] train loss: [0.7190] (epoch [4/4])\n",
      "[2134/2136] train loss: [0.3079] (epoch [4/4])\n",
      "[2135/2136] train loss: [0.4169] (epoch [4/4])\n",
      "[2136/2136] train loss: [0.0597] (epoch [4/4])\n",
      "epoch [4/4] validation loss: [0.3620] validation accuracy: [0.8339587242026266]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "cls_model.to(device)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "step = 0\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    \n",
    "    # train loop\n",
    "    cls_model.train()\n",
    "    for data in train_loader:\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attention_mask = data[\"attention_mask\"].to(device)\n",
    "        label = data[\"label\"].view(-1, 1).float().to(device)\n",
    "        \n",
    "        logits = cls_model.forward(input_ids, attention_mask)\n",
    "        \n",
    "        \n",
    "        loss = loss_fn.forward(\n",
    "            input = logits,\n",
    "            target = label\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step() # update paramater\n",
    "        scheduler.step() \n",
    "        optimizer.zero_grad() # clear gradient\n",
    "        \n",
    "        vis_loss = loss.detach().cpu()\n",
    "        \n",
    "        print(f\"[{step + 1}/{num_training_steps}] train loss: [{vis_loss:.4f}] (epoch [{epoch + 1}/{num_train_epochs}])\")\n",
    "        \n",
    "        \n",
    "        train_losses.append(vis_loss)\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    val_loss = 0\n",
    "    \n",
    "    cls_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            labels = data[\"label\"].view(-1, 1).float().to(device)\n",
    "            \n",
    "            logits = cls_model.forward(input_ids, attention_mask)\n",
    "            loss = loss_fn.forward(\n",
    "                input = logits,\n",
    "                target = labels\n",
    "            )\n",
    "            \n",
    "            val_loss += loss.detach().cpu()\n",
    "            \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "    val_acc = compute_accuracy(val_loader)\n",
    "    print(f\"epoch [{epoch + 1}/{num_train_epochs}] validation loss: [{val_loss:.4f}] validation accuracy: [{val_acc}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: [0.379112184047699]\n",
      "Test accuracy: [0.8395872420262664]\n"
     ]
    }
   ],
   "source": [
    "# test loss\n",
    "cls_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attention_mask = data[\"attention_mask\"].to(device)\n",
    "        label = data[\"label\"].view(-1, 1).float().to(device)\n",
    "        \n",
    "        logits = cls_model.forward(input_ids, attention_mask)\n",
    "        loss = loss_fn.forward(\n",
    "            input = logits,\n",
    "            target = label\n",
    "        )\n",
    "        \n",
    "        test_loss += loss.detach().cpu()\n",
    "        \n",
    "    test_loss /= len(val_loader)\n",
    "    \n",
    "test_acc = compute_accuracy(test_loader)\n",
    "\n",
    "print(f\"Test Loss: [{test_loss}]\\nTest accuracy: [{test_acc}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
